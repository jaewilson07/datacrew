[{"objectID": "9e0e584e54b0-0", "text": "Title\n\nMySQL Connector\n\nArticle Body\n\nIntro\nMySQL is a widely used open-source relational database management system.\u00a0You can use Domo's MySQL Connector to pull data from your MySQL database and compile custom reports. You indicate the data you want by inputting an SQL query. For more information about the MySQL API, visit their website. (http://dev.mysql.com/doc/refman/5.0/en/c-api.html)\nThe MySQL connector is a \"Database\" connector, meaning it retrieves data from a database using a query. In the Data Center, you can access the connector page for this and other Database connectors by clicking Database in the toolbar at the top of the window.\nYou connect to your MySQL database in the Data Center. This topic discusses the fields and menus that are specific to the MySQL connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\n\n\n \n\n\nNotes:\u00a0\nThis connector supports TLS IF your MySQL server supports TLS.Non SSL connections are not supported. If no certificate is provided, the connection is still SSL but without any certificate authentication. The connection will trust all server certificates. Refer to the following\u00a0link for details : https://msdn.microsoft.com/en-us/library/bb879949%28v=sql.110%29.aspx", "source": "../../raw_kb/article/mysql_connector/index.html", "title": "MySQL Connector"}, {"objectID": "9e0e584e54b0-1", "text": "Primary Use CasesPulling data mart and data warehouse SQL queriesPrimary MetricsN/APrimary Company RolesCIOCTOAverage Implementation Time5-40+ hoursEase of Use (on a 1-to-10 scale with 1 being easiest)7\n\u00a0\nBest Practices\nLimit the results set size is much as possible.Keep the number of columns to a minimum.\nPrerequisites\nTo connect to a MySQL database and create a DataSet, you must have the following:\nThe username and password you use to log into your MySQL databaseThe host name for the databaseThe port number for the databaseThe database name or schema nameThe SQL query you will use to pull dataSSL\nYou can also include the URL where your SSL CA Certificate is located, though this is optional. If your SSL configuration requires use of all 3 .PEM certificate files, you can utilize the MySQL Advanced Security Connector which has a field for each file.\nCreating MySQL Accounts\nYou can create MySQL accounts two ways:\nBy using account management statements intended for creating accounts and establishing their privileges, such as CREATE USER and GRANT. These statements cause the server to make appropriate modifications to the underlying grant tables.By manipulating the MySQL grant tables directly with statements such as INSERT, UPDATE, or DELETE.\nThe preferred method is to use account management statements because they are more concise and less error-prone than manipulating the grant tables directly.\nAnother option for creating accounts is to use the GUI tool MySQL Workbench. Also, several third-party programs offer capabilities for MySQL account administration, such as phpMyAdmin.\nWhitelisting\nBefore you can connect to a\u00a0MySQL database, you must also whitelist a number of IP addresses on your database server on the\u00a0port\u00a0you want to connect to. For the full list of IP addresses, see Whitelisting IP Addresses for Connectors.\nConnecting to Your MySQL Database", "source": "../../raw_kb/article/mysql_connector/index.html", "title": "MySQL Connector"}, {"objectID": "9e0e584e54b0-2", "text": "Connecting to Your MySQL Database\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the MySQL Connector page. The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.", "source": "../../raw_kb/article/mysql_connector/index.html", "title": "MySQL Connector"}, {"objectID": "9e0e584e54b0-3", "text": "Note:\u00a0When using the copy/paste function for your credentials, ensure there is no whitespace at the beginning or end of the string. By accidentally pasting whitespace, it will cause the connector to error when trying to connect.", "source": "../../raw_kb/article/mysql_connector/index.html", "title": "MySQL Connector"}, {"objectID": "9e0e584e54b0-4", "text": "Credentials Pane\nThis pane contains fields for entering credentials to connect to your database. The following table describes what is needed for each field: \u00a0\nFieldDescriptionHostEnter the host name for the SQL database. For example: db.company.comDatabase NameEnter the name of the SQL database or schema.UsernameEnter your MySQL username.PasswordEnter your MySQL password.CA CertificateEnter the URL where the SSL Ca Certificate is located (optional).PortEnter the port number for the database.\nOnce you have entered valid\u00a0MySQL credentials, you can use the same account any time you go to create a new\u00a0MySQL DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see\u00a0Managing User Accounts for Connectors.\nDetails Pane\nIn this pane you create an SQL query to pull data from your database, with or without a parameter.\nMenuDescriptionQuery TypeSelect the desired MySQL query type\u2014either with or without a parameter.QueryEnter the Structured Query Language (SQL) query to use in selecting the data you want. For example:\nselect * from Employee\nYou can use the\u00a0Query Helper\u00a0parameter to help you write a usable SQL query. To use the\u00a0Query Helper, do the following:Select your database table\u00a0and table columns in the appropriate menus.Copy the SQL statement that appears in the\u00a0Query Helper\u00a0field.Paste the copied SQL statement into the\u00a0Query\u00a0field.\u00a0Query ParameterEnter the query parameter value. This is the initial value for the query parameter. You can use this option to retrieve new data since the last run.\u00a0\nFor example, if you entered the following query in the\u00a0Query\u00a0field...\nselect * from test.lastValue where id <= !{lastvalue:id}! order by id desc\n...and then entered the following for the\u00a0Query Parameter...\n!{lastvalue:id}!=3", "source": "../../raw_kb/article/mysql_connector/index.html", "title": "MySQL Connector"}, {"objectID": "9e0e584e54b0-5", "text": "!{lastvalue:id}!=3\n...then the first run would return 3 rows, and all subsequent runs would return 1 row, and the results would be ordered from largest to smallest.\u00a0\nSimilarly, if you entered the following in the Query\u00a0field...\nselect * from test.lastValue where time > !{lastrundate:time}!\n...and then entered the following for the\u00a0Query Parameter...\n!{lastrundate:time}!=01/01/1990\n...then the first run would return 5 rows and all subsequent runs would return 0 rows.TinyInt Values Treated as Boolean Values?Select\u00a0Yes\u00a0if you want TinyInt\u00a0values to be treated as Boolean.Cast Boolean Values To...Select whether Boolean values will be cast to integers or strings.Database Tables (Optional)Select the database table you want to import into Domo.\u00a0Table Columns (Optional)Select the table columns you want to import into Domo.Query Helper (Optional)\u00a0Copy and paste the SQL statement in this field into the\u00a0Query\u00a0field. For more information, see\u00a0Query, above.\n\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nTroubleshooting\nVerify the credentials using MySQL Workbench.Confirm the server supports encrypted connections.Confirm the Domo IPs are whitelisted.To speed up your runtime, make sure the tables you are joining don't have duplicate column names and that you call each column only once.", "source": "../../raw_kb/article/mysql_connector/index.html", "title": "MySQL Connector"}, {"objectID": "52e8ea323c21-0", "text": "TitleMySQL Partition ConnectorArticle BodyIntro\nMySQL is a widely used open-source relational database management system.\u00a0With Domo's MySQL integration, you can easily connect your MySQL data and make faster decisions. Partitioning enables the table data to be divided across multiple storage objects (data partitions), according to the values in one or more table columns based on a set of user-defined rules. Use Domo\u2019s MySQL Partition connector to optimize the way the database engine physically stores data.\nYou connect to your MySQL Partition account in the Data Center. This topic discusses the fields and menus that are specific to the MySQL Partition connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\n\n\n \n\n\nNotes:\u00a0\nThis connector supports TLS IF your MySQL server supports TLS.Non SSL connections are not supported. If no certificate is provided, the connection is still SSL but without any certificate authentication. The connection will trust all server certificates. Refer to the following\u00a0link for details : https://msdn.microsoft.com/en-us/library/bb879949%28v=sql.110%29.aspx", "source": "../../raw_kb/article/mysql_partition_connector/index.html", "title": "MySQL Partition Connector"}, {"objectID": "52e8ea323c21-1", "text": "Prerequisites\nTo connect to your MySQL Partition account and create a DataSet, you must have the following:\nThe username and password you use to log into your MySQL database.The host name for the database.The port number for the database.The database name or schema name.SSLYou can also include the URL where your SSL CA Certificate is located, though this is optional.\nBefore you can connect to a MySQL\u00a0database, you must also whitelist a number of IP addresses on your database server on the\u00a0port\u00a0you want to connect to. For the full list of IP addresses, see\u00a0Whitelisting IP Addresses for Connectors.\nConnecting to Your MySQL Partition Account\nThis section enumerates the options in the Credentials and Details panes in the MySQL Partition Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your MySQL Partition account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionJDBC DriverSelect the JDBC driver to use to connect to the database server.HostEnter the host name for the MySQL database. For example:\u00a0db.company.comPortEnter the port number for the database.Database NameEnter the name of the MySQL database or schema.UsernameEnter your MySQL username.PasswordEnter your MySQL password.CA CertificateEnter the URL where the SSL CA Certificate is located (optional).\nOnce you have entered valid\u00a0credentials, you can use the same account any time you go to create a new MySQL Partition DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nIn this pane you specify the attributes and conditions\u00a0to partition\u00a0your data.", "source": "../../raw_kb/article/mysql_partition_connector/index.html", "title": "MySQL Partition Connector"}, {"objectID": "52e8ea323c21-2", "text": "Details Pane\nIn this pane you specify the attributes and conditions\u00a0to partition\u00a0your data.\nMenuDescriptionQueryEnter the SQL query to execute.Table NameSelect the database table.Partition Column NameSelect partition column name.Past DaysEnter the number of past days you want to get data for. Value can be a positive integer. For example: 30.Date FormatSelect the required date format. By default\u00a0yyyy-MM-dd\u00a0will be used.Select if you want to compress the dataChoose the way you want the data to be uploaded. Select True, if you want the data to be compressed while uploading, else select False.Tinyint values treated as (bit) boolean valuesSelect Yes if you want the tiny integer\u00a0values to be treated as boolean\u00a0values, else select No.Cast Boolean Values to...Select whether the String or Integer boolean values will be cast to within your dataset.\u00a0String: False/TrueInteger: 0/1\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding a DataSet Using a Data Connector.", "source": "../../raw_kb/article/mysql_partition_connector/index.html", "title": "MySQL Partition Connector"}, {"objectID": "ddf3f9342f86-0", "text": "Title\n\nMySQL SSH Connector\n\nArticle Body\n\nIntro\nMySQL is a widely used open-source relational database management system.\u00a0You can use Domo's MySQL SSH Connector to pull data from your MySQL database and compile custom reports. You indicate the data you want by inputting an SQL query. For more information about the MySQL API, visit their website. (http://dev.mysql.com/doc/refman/5.0/en/c-api.html)\nThe MySQL SSH connector is a \"Database\" connector, meaning it retrieves data from a database using a query. In the Data Center, you can access the connector page for this and other Database connectors by clicking Database in the toolbar at the top of the window.\nYou connect to your MySQL database in the Data Center. This topic discusses the fields and menus that are specific to the MySQL SSH connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrimary Use CasesPulling data mart and data warehouse SQL queriesPrimary MetricsN/APrimary Company RolesCIOCTOAverage Implementation Time5-40+ hoursEase of Use (on a 1-to-10 scale with 1 being easiest)7\nBest Practices\nLimit the results set size as much as possible.Keep the number of columns to a minimum.\nPrerequisites\nTo connect to a MySQL database via an SSH server and create a DataSet, you must have the following:\nThe hostname of the UNIX server you are SSH-tunneling throughThe SSH username and password for your UNIX accountThe host name for the databaseThe SSH private key (either DES or RSA)The database nameThe username and password you use to log into your MySQL database\n\n\n\u00a0\n\nNote: Domo does not support the SSH keys generated using ssh-keygen. The SSH keys need to be the DES or RSA keys (in PEM format) generated by OpenSSL.", "source": "../../raw_kb/article/mysql_ssh_connector/index.html", "title": "MySQL SSH Connector"}, {"objectID": "ddf3f9342f86-1", "text": "Creating MySQL Accounts\nYou can create MySQL accounts two ways:\nBy using account management statements intended for creating accounts and establishing their privileges, such as CREATE USER and GRANT. These statements cause the server to make appropriate modifications to the underlying grant tables.By manipulating the MySQL grant tables directly with statements such as INSERT, UPDATE, or DELETE.\nThe preferred method is to use account management statements because they are more concise and less error-prone than manipulating the grant tables directly.\nAnother option for creating accounts is to use the GUI tool MySQL Workbench. Also, several third-party programs offer capabilities for MySQL account administration, such as phpMyAdmin.\nWhitelisting\nBefore you can connect to a\u00a0MySQL database, you must also whitelist a number of IP addresses on your database server on the\u00a0port\u00a0you want to connect to. For the full list of IP addresses, see Whitelisting IP Addresses for Connectors.\nConnecting to Your MySQL Database\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the MySQL Connector page. The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your database. The following table describes what is needed for each field: \u00a0\nFieldDescriptionSSH Server HostnameEnter the hostname of the UNIX server to SSH-tunnel through.SSH UsernameEnter the SSH username for your UNIX account.SSH PasswordEnter the SSH password for your UNIX account.Database HostnameEnter the hostname or IP address for the SQL database. For example: db.company.comSSH Private KeyEnter the SSH private key (either DES or RSA).Database NameEnter the name of the SQL database or schema.Database UsernameEnter your MySQL username.Database PasswordEnter your MySQL password.", "source": "../../raw_kb/article/mysql_ssh_connector/index.html", "title": "MySQL SSH Connector"}, {"objectID": "ddf3f9342f86-2", "text": "Once you have entered valid credentials, you can use the same account any time you go to create a new\u00a0MySQL SSH DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see\u00a0Managing User Accounts for Connectors.\nDetails Pane\nIn this pane you create an SQL query to pull data from your database as well as specify a few options.\nMenuDescriptionQuery TypeSelect a query type.QueryRegular SQL query without parameter.Query ParameterSQL query with parameter.SQL QueryStructured Query Language (SQL) query to use in selecting the data you want. For example:\nselect * from EmployeeQuery ParameterEnter the query parameter value, it is the initial value for query parameter. The last run date is optional. By default, it is '02/01/1700' if is not provided. \nFor example: !{lastvalue:_id}!=1,!{lastrundate:start_date}!=02/01/1944TINYINT Values Treated as Bit (Boolean) Values?Select Yes if you want TINYINT values to be treated as Boolean values.Keep Connection Alive For Large QueriesSelect Yes if the connection should be kept running for very large queries.Include HTML TagSelect Yes to include the html tag with the data.\n\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nTroubleshooting\nVerify the credentials using MySQL Workbench.Confirm the server supports encrypted connections.Confirm the Domo IPs are whitelisted.", "source": "../../raw_kb/article/mysql_ssh_connector/index.html", "title": "MySQL SSH Connector"}, {"objectID": "32a37845ddda-0", "text": "TitleMySQL SSH MultiStatement ConnectorArticle BodyIntro\nMySQL is a widely used open-source relational database management system.\u00a0You can use Domo's MySQL SSH Multi-Statement Connector to pull data from your MySQL database and compile custom reports. You indicate the data you want by inputting an SQL query. For more information about the MySQL API, visit their website. (http://dev.mysql.com/doc/refman/5.0/en/c-api.html)\nThe MySQL SSH MultiStatement connector is a \"Database\" connector, meaning it retrieves data from a database using a query. In the Data Center, you can access the connector page for this and other Database connectors by clicking Database in the toolbar at the top of the window.\nYou connect to your MySQL database in the Data Center. This topic discusses the fields and menus that are specific to the MySQL SSH MultiStatement connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in Adding a DataSet Using a Data Connector.\nPrimary Use CasesPulling data mart and data warehouse SQL queriesPrimary MetricsN/APrimary Company RolesCIOCTOAverage Implementation Time5-40+ hoursEase of Use (on a 1-to-10 scale with 1 being easiest)7\nBest Practices\nLimit the results set size as much as possible.Keep the number of columns to a minimum.\nPrerequisites\nTo connect to a MySQL database via an SSH server and create a DataSet, you must have the following:\nThe hostname of the UNIX server you are SSH-tunneling throughThe SSH username and password for your UNIX accountThe host name for the databaseThe SSH private key (either DES or RSA) in PEM format\u00a0The database nameThe username and password you use to log into your MySQL database\n\n\n\u00a0\n\nNote: Domo does not support the SSH keys generated using ssh-keygen. The SSH keys need to be the DES or RSA keys (in PEM format) generated by OpenSSL.", "source": "../../raw_kb/article/mysql_ssh_multistatement_connector/index.html", "title": "MySQL SSH MultiStatement Connector"}, {"objectID": "32a37845ddda-1", "text": "Creating MySQL Accounts\nYou can create MySQL accounts two ways:\nBy using account management statements intended for creating accounts and establishing their privileges, such as CREATE USER and GRANT. These statements cause the server to make appropriate modifications to the underlying grant tables.By manipulating the MySQL grant tables directly with statements such as INSERT, UPDATE, or DELETE.\nThe preferred method is to use account management statements because they are more concise and less error-prone than manipulating the grant tables directly.\nAnother option for creating accounts is to use the GUI tool MySQL Workbench. Also, several third-party programs offer capabilities for MySQL account administration, such as phpMyAdmin.\nWhitelisting\nBefore you can connect to a\u00a0MySQL database, you must also whitelist a number of IP addresses on your database server on the\u00a0port\u00a0you want to connect to. For the full list of IP addresses, see Whitelisting IP Addresses for Connectors.\nConnecting to Your MySQL Database\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details panes in the MySQL SSH Multistatement Connector page. The components of the other panes in this page, Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your database. The following table describes what is needed for each field: \u00a0\nFieldDescriptionSSH Server HostnameEnter the hostname of the UNIX server to SSH-tunnel through.SSH UsernameEnter the SSH username for your UNIX account.SSH PasswordEnter the SSH password for your UNIX account.Database HostnameEnter the hostname or IP address for the SQL database. For example: db.company.comSSH Private KeyEnter the SSH private key (either DES or RSA).Database NameEnter the name of the SQL database or schema.Database UsernameEnter your MySQL username.Database PasswordEnter your MySQL password.", "source": "../../raw_kb/article/mysql_ssh_multistatement_connector/index.html", "title": "MySQL SSH MultiStatement Connector"}, {"objectID": "32a37845ddda-2", "text": "Once you have entered valid credentials, you can use the same account any time you go to create a new MySQL SSH Multistatement DataSet. You can manage connector accounts in the Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see\u00a0Managing User Accounts for Connectors.\nDetails Pane\nIn this pane you create an SQL query to pull data from your database as well as specify a few options.\nMenuDescriptionQuery TypeSelect a query type.Query TypeDescriptionQueryRegular SQL query without parameter.Query ParameterSQL query with parameter.Query ParameterEnter the query parameter value. It is the initial value for query parameter. The last run date is optional. The default value for the last date is '02/01/1700' if not provided.\nExample:\u00a0!{lastvalue:_id}!=1,!{lastrundate:start_date}!=02/01/1944SQL QueryStructured Query Language (SQL) query to use in selecting the data you want. For example:\nselect * from EmployeeTINYINT Values Treated as Bit (Boolean) Values?Select Yes if you want TINYINT values to be treated as Boolean values.Keep Connection Alive For Large QueriesRuns an additional thread to keep the connection alive. Useful for long runs.Query TimeoutEnter connector timeout value in minute(s).Remove Duplicate Records (Connector Update Mode is MERGE)Check this box to remove duplicate records when connector is using Merge/Upsert functionality, bringing in only the most recently modified data. Duplicates are removed using a SQLite query that keeps the most recently modified row.\t\t\tChecking this box will slow your connector run, so use this feature only when necessary.\n\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nTroubleshooting", "source": "../../raw_kb/article/mysql_ssh_multistatement_connector/index.html", "title": "MySQL SSH MultiStatement Connector"}, {"objectID": "32a37845ddda-3", "text": "Troubleshooting\nVerify the credentials using MySQL Workbench.Confirm the server supports encrypted connections.Confirm the Domo IPs are whitelisted.", "source": "../../raw_kb/article/mysql_ssh_multistatement_connector/index.html", "title": "MySQL SSH MultiStatement Connector"}, {"objectID": "10e19273f878-0", "text": "TitleMySQL SSH Partition ConnectorArticle BodyIntro\nMySQL is a widely used open-source relational database management system. With Domo's MySQL integration, you can easily connect your MySQL data and make faster decisions. Partitioning enables the table data to be divided across multiple storage objects (data partitions), according to the values in one or more table columns based on a set of user-defined rules. Use Domo\u2019s MySQL SSH Partition connector to optimize the way the database engine physically stores data.\nYou connect to your MySQL account in the Data Center. This topic discusses the fields and menus that are specific to the MySQL SSH Partition connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in Adding a DataSet Using a Data Connector.\n\n\n\u00a0\n\n\nNotes:\u00a0\nThis connector supports TLS IF your MySQL server supports TLS.Non SSL connections are not supported. If no certificate is provided, the connection is still SSL but without any certificate authentication. The connection will trust all server certificates. Refer to the following\u00a0link for details : https://msdn.microsoft.com/en-us/library/bb879949%28v=sql.110%29.aspx\n\n\n\n\nPrerequisites\nTo connect to your MySQL account and create a DataSet, you must have the following:\nThe hostname of the UNIX server you are SSH-tunneling throughThe SSH username and password for your UNIX accountThe SSH private key in PEM format (either DES or RSA)The host name for the databaseThe database nameThe username and password you use to log into your MySQL database\n\n\n\u00a0\n\nNote: Domo does not support the SSH keys generated using ssh-keygen. The SSH keys need to be the DES or RSA keys (in PEM format) generated by OpenSSL.", "source": "../../raw_kb/article/mysql_ssh_partition_connector/index.html", "title": "MySQL SSH Partition Connector"}, {"objectID": "10e19273f878-1", "text": "Before you can connect to a MySQL\u00a0database, you must also whitelist a number of IP addresses on your database server on the\u00a0port\u00a0you want to connect to. For the full list of IP addresses, see\u00a0Whitelisting IP Addresses for Connectors.\nConnecting to Your MySQL Account\nThis section enumerates the options in the Credentials and Details panes in the MySQL SSH Partition Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your MySQL SSH Partition account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionJDBC DriverSelect the JDBC driver to use to connect to the database server.SSH Server HostnameEnter the hostname of the UNIX server to SSH-tunnel through.SSH UsernameEnter the SSH username for your UNIX account.SSH PasswordEnter the SSH password for your UNIX account.Database HostnameEnter the hostname or IP address for the SQL database. For example:\u00a0db.company.comSSH Private KeyEnter the SSH private key in PEM format (either DES or RSA).Database NameEnter the name of the SQL database or schema.Database UsernameEnter your MySQL username.Database PasswordEnter your MySQL password.\nOnce you have entered valid\u00a0credentials, you can use the same account any time you go to create a new MySQL SSH Partition DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nIn this pane you specify the attributes and conditions\u00a0to partition\u00a0your data.", "source": "../../raw_kb/article/mysql_ssh_partition_connector/index.html", "title": "MySQL SSH Partition Connector"}, {"objectID": "10e19273f878-2", "text": "Details Pane\nIn this pane you specify the attributes and conditions\u00a0to partition\u00a0your data.\nMenuDescriptionQueryEnter the SQL query to execute. Please enter table name in back-quotes.(Example: select * from `table_name`)Table NameSelect the database table.Partition Column NameSelect partition column name.Past DaysEnter the number of past days you want to get data for. Value can be a positive integer. For example: 30.Date FormatPlease select/enter proper date format according to the date format present in partition column. By default yyyy-MM-dd\u00a0will be used.Custom Date FormatEnter the custom date format.Select if you want to compress the dataChoose the way you want the data to be uploaded. Select True, if you want the data to be compressed while uploading, else select False.Tinyint values treated as (bit) boolean valuesSelect Yes if you want the tiny integer\u00a0values to be treated as boolean\u00a0values, else select No.Cast Boolean Values to...Select whether the String or Integer boolean values will be cast to within your dataset.\u00a0\t\t\tString: False/True\t\t\tInteger: 0/1Keep connection alive (for large queries)Runs an additional thread to keep the connection alive. Useful for long runs.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding a DataSet Using a Data Connector.", "source": "../../raw_kb/article/mysql_ssh_partition_connector/index.html", "title": "MySQL SSH Partition Connector"}, {"objectID": "fb091d666553-0", "text": "TitleMySQL SSH Writeback ConnectorArticle BodyIntro\nMySQL is an open-source relational database management system. The MySQL SSH Writeback connector supports a secure connection to export your data from a Domo DataSet to the provided MySQL database. You export data to a MySQL database in the Data Center.\nYou configure your Domo-MySQL connection in the Data Center. This topic discusses the fields and menus that are specific to the MySQL SSH Writeback Connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in Adding a DataSet Using a Data Connector.\n\n\n\u00a0\n\nNote: The owner of a writeback dataset must also be an owner or co-owner of the input dataset.\n\u00a0\n\n\n\nPrerequisites\nTo configure this connector, you must have the following:\nThe hostname of the server you are SSH-tunneling throughYour SSH server port number, username, password, private key, and private key passphraseThe hostname or IP address of your database serverYour MySQL port number, username, password, and database name\n\n\n\u00a0\n\nNote: Domo does not support the SSH keys generated using ssh-keygen. The SSH keys need to be the DES or RSA keys generated by OpenSSL.\n\n\n\n\u00a0\n\n\n\u00a0\n\nImportant: You will need the following permissions on MySQL:\n\nFILECREATEDROPINSERTSELECTUPDATE", "source": "../../raw_kb/article/mysql_ssh_writeback_connector/index.html", "title": "MySQL SSH Writeback Connector"}, {"objectID": "fb091d666553-1", "text": "Configuring the Connection\nThis section enumerates the options in the Credentials and Details panes in the MySQL SSH Writeback\u00a0Connector page. The components of the other panes in this page, Scheduling and Name & Describe Your DataSet, are universal across most Connector types and are discussed in greater length in Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your MySQL account where you want your data to be copied to. The following table describes what is needed for each field: \u00a0\nFieldDescriptionSSH Server Host NameEnter your SSH server host name.SSH Port NumberEnter your SSH server port number.SSH UsernameEnter your SSH sever username.SSH PasswordEnter your SSH server password.SSH Private KeyEnter the SSH private key in PEM format (either DES or RSA).SSH Private Key PassphraseEnter your SSH server private key passphrase.MySQL JDBC DriverSelect the MySQL JDBC driver to use.HostEnter your hostname or IP address of your database server.PortEnter your MySQL port number.UsernameEnter your MySQL username.PasswordEnter your MySQL password.DatabaseEnter your MySQL database name.\nOnce you have entered valid credentials, you can use the same account any time you go to set up a new Domo-MySQL connection. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a number of fields for specifying your data and indicating where it's going.\nMenuDescriptionDataSet IDEnter your Domo dataset ID(GUID) located in the dataset URL.", "source": "../../raw_kb/article/mysql_ssh_writeback_connector/index.html", "title": "MySQL SSH Writeback Connector"}, {"objectID": "fb091d666553-2", "text": "For example, in the URL https://mycompany.domo.com/datasources/845305d8-da3d-4107-a9d6-13ef3f86d4a4/details/overview, the DataSet ID is\u00a0845305d8-da3d-4107-a9d6-13ef3f86d4a4.\u00a0How would you like to select your table?Specify whether you would like to create a new table or select an existing table to export your DataSet data to.Table NameSelect whether you would like to use the dataset ID or a custom name for the table name.Custom Table NameEnter the name for the SQL table to write the dataset data to.Delete existing table and create a new table with the same nameSelect this checkbox if you want Domo to delete the existing table and create a new one with the same name. \nWARNING: This deletes the existing table and the data cannot be recovered once deleted.Existing TableSelect the table to write the dataset data to.Update Operation TypeSelect whether you want to append data, overwrite new data, or upsert data while updating it.Use Column MappingSelect the checkbox if you wish to provide Dataset Column Name and Table Column Name mapping. If this option is selected, only those columns that are provided in the Text Areas will be updated/inserted.Dataset Column NamesEnter the comma separated list of Dataset Column Names.Table Column NamesEnter the comma separated list of Table Column Names. Table Column Names should correspond to the Dataset Column Names in the same sequence. The Number of Dataset Column Names should be equal to Table Column Names for proper mapping.Primary ColumnSelect the column name that should be primary key column.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nFAQs\nWhat kind of credentials do I need to power up this Connector?", "source": "../../raw_kb/article/mysql_ssh_writeback_connector/index.html", "title": "MySQL SSH Writeback Connector"}, {"objectID": "fb091d666553-3", "text": "FAQs\nWhat kind of credentials do I need to power up this Connector?\nYou need the following:\nThe hostname of the server you are SSH-tunneling throughYour SSH server port number, username, password, private key, and private key passphraseThe hostname or IP address of your database serverYour MySQL port number, username, password, and database nameYou also need to select the MySQL JDBC driver to use\nAre there any API limits I should be aware of?\nNo\nHow do I find the Input Dataset ID?\nYour Domo input dataset id is in the URL of the dataset you are exporting data from. For example: https://customer.domo.com/datasources/aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee/details/settings\nTroubleshooting\nMake sure your authentication remains valid.Review the configuration to make sure that all required items have been selected.Review the Connector history for error messages.In rare cases, you may be requesting too much information and reaching API limitations or timeouts. If this is the case, you can review the history of the Connector run to see the error message and duration. If this is the case, you can reduce the number of accounts that are being pulled, choose a smaller number of metrics for the report that you are pulling, or reduce the timeframe that you are trying to pull.", "source": "../../raw_kb/article/mysql_ssh_writeback_connector/index.html", "title": "MySQL SSH Writeback Connector"}, {"objectID": "b3e9ed986c48-0", "text": "TitleMySQL Writeback ConnectorArticle BodyIntro\nTo learn more about MySQL, visit their website at https://www.mysql.com/.\nYou export data to a\u00a0MySQL database\u00a0in the Data Center. This topic discusses the fields and menus that are specific to the MySQL Database Writeback\u00a0connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\n\n\n\n\n\nNote: The owner of a writeback dataset must also be an owner or co-owner of the input dataset.\n\n\n\n\nPrerequisites\nTo configure this connector, you will need the following:\nA Domo Client ID and Client Secret. To obtain these credentials, do the following:Log into your Domo developer account at https://developer.domo.com/login.\u00a0Create a new client.\u00a0Select the desired data and user application scope.Click\u00a0Create.Your MySQL database or schema name.The hostname or IP address of your MySQL database server, such as db.mycompany.com.\u00a0Your MySQL Databaseserver port number.Your MySQL username and password.\u00a0The port number for your MySQL server.Your MySQL CA certificate\n\n\n \n\n\nImportant: You will need the following permissions on MySQL:\nFILECREATEDROPINSERTSELECTUPDATE", "source": "../../raw_kb/article/mysql_writeback_connector/index.html", "title": "MySQL Writeback Connector"}, {"objectID": "b3e9ed986c48-1", "text": "Configuring the Connection\nThis section enumerates the options in the Credentials and Details panes in the MySQL Writeback Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Domo\u00a0developer\u00a0account as well as the table in your MySQL database where you want your data to be copied to. The following table describes what is needed for each field: \u00a0\nFieldDescriptionDomo Client IDEnter your Domo client ID.Domo Client SecretEnter your Domo client secret.Database NameEnter the name of your MySQL database.HostEnter your MySQL database\u00a0hostname.UsernameEnter your MySQL username.PasswordEnter your MySQL password.\u00a0CA CertificatePaste the text for your MySQL CA certificate.\u00a0PortEnter your MySQL database\u00a0port number.\nFor more information about obtaining these credentials, see \"Prerequisites,\" above.\u00a0\nOnce you have entered valid credentials, you can use the same account any time you go to set up a new Domo-MySQL connection. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a number of fields for specifying your data and indicating where it's going.", "source": "../../raw_kb/article/mysql_writeback_connector/index.html", "title": "MySQL Writeback Connector"}, {"objectID": "b3e9ed986c48-2", "text": "This pane contains a number of fields for specifying your data and indicating where it's going.\nMenuDescriptionDataSet IDEnter the DataSet\u00a0ID (GUID) for the DataSet you want to copy to MySQL. You can find the ID by opening the details view for the DataSet in the Data Center and looking at the portion of the URL following datasources/.\u00a0For example, in the URL\u00a0https://mycompany.domo.com/datasources/845305d8-da3d-4107-a9d6-13ef3f86d4a4/details/overview, the DataSet ID is\u00a0845305d8-da3d-4107-a9d6-13ef3f86d4a4.\u00a0Select Table NameSelect how you want to name the table where data will be copied.\u00a0DataSet\u00a0ID. The table name will be the number you entered for\u00a0DataSet ID.DataSet\u00a0Name. The table name will be the same as that of the input DataSet.Custom Name. You will give the table a custom name in the\u00a0Custom Table Name\u00a0field.Custom Table NameEnter the name of the table in your MySQL database where you want your DataSet data to be copied.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/mysql_writeback_connector/index.html", "title": "MySQL Writeback Connector"}, {"objectID": "8b9523d299a7-0", "text": "TitleNaming Conventions Best PracticesArticle BodyIntro", "source": "../../raw_kb/article/naming_conventions_best_practices/index.html", "title": "Naming Conventions Best Practices"}, {"objectID": "8b9523d299a7-1", "text": "Title of the card\nUse the title of the card to describe the chart and not the summary number.Do not include date range qualifiers (This Year, Last Quarter) in the title. An exception could be when the chart does not have dates on an axis and the chart does not have the standard date range activated.In the title, do not include units or amounts, as those are handled on the chart axis labels.All KPIs have an operator, at least one measurement item, and at least one dimension. In the title, include the following elements: [Operator] Measurement and Dimension(s).The Operator is omitted when the measurement is simply an amount or number.The Operator is required when the measure is calculated. For example, \u201cPercent of\u201d or \u201cAverage.\"The first Dimension is preceded with \u201cBy\u201d (ex: Average Deal Size by Rep).Subsequent Dimensions are separated with \u201cand\u201d (ex: Upside ACV by Account and Team).\nGeneral naming best practices\nUse business language rather than technical terms.Do not use \u201cCount\u201d or \u201cSum\u201d language.Avoid abbreviations. For example...\"Last 12 Months\" instead of \"L12M\"\"Year Over Year\" instead of \"YOY\"\"This Month\" instead of \"MTD\"\"This Year\" instead of \"YTD\"If you use an abbreviation, define the abbreviation in the card description.Do not name columns the same as functions that are used in SQL, such as \"DATE,\" \"Date,\" \"date,\" or \"Year.\" Instead, use more specific terms such as \"Start Date,\" \"End Date,\" \"Shipping Date,\" \"Year of Transport,\" etc.\u00a0Here is a list to avoid if needed: https://dev.mysql.com/doc/refman/5.6/en/keywords.html.\nDate Ranges", "source": "../../raw_kb/article/naming_conventions_best_practices/index.html", "title": "Naming Conventions Best Practices"}, {"objectID": "8b9523d299a7-2", "text": "Date Ranges\nWhen dealing with daily information that is not a month-over-month comparison, typically include last month and this month.When dealing with weekly information that is not a period-over-period comparison, typically include at least last month and this month.When dealing with monthly data that is not a year-over-year comparison, typically include 12 months and this month.When dealing with quarterly data that is not a year-over-year comparison, typically include last 4 quarters and this quarter.\nNumber Precision\nWhen using the Auto Abbreviate Units format type, use 2 decimal places.Use the Auto Abbreviate Units precision unless the situation calls for showing the entire number.\nSummary Number\nSelect a measurement meaningful on its own but is related to the chart.Spell it out\u2014\"This is what it is.\"Include the date range in the summary number description when summary number range is fixed and different from the default chart range.\nDataSets\nUtilize suffix/prefix: PROD, INT, QA, or TEMPName DataSets using a common format (ex: BU_System_Dept_Suffix; have ABC_Salesforce_Sales_PROD)Avoid using / or \\ in the DataSet name.Add tags to your DataSets to make them more easily searchable.", "source": "../../raw_kb/article/naming_conventions_best_practices/index.html", "title": "Naming Conventions Best Practices"}, {"objectID": "ddb09390ceb0-0", "text": "TitleNASA ConnectorArticle BodyIntro\nThe National Aeronautics and Space Administration, or NASA, is an independent agency of the United States Federal Government responsible for the civilian space program\u00a0as well as aeronautics and aerospace research.\u00a0 To learn more about the NASA API, visit their page (https://api.nasa.gov/).\nYou connect to NASA's API\u00a0in the Data Center. This topic discusses the fields and menus that are specific to the NASA connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0 a DataSet Using a Data Connector.\nPrerequisites\nTo connect to the NASA API\u00a0and create a DataSet, you must have a NASA API key. To request an API key, visit\u00a0https://api.nasa.gov/index.html#apply-for-an-api-key.\u00a0\nConnecting to the NASA API\nThis section enumerates the options in the Credentials and Details panes in the NASA Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to the NASA API. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter your NASA API key. To request an API key,\u00a0visit\u00a0https://api.nasa.gov/index.html#apply-for-an-api-key.\u00a0\nOnce you have entered valid NASA credentials, you can use the same account any time you go to create a new NASA DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/nasa_connector/index.html", "title": "NASA Connector"}, {"objectID": "ddb09390ceb0-1", "text": "MenuDescriptionReportSelect the NASA report you want to run.\u00a0The following reports are available:Astronomy Picture of the DayReturns data about the Astronomy Picture of the Day.Coronal Mass EjectionReturns coronal mass ejection (CME) data for the given time period.Geomagnetic StormReturns geomagnetic storm (GST) data for the given time period.Interplanetary ShockReturns interplanetary shock (IPS) data for the given time period.Solar FlareReturns solar flare (FLR) data for the given time period.Solar Energetic Particle\u00a0Returns solar energetic particle (SEP) data for the given time period.Magnetopause CrossingReturns magnetopause crossing (MPC) data for the given time period.Radiation Belt EnhancementReturns radiation belt enhancement (RBE) data for the given time period.High Speed StreamReturns high speed stream (HSS) data for the given time period.WSA + ENLIL\u00a0SimulationReturns WSA + ENLIL simulation data for the given time period.NotificationsReturns all notifications for the given time period.Duration\u00a0Select whether you want to pull data for a specific date or a date range.\u00a0Report Date\u00a0Select whether the report data is", "source": "../../raw_kb/article/nasa_connector/index.html", "title": "NASA Connector"}, {"objectID": "ddb09390ceb0-2", "text": "date range.\u00a0Report Date\u00a0Select whether the report data is for a specific date or for a relative number of days back from today.\u00a0Select Specific Date\u00a0Select the date for the report.\u00a0Days BackEnter the number of past days that should appear in the report.\u00a0\u00a0Start DateSpecify whether the\u00a0first date in your date range is a specific or relative date.\u00a0You select the last date in your range in\u00a0End Date.\u00a0End DateSpecify whether the second date in your date range is a specific or relative date. You select the first date in your range in\u00a0Start Date.\u00a0\u00a0Select Specific Start DateSelect\u00a0the first date in your date range.\u00a0Select Specific End DateSelect the second date in your date range.\u00a0Days Back to Start FromEnter the number of the farthest day back that should be represented in the report. Combine with\u00a0Days Back to End At\u00a0to create a range of represented days.", "source": "../../raw_kb/article/nasa_connector/index.html", "title": "NASA Connector"}, {"objectID": "ddb09390ceb0-3", "text": "For example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Days Back to End AtEnter the number of the most recent day back that should be represented in the report. Combine with\u00a0Days Back to Start From\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/nasa_connector/index.html", "title": "NASA Connector"}, {"objectID": "605f0504c3ca-0", "text": "TitleNational Resources Conservation Service ConnectorArticle BodyIntro\nThe National Water and Climate Center maintains a large database of soil, water, and climate data known as AWDB (air and water database). Use Domo's National Resources Conservation Service Connector to pull data from National Resources Conservation Center API for USA States.\nYou create a National Resources Conservation Service DataSet in the\u00a0Data Center.\nThe National Resources Conservation Service connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking\u00a0Cloud App\u00a0in the toolbar at the top of the window.\nThis topic discusses the fields and menus that are specific to the\u00a0National Resources Conservation Service connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nNone.\nCreating a\u00a0National Resources Conservation Service DataSet\u00a0\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/national_resources_conservation_service_connector/index.html", "title": "National Resources Conservation Service Connector"}, {"objectID": "605f0504c3ca-1", "text": "MenuDescriptionReportSelect the National Resources Conservation Service report you want to run.\u00a0The following reports are available:Central Tendency DataReturns the 30-year central tendency (average or median) value(s) for the current normals period. The method takes a Duration in order to retrieve DAILY, MONTHLY, SEMIMONTHLY, or ANNUAL central tendencies.Central Tendency Peak DataReturns the peak 30-year central tendency (average or median) value(s) for the current normals period. The method takes a Duration in order to retrieve DAILY, MONTHLY, SEMIMONTHLY, or ANNUAL central tendencies.DataReturns an array of Data objects that contain the data values for each station requested. The data will be returned in the same order as the stations requested.Data Inserted Or Updated SinceReturns data (any duration but HOURLY) for one or more stations, for a single element, for a range of dates, but only returns data that has been inserted or modified since some date that the user specifies.ElementsReturns list of Element objects (one for each element defined in the AWDB database).Forecast PeriodsReturns a list of", "source": "../../raw_kb/article/national_resources_conservation_service_connector/index.html", "title": "National Resources Conservation Service Connector"}, {"objectID": "605f0504c3ca-2", "text": "in the AWDB database).Forecast PeriodsReturns a list of all forecast periods defined in the AWDB database.Forecast PointsReturns one or more forecast points using search criteria such as station ids, state codes, network codes, etc. Any of the parameters that take a list can be null if you don\u2019t want to search by that criteria. If any of the parameters that take a list have more than one item, the search will return forecast points that match any of those items.Height DepthsReturns a list of all possible height/depths that are defined in AWDB (returned as a list of HeightDepth objects). Each HeightDepth object consists of a value (positive for a height, and negative for a depth).Hourly DataReturns an array of HourlyData objects that contain the data values for each station requested.Instantaneous DataReturns instantaneous SNOTEL or SCAN data for one or more stations for a single element for a range of dates.Peak DataReturns the annual peak data value for each water year requested, for one or more stations, for a single element. The peak data value is", "source": "../../raw_kb/article/national_resources_conservation_service_connector/index.html", "title": "National Resources Conservation Service Connector"}, {"objectID": "605f0504c3ca-3", "text": "for a single element. The peak data value is the highest value in each water year (if there are multiple values that equal the highest value, the last one is returned).Reservoir Metadata MultipleRetrieves metadata for several reservoir stations in a single call.Station Metadata MultipleReturns a list of StationMetadata objects that contain the station metadata for each station requested. The metadata will be returned in the same order as the stations requested.StationsReturns a list of strings that are the stationTriplets for the stations which match the search criteria passed in.Station ElementsReturns a list of all elements that a station has (or had) data or normals for a specified begin and end date.UnitsReturns a list of all units defined in the AWDB database. Each item in the returned list will be a unit object that contains the unit code and the name (plural name) of the unit.Select StateSelect the state for which you want to fetch the data.Network CodesThe network code of the data to retrieve.Element CodesThe element code of the data to retrieve.DurationThe time span to retrieve the data for.OrdinalEnter", "source": "../../raw_kb/article/national_resources_conservation_service_connector/index.html", "title": "National Resources Conservation Service Connector"}, {"objectID": "605f0504c3ca-4", "text": "retrieve.DurationThe time span to retrieve the data for.OrdinalEnter the number that indicates whether the element is from the primary sensor(1), the secondary sensor(2), and so on.Get FlagsChoose whether you want to retrieve the flags by selecting either of the True or False values.\u00a0If true, flags associated with the report will be retrieved and returned, otherwise the flags won\u2019t be returned.Height Depth ValueEnter the height/depth for the element of the data to retrieve, or null if the element doesn\u2019t have a height/depth. Use default value 0 (Zero) for passing null.Central Tendency TypeSelect the type of central tendency values to retrieve. This can be AVERAGE, MEDIAN or NORMAL; where NORMAL will be the default type for the given station and element.Begin DayThe first day of the first month for which the central tendencies to be retrieved (1-31).Begin MonthThe first month of central tendencies to retrieve.End DayThe last day of the last month for which the central tendencies to be retrieved (1-31).End MonthThe last month of central tendencies to", "source": "../../raw_kb/article/national_resources_conservation_service_connector/index.html", "title": "National Resources Conservation Service Connector"}, {"objectID": "605f0504c3ca-5", "text": "MonthThe last month of central tendencies to retrieve.Begin YearThe first water year for which to get the peak data value.End YearThe last water year for which to get the peak data value.FilterFilter determines which subset of data to retrieve. This can be ALL to get all values, FIRST OF DAY to get only the first value of each day, or MIDNIGHT ONLY to get only the midnight value of each day requested.Unit SystemSelect the unit code that indicates the units of the calculated forecast values and the period average.Insert or Update\u00a0 Begin DateSelect the date selection format to begin the data insert or update.Date (Date Selection)Select the date selection format.Single Date - Specific DateSelect a specific date for which you want fetch the data using the date picker.Single Date - Relative DateSelect or enter the number of days for which\u00a0you would like to receive data back\u00a0from the current date (which you specify in\u00a0Days Back). For example, enter 0 for today, 1 for yesterday, or 7 for 7 days ago.Date RangeSelect the start date and end date between which", "source": "../../raw_kb/article/national_resources_conservation_service_connector/index.html", "title": "National Resources Conservation Service Connector"}, {"objectID": "605f0504c3ca-6", "text": "RangeSelect the start date and end date between which you want the data to be fetched.Start DateSpecify whether the\u00a0start date in your date range is a specific or relative date. Select Specific Date\u00a0if you want to fetch data for a particular\u00a0day\u00a0using the date picker. Select\u00a0Relative\u00a0if you always want the report to retrieve data for a given number of days back\u00a0from the current date (which you specify in\u00a0Days Back).\u00a0If you choose\u00a0Relative\u00a0here, you should also choose\u00a0Relative\u00a0for\u00a0End Date\u00a0and specify\u00a0a value for\u00a0Days Back.", "source": "../../raw_kb/article/national_resources_conservation_service_connector/index.html", "title": "National Resources Conservation Service Connector"}, {"objectID": "605f0504c3ca-7", "text": "For example, if you enter\u00a010\u00a0for\u00a0Days Back in\u00a0Start Date\u00a0and\u00a05\u00a0for\u00a0Days Back in End Date\u00a0and you set the\u00a0DataSet to update\u00a0daily, each new day the report will update to show information for 5 to 10 days in the past.End Date - Specific DateSpecify whether the\u00a0end date in your date range is a specific or relative date.\u00a0Select Specific Date\u00a0if you want to fetch data for a particular\u00a0day\u00a0using the date picker. Select\u00a0Relative\u00a0if you always want the report to retrieve data for a given number of days back\u00a0from the current date (which you specify in\u00a0Days Back).\u00a0If you choose\u00a0Relative\u00a0here, you should also choose\u00a0Relative\u00a0for\u00a0End Date\u00a0and specify\u00a0a value for\u00a0Days Back.\nFor example, if you enter\u00a010\u00a0for\u00a0Days Back in\u00a0Start Date\u00a0and\u00a05\u00a0for\u00a0Days Back in End Date\u00a0and you set the\u00a0DataSet to update\u00a0daily, each new day the report will update to show information for 5 to 10 days in the past.Time PeriodSelect the time period for which you would like to receive data.Starting Day of the WeekSelect whether you want the week to begin by Sunday or Monday while fetching the data.\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding a DataSet Using a Data Connector.", "source": "../../raw_kb/article/national_resources_conservation_service_connector/index.html", "title": "National Resources Conservation Service Connector"}, {"objectID": "2eb12f4f8fc0-0", "text": "TitleNativo ConnectorArticle BodyIntro\nNativo is an advertising platform that promises higher engagement rates for marketers, premium monetization for publishers, and a non-interruptive experience for consumers. You can use Domo's Nativo connector to retrieve Nativo report data such as number of links clicked, video views, impressions, and so on. To learn more about the Nativo API, visit their page at https://admin.nativo.net/docs/reporting.html (credentials are required for access).\nYou connect to your Nativo account in the Data Center. This topic discusses the fields and menus that are specific to the Nativo connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Nativo account and create a DataSet, you must have the following:\nA Nativo public key (token)A Nativo secret\nThese credentials are provided by your Nativo team upon account creation.\nConnecting to Your Nativo Account\nThis section enumerates the options in the Credentials and Details panes in the Nativo Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Nativo account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionTokenEnter your Nativo token (public key).SecretEnter your Nativo secret (private key).\nOnce you have entered valid Nativo credentials, you can use the same account any time you go to create a new Nativo DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane", "source": "../../raw_kb/article/nativo_connector/index.html", "title": "Nativo Connector"}, {"objectID": "2eb12f4f8fc0-1", "text": "Details Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/nativo_connector/index.html", "title": "Nativo Connector"}, {"objectID": "2eb12f4f8fc0-2", "text": "MenuDescriptionReportSelect the Nativo report you want to run.\u00a0The following reports are available:DirectReturns selected campaign and ad metrics from the Nativo Direct Service for a given time period.Managed CampaignReturns selected campaign and ad metrics from the Nativo Managed Campaign Service for a given time period.MarketplaceReturns selected campaign and ad metrics from the Nativo Marketplace Service for a given time period.PreferredReturns selected campaign and ad metrics from the Nativo Preferred Service for a given time period.BreakdownSelect all categories that you want to break down the report data by.MetricsSelect all metrics that you want to appear in your report.Filter BySelect a category to filter the data by. If you select None, no filter is applied (i.e. all available data will be pulled).AdvertisersSelect all advertisers you want to appear in your report.CampaignsSelect all campaigns you want to appear in your report.DevicesEnter a comma-separated list of IDs for devices you want to appear in your report.PublicationsEnter a comma-separated list of IDs for publications you want to appear in your report.PublishersEnter a comma-separated list", "source": "../../raw_kb/article/nativo_connector/index.html", "title": "Nativo Connector"}, {"objectID": "2eb12f4f8fc0-3", "text": "to appear in your report.PublishersEnter a comma-separated list of IDs for publishers you want to appear in your report.ResolutionSelect whether you want to show data by hour, by day, or totals.Time ZoneSelect the time zone for your report data (the default is UTC).Duration\u00a0Select whether you want to pull data for a specific date or a date range.\u00a0Report Date\u00a0Select whether the report data is for a specific date or for a relative number of days back from today.\u00a0Select Specific Date\u00a0Select the date for the report.\u00a0Days BackEnter the number of past days that should appear in the report.\u00a0\u00a0Start DateSpecify whether the\u00a0first date in your date range is a specific or relative date.\u00a0You select the last date in your range in\u00a0End Date.\u00a0End DateSpecify whether the second date in your date range is a specific or relative date. You select the first date in your range in\u00a0Start Date.\u00a0\u00a0Select Specific Start DateSelect\u00a0the first date in your date range.\u00a0Select Specific End DateSelect the second date in your date range.\u00a0Days Back to Start FromEnter the", "source": "../../raw_kb/article/nativo_connector/index.html", "title": "Nativo Connector"}, {"objectID": "2eb12f4f8fc0-4", "text": "your date range.\u00a0Days Back to Start FromEnter the number of the farthest day back that should be represented in the report. Combine with\u00a0Days Back to End At\u00a0to create a range of represented days.", "source": "../../raw_kb/article/nativo_connector/index.html", "title": "Nativo Connector"}, {"objectID": "2eb12f4f8fc0-5", "text": "For example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Days Back to End AtEnter the number of the most recent day back that should be represented in the report. Combine with\u00a0Days Back to Start From\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/nativo_connector/index.html", "title": "Nativo Connector"}, {"objectID": "23afce2e8644-0", "text": "TitleNeo4j ConnectorArticle BodyIntro\nNeo4j is a graph database that stores nodes, relationships, and their respective properties. Some of the business use cases for using Neo4j include but are not limited to recommendation engines, detecting financial fraud, and researching rare diseases.\nYou can use the Cypher language to use query in Neo4j. Cypher is a declarative query language that provides a visual and logical way to match node and relationships. To learn more about cypher and its syntax, you can visit https://neo4j.com/developer/cypher/.\nThis topic discusses the fields and menus that are specific to the Neo4j \u00a0 Connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to a Neo4j graph, your database must have the following:\nAvailable over the internetSSL enabled over HTTPSEnable HTTP setting in instance configuration file (dbms.connector.http.enabled=true)Whitelist Domo's IP addresses that can be found at Whitelisting IP addresses for connectorsA service account with minimum Read access\nConnecting to Your Neo4j graph\nThis section enumerates the options in the Credentials and Details panes in the Neo4j Connector page. The components of the other panes in this page, Scheduling and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Neo4j graph. The following table describes what is needed for each field:\nFieldDescriptionNeo4j Instance URLEnter the URL of your instance.\nExample: neo4j.database.url\u00a0or graph.site.com:7473.\n\n\n\u00a0\n\nNote: Include port number if applicable. The default port is 7473\u00a0for Neo4j.", "source": "../../raw_kb/article/neo4j_connector/index.html", "title": "Neo4j Connector"}, {"objectID": "23afce2e8644-1", "text": "Neo4j Database NameEnter the name of your database.UsernameEnter the username for your database.PasswordEnter the password for your database.\nOnce you have entered valid credentials, you can use the same account any time you go to create a new Neo4j DataSet. You can manage Connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis is where you will insert your Cypher query. Note that this query must return properties, not nodes.\nMenuDescriptionQueryEnter your Cypher query.\nExample:MATCH (p:Person)-[:BUYS]->(i:Item)\u00a0 \u00a0 \u00a0 \u00a0RETURN p.name as Name,i.type as ItemTypeMATCH (a:Actor)-[:PRODUCES]->(m:Movie)<-[:DIRECTS]-(d:Director)\u00a0 \u00a0 \u00a0 \u00a0RETURN a.name as ActorName, a.DOB as DOB,m.title as MovieTitle,d.name as DirectorName\nOther Panes\nFor information about the remaining sections of the Connector interface, including how to configure scheduling, retry, and update options, see Adding a DataSet Using a Data Connector.\nFAQs\nWhat kind of data can I get from the Neo4j Connector?\nYou can access Neo4j Graph database data with this connector, represented as a table.\nWhat credentials do I need to access the Neo4j Connector?\nThis connector leverages the Neo4j Bolt REST api hyperlink and requires the associated username and password.\nHow often is the Neo4j data updated?\nThe Neo4j data can be updated as often as needed based on the options available in the Domo connector UI.\nCan I see an example of the Cypher syntax required to return a table from graph data?\nThe Cypher query needs to return properties as opposed to nodes, for example:", "source": "../../raw_kb/article/neo4j_connector/index.html", "title": "Neo4j Connector"}, {"objectID": "23afce2e8644-2", "text": "The Cypher query needs to return properties as opposed to nodes, for example:\nMATCH (p:Person)-[r:IS_IN_CHARGE_OF]->(c:Project)\nRETURN p.name as Person, c.name as Project", "source": "../../raw_kb/article/neo4j_connector/index.html", "title": "Neo4j Connector"}, {"objectID": "ac16b67ad3f2-0", "text": "Title\n\nNested Bar Chart\n\nArticle Body\n\nIntro\n\nIn a nested bar chart, the total values for all categories are represented as gray bars, and the values for all series are represented as smaller, colored bars and are shown side-by-side or stacked on top of each other within the bars for their respective categories. Vertical and horizontal subtypes are available for nested bar charts.\nDomo also includes a version of the nested bar chart with trendlines for comparison. For more information, see\u00a0Nested bar with line chart.\nPowering nested bar charts\nA nested bar chart requires three columns or rows of data from your DataSet\u2014one for categories, one for the series in each category, and one for values. For information about value, category, and series data, see Understanding Chart Data.\nIn the Analyzer, you choose the columns containing the data for your nested bar chart. For more information about choosing data columns, see\u00a0Applying DataSet Columns to Your Chart.\nFor more information about formatting charts in the Analyzer, see\u00a0KPI Card Building Part 2: The Analyzer.\nThe following graphic shows you how the data from a typical column-based spreadsheet is converted into a vertical nested bar chart:\n\nThe following graphic shows you how the data from the same column-based spreadsheet is converted into a horizontal nested bar chart:", "source": "../../raw_kb/article/nested_bar_chart/index.html", "title": "Nested Bar Chart"}, {"objectID": "ac16b67ad3f2-1", "text": "Customizing nested bar charts\nYou can customize the appearance of a nested bar chart by editing its Chart Properties. For information about all chart properties, see Chart Properties. Unique properties of nested bar charts include the following. You can click a thumbnail image to see a larger image.\nPropertyDescriptionExampleGeneral > Sort Each CategoryAllows you to sort the items in each individual category in most kinds of multi-series bar and lollipop charts. You can choose an ascending or descending sort. If you select\u00a0Default, the default sort is applied. This option does not work when the\u00a0Value Scale > Log Scale\u00a0box is checked.\nIn the example at right, bars within all categories are sorted in descending order.\u00a0General > Sort on TotalsAllows you to sort categories in many kinds of bar and lollipop charts by their total values, in either ascending or descending order. If you select\u00a0Default, the default sort is applied. This option does not work when the chart has automatic time scaling applied. (You can turn off automatic time scaling by checking the box for\u00a0Category Scale > Never Use Time Scale.\nIn the example at right, the categories are sorted by their totals in ascending order.General > Maximum BarsAllows you to specify the number of bars that appear in your bar chart. Data for all remaining bars is lumped into a single \"Other\" bar (unless you hide this bar using the\u00a0Hide 'Other' Bar\u00a0toggle.", "source": "../../raw_kb/article/nested_bar_chart/index.html", "title": "Nested Bar Chart"}, {"objectID": "ac16b67ad3f2-2", "text": "The example at right shows a bar chart in which the maximum number of bars\u00a0has been set to 7.General > Hide 'Other' BarsHides or shows the \"Other\" bar that appears when you set a maximum number of bars using the\u00a0Maximum Bars\u00a0option.\u2014General > Group Legend TextLets you specify the legend text for the \"group bars\" (the vertical gray bars that show the totals for each category). In the example, the default group bar legend text has been replaced with the words \"Grand Total.\"General > Hide Group in LegendHides the legend text for the \"group bars\" (the vertical gray bars that show the total for each category.\u2014Data Label Settings > \u00a0Show Group TotalDetermines whether data labels appear over the gray \"total\" bars in nested bar charts. The chart at right shows an example of this.", "source": "../../raw_kb/article/nested_bar_chart/index.html", "title": "Nested Bar Chart"}, {"objectID": "d90945a91e36-0", "text": "Title\n\nNested Bar with Line Chart\n\nArticle Body\n\nIntro\n\nA nested bar with line chart is a combination of a Chart Properties). The line and gray total bars are measured on the left vertical axis, and the colored series bars are measured on the right axis.\u00a0\nPowering nested bar with line charts\nNested bar with line charts require three columns or rows of data from your DataSet\u2014one for series, one for categories, and one for values. For information about value, category, and series data, see Understanding Chart Data.\nIn the Analyzer, you choose the columns containing the data for your nested bar with line chart. For more information about choosing data columns, see\u00a0Applying DataSet Columns to Your Chart.\nFor more information about formatting charts in the Analyzer, see\u00a0KPI Card Building Part 2: The Analyzer.\nThe following graphic shows you how data from a typical column-based spreadsheet is converted into a nested bar with line chart:", "source": "../../raw_kb/article/nested_bar_with_line_chart/index.html", "title": "Nested Bar with Line Chart"}, {"objectID": "d90945a91e36-1", "text": "Customizing nested bar with line charts\nYou can customize the appearance of a nested bar with line chart by editing its Chart Properties and by changing the sorting, scale syncing, and number formatting.\nChart Properties\nUnique Chart Properties of nested bar with line charts include the following. You can click a thumbnail image to see a larger image.\nFor information about all Chart Properties, see\u00a0Chart Properties.\nPropertyDescriptionExampleGeneral > Series on Left ScaleDetermines how many series in your chart appear as lines. By default, the first series that appears in your legend for these chart types becomes a line, and all remaining series become bars. However, you can convert series from bars to lines by entering the desired number of lines here. For example, if your chart had three series, the first series appearing in your legend would appear as a line, and the remaining two series would appear as bars. You could turn the second series into a line by entering 2 in the Series on Left Scale field.\u2014General > Sort Each CategoryAllows you to sort the items in each individual category in most kinds of multi-series bar and lollipop charts. You can choose an ascending or descending sort. If you select\u00a0Default, the default sort is applied. This option does not work when the\u00a0Value Scale > Log Scale\u00a0box is checked.\nIn the example at right, bars within all categories are sorted in descending order.\u00a0Data Label Settings > \u00a0Show Group TotalDetermines whether data labels appear over the gray \"total\" bars in nested bar charts. The chart at right shows an example of this.\nSorting\nYou can manipulate which series becomes lines and bars in a nested bar with line chart by changing the series order in your legend. By default, the sort method is set to No Sorting, which arranges your series in alphabetical order. For most charts with both lines and bars, this is not the optimal sort method. For the best results, do the following:", "source": "../../raw_kb/article/nested_bar_with_line_chart/index.html", "title": "Nested Bar with Line Chart"}, {"objectID": "d90945a91e36-2", "text": "Ensure that the series that should correspond to the line appears first in your DataSetChoose an item-based sorting method, either ascending or descending\nBecause item-based sorting sorts the items in the DataSet alphabetically by category, with the series items in each category appearing in the same order that they appear in the spreadsheet, the first series in your DataSet becomes the line. For more information about sorting, see\u00a0Sorting the Data in Your Chart.\nChanging scale formatting\nIt is possible to have separate number formatting for both vertical axes in a\u00a0 nested bar with line chart. For example, you could have percent symbols affixed to the values in one axis and currency symbols affixed to the values in the other. You can do this in the Format menus or the Chart Properties. Domo recommends that you use Chart Properties to make formatting changes, not the Format menus, because the options in the Format menus are overridden by formatting changes in Chart Properties. For more information about formatting numbers, see\u00a0Formatting Values in Your Chart.", "source": "../../raw_kb/article/nested_bar_with_line_chart/index.html", "title": "Nested Bar with Line Chart"}, {"objectID": "1f7f82851d62-0", "text": "Title\n\nNetatmo Connector\n\nArticle Body\n\nIntro\nNetatmo provides online interfaces and APIs for interacting with and managing its internet-connected devices, such as cameras, thermostats and weather stations. Use Domo's Netatmo connector to retrieve public weather data, device listings, and so on. To learn more about the Netatmo API, visit their page (https://dev.netatmo.com/).\nYou connect to your Netatmo account in the Data Center. This topic discusses the fields and menus that are specific to the Netatmo connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Netatmo account and create a DataSet, you must have a Netatmo username and password.\nConnecting to Your Netatmo Account\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the Netatmo Connector page.\u00a0The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThe Domo Netatmo connector uses OAuth to connect, so there is no need to enter credentials within Domo. Click\u00a0Connect\u00a0(or select\u00a0Add Account\u00a0if\u00a0you have\u00a0existing Netatmo accounts in Domo) to open the Netatmo OAuth screen where you can enter your Netatmo username and password. Once you have entered valid Netatmo credentials, you can use the same account any time you go to create a new Netatmo DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see\u00a0Managing User Accounts for Connectors.", "source": "../../raw_kb/article/netatmo_connector/index.html", "title": "Netatmo Connector"}, {"objectID": "1f7f82851d62-1", "text": "Note:\u00a0If you are already logged into Netatmo when you connect in Domo, you are authenticated automatically when you click Add account. If you want to connect to an account that is different from the one you are logged into, you must first log out of Netatmo.", "source": "../../raw_kb/article/netatmo_connector/index.html", "title": "Netatmo Connector"}, {"objectID": "1f7f82851d62-2", "text": "Details Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.\nMenuDescriptionReportSelect the Netatmo report you want to run.\u00a0The following reports are available:Enterprise - Partner DevicesRetrieves a list of devices associated with your Enterprise application.MeasurementsRetrieves selected measurements for weather station or thermostat devices or modules.Weather - Public DataReturns public weather data for a geographic area between the given northeast and southwest coordinate.Weather Stations - DataReturns data from your weather station device(s).Welcome - Home DataReturns information about users' homes and cameras.Welcome - Home Data - CamerasReturns home data, including a list of cameras.Welcome - Home Data - PersonsReturns home data, including a list of persons.DeviceSelect the ID of the device you want to retrieve data for.Scale (Aggregation)Select how you want your report data to be aggregated.Duration\u00a0Select whether you want to pull data for a specific date or a date range.\u00a0Report Date\u00a0Select whether the report data is for a specific date or for a relative number of days back from today.\u00a0Select Specific Date\u00a0Select the date for the report.\u00a0Days BackEnter the number of past days that should appear in the report.\u00a0\u00a0Start DateSpecify whether the\u00a0first date in your date range is a specific or relative date.\u00a0You select the last date in your range in\u00a0End Date.\u00a0End DateSpecify whether the second date in your date range is a specific or relative date. You select the first date in your range in\u00a0Start Date.\u00a0\u00a0Select Specific Start DateSelect\u00a0the first date in your date range.\u00a0Select Specific End DateSelect the second date in your date range.\u00a0Days Back to Start FromEnter the number of the farthest day back that should be represented in the report. Combine with\u00a0Days Back to End At\u00a0to create a range of represented days.", "source": "../../raw_kb/article/netatmo_connector/index.html", "title": "Netatmo Connector"}, {"objectID": "1f7f82851d62-3", "text": "For example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Days Back to End AtEnter the number of the most recent day back that should be represented in the report. Combine with\u00a0Days Back to Start From\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Latitude NortheastEnter the latitude of the northeast corner of the requested area. This should be an integer between -85 and 85 degrees.Longitude NortheastEnter the longitude of the northeast corner of the requested area. This should be an integer between -180 and 180 degrees.Latitude SouthwestEnter the latitude of the southwest corner of the requested area. This should be an integer between -85 and 85 degrees.Longitude SouthwestEnter the longitude of the southwest corner of the requested area. This should be an integer between -180 and 180 degrees.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/netatmo_connector/index.html", "title": "Netatmo Connector"}, {"objectID": "dca7be052b75-0", "text": "Title\n\nNetbase Connector\n\nArticle Body", "source": "../../raw_kb/article/netbase_connector/index.html", "title": "Netbase Connector"}, {"objectID": "dca7be052b75-1", "text": "Intro\nThe NetBase Insight API enables you to search the ConsumerBase index, which contains billions of insight-rich sound bites (sentences), based on the focus of your analysis. Retrieve data to use as input for visualizations in your websites and applications. The Insight API returns metric values, sentiment classifications, emotions, behaviors, and attributes for objects, named entities, and more. You can use the Insight API to integrate social media data and metrics in your web sites and applications. To learn more about the Netbase API, visit their page (http://learn.netbase.com/i/706080-ne...ming-interface).\nYou connect to your Netbase account in the Data Center. This topic discusses the fields and menus that are specific to the Netbase connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrimary Use CasesViewing the ranking of insight categoriesGetting an overview of how your brands are being receivedPrimary MetricsSound bites containing a specified insight typeTotal buzzNet sentimentPassion intensityPrimary Company RolesSocial media strategistsPublic relations peopleAverage Implementation Time1 hourEase of Use (on a 1-to-10 scale with 1 being easiest)4 (user should have some knowledge of Netbase)\nBest Practices\nBe aware that time zones using this connector are determined by UTC.\nPrerequisites\nTo connect to your Netbase account and create a DataSet, you must a Netbase username and password.\nConnecting to Your Netbase Account\nThis section enumerates the options in the\u00a0 Credentials \u00a0and\u00a0 Details \u00a0panes in the Netbase Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane", "source": "../../raw_kb/article/netbase_connector/index.html", "title": "Netbase Connector"}, {"objectID": "dca7be052b75-2", "text": "Credentials Pane\nThis pane contains fields for entering credentials to connect to your Netbase account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionUsernameEnter the username for your Netbase account.PasswordEnter the password for your Netbase account.\nOnce you have entered valid Netbase credentials, you can use the same account any time you go to create a new Netbase DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports menu, along with a number of other menus for filtering the report data.\nMenuDescriptionReportSelect the Netbase report you want to run.\u00a0The following reports are available:Metric ValueReturns one or more metric values for a time period or time series. You can retrieve metrics such as total buzz, net sentiment, or passion intensity, for a topic.Insight CountReturns the number of sound bites (mentions) containing a specified insight type, such as an emotion or a behavior.Cross TabulationReturns a specified metric value for one or more topics distributed across one or more themes.Retrieve DocumentsReturns a list of documents matching the Insight API call, including: Metadata for a document, including its insights and sentiment classification.The text for each matching sound bite in a document, including the two sentences that occur before and after the matching sentences.", "source": "../../raw_kb/article/netbase_connector/index.html", "title": "Netbase Connector"}, {"objectID": "dca7be052b75-3", "text": "Note:  Some content providers, such as Twitter, prohibit the download of sound bite text and author details.", "source": "../../raw_kb/article/netbase_connector/index.html", "title": "Netbase Connector"}, {"objectID": "dca7be052b75-4", "text": "The total document countThemesReturns a list of themes filtered by scopeTopicsReturns a list of topics filtered by scope and content type.Topic ScopeSelect the category of topics you want to be able to pull data for.Theme ScopeSelect the category of themes you want to be able to pull data for.TopicsSelect the topic you want to pull data for.Theme FiltersSelect the themes you want to pull data for (up to 50).Time PeriodEnter the time period for the data you want to return. This should be in the format {time period},{time offset},{time rounding}.\u00a0\nThe following table lists different examples of how to set this parameter:No entryOne week of data ending a minute ago5dFive days of data ending a minute ago6d,1dSix days of data ending last midnight UTC10d,1h,1hTen days of data ending at least an hour ago, on the hour2016-05-22Data between May 22 and now2016-05-22 06:00, 2016-05-30 07:00Data between 6AM UTC May 22 and 7AM UTC May 30Size NeededSpecifies the number of Documents or Insights to be returned. Maximum value for Documents: 2000. Maximum value for Insight Count: 1000 Note only numeric values are valid.Peer CountThe peerCount specifies the number of sentences to return before and after a matching sentence. Default is 2.SortThe sort parameter specifies the sort order for the top sound bites that the Insight API returns in the call. The Insight API sorts to the precision of Deci\u00a0seconds. \nTo sort in ascending order: sort=sort_option.", "source": "../../raw_kb/article/netbase_connector/index.html", "title": "Netbase Connector"}, {"objectID": "dca7be052b75-5", "text": "To sort in descending order: sort_option where sort_option is one of the following:\u00a0confidenceScore\u00a0sorts results by a metric that indicates a sound bite's spaminess. It is primarily for internal NetBase use. A lower score indicates that a sound bite is less spammy than a sound bite with a higher score.\u00a0timestamp\u00a0sorts results by the date/time data was published to the Internet.\u00a0alertTimestamp sorts results by the date/time data was indexed into the ConsumerBase system. To sort results in descending order, preface the parameter with a hyphen (-). To sort in ascending order, do not include the hyphen.Time UnitsSelect the time unit that the data in the report should be broken down by. For example, if you select Month, twelve rows of data appear, one for each month in the year.Metric SeriesSelect the metric series you want to filter by. You can select as many metric IDs as you want.AuthorsThe authors parameter specifies an author whose documents to include in the analysis. This value will be overwritten if an 'authors' value is provided in the", "source": "../../raw_kb/article/netbase_connector/index.html", "title": "Netbase Connector"}, {"objectID": "dca7be052b75-6", "text": "overwritten if an 'authors' value is provided in the text area. Specifying this parameter excludes documents published by all other authors.syntax:author_name:domain_nameDo not include '@', 'https://'; or 'www.'DomainsThe domains parameter specifies a domain from which data should be included in the analysis. This value will be overwritten if a 'domains' value is provided in the text area. Specifying this parameter excludes documents from all other domains.Note:The Insight API supports specifying subdomains and folders, such as http://facebook.com/TheSmokingTire/.KeywordsThe keywords parameters specifies keywords for filtering results. These parameters match both of the following:Sentences containing the keyword, along with their preceding and succeeding sentences.All sentences in documents whose title contains the specified keyword.SentimentsThe sentiments parameter retrieves only data that NetBase has classified with a specified sentiment type. This value will be overwritten if a 'sentiments' value is provided in the text area.SourcesThe sources parameter enables you to filter results by source type. If specified, the Insight API only returns data from the specified source", "source": "../../raw_kb/article/netbase_connector/index.html", "title": "Netbase Connector"}, {"objectID": "dca7be052b75-7", "text": "the Insight API only returns data from the specified source type. This value will be overwritten if a 'sources' value is provided in the text area.Additional Optional ParametersSelect the optional parameters you want to filter by. You can select as many optional parameters as you want.", "source": "../../raw_kb/article/netbase_connector/index.html", "title": "Netbase Connector"}, {"objectID": "dca7be052b75-8", "text": "For in-depth documentation on optional parameters, see https://api.netbase.com/explorer/api/netbase.Theme ArraySelect up to 50 theme arrays. A theme array is a theme you can use to further drill down into your data set. You must define themes in a NetBase application before you can use them in Domo.Size NeededSpecifies the number of documents or insights to be returned. The maximum number of documents that may be returned is 2000, and the maximum number of insights is 1000. Only numeric values are valid.Peer CountSpecifies the number of sentences to return before and after a matching sentence. The default is 2.CategoriesSelect the categories you want to filter by. You can select as many categories as you want.MeasureSelect the measure parameter for the report.Mentions returns the number of matching sentences for the Categories value. For example, if you selected Sentiment for the category, your report would return the number of sentences for each sentiment classification found by the query.Posts returns the number of matching documents for the Categories value. For example, if you selected Geolocation for the category, your report would return the number of matching documents for each geolocation found by the query.Followers returns the number of followers when when the selected Categories value is Authors. You cannot use Followers with any other category value. A follower count is the number of users following an author at the moment they publish a document.Content TypeSelect to filter topics by content type.\n\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding a DataSet Using a Data Connector.\nTroubleshooting\nIf the connection fails, check the error message. It may contain information concerning an illegal configuration that NetBase does not allow. For example, when running the Insight Count report,\u00a0 if you select Followers for your Measure, selecting any category but Authors will return an error.", "source": "../../raw_kb/article/netbase_connector/index.html", "title": "Netbase Connector"}, {"objectID": "b6f87e5f712c-0", "text": "TitleNetSuite App TBA ConnectorArticle BodyIntro\nThis version of the NetSuite connector uses NetSuite's SuiteScript 2.0 as well as token-based authentication (TBA). Use this version of the connector if you want to effectively gather all of your NetSuite data as securely as possible.\u00a0\nYou connect to NetSuite\u00a0in the Data Center. This topic discusses the fields and menus that are specific to the NetSuite App TBA\u00a0connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your NetSuite account and create a DataSet using this connector, you must have the following:\nAn installed \"Domo Data Connection 2.0\" NetSuite bundleA NetSuite token ID and token secretA NetSuite account IDA NetSuite script bundle and deploy bundle IDA NetSuite report ID\nEach of these items is discussed in more detail in the next two sections.\nInstalling the NetSuite Bundle\nBefore you can connect to NetSuite\u00a0data using this connector, you must first install the Domo Data Connection 2.0 bundle from NetSuite.\nTo install the bundle,\nIn NetSuite, select\u00a0Customization > SuiteBundler > Search & Install Bundles.\u00a0In the\u00a0Keywords\u00a0section, search for \"Domo.\"Click the search result for \"Domo Data Connection 2.0.\"Click\u00a0Install.Select\u00a0Customization > SuiteBundler\u00a0> Search & Install Bundles > List.Locate \"Domo Data Connection 2.0\" in the list.Make sure the install status is complete, indicated by a green checkmark.\u00a0\nConnecting to Your NetSuite Data in Domo", "source": "../../raw_kb/article/netsuite_app_tba_connector/index.html", "title": "NetSuite App TBA Connector"}, {"objectID": "b6f87e5f712c-1", "text": "Connecting to Your NetSuite Data in Domo\nThis section enumerates the options in the Credentials and Details panes in the NetSuite App TBA Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for to connecting to your NetSuite account. Each connection option is discussed in detail in continuation.\u00a0\nOnce you have connected to NetSuite, you can use the same account any time you go to create a new NetSuite App TBA DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nChoosing Your Environment\nIn the\u00a0Environment\u00a0menu, select\u00a0Sandbox if your Netsuite\u00a0account is a sandbox account. You can find this by hovering over your name/account in the top right corner of NetSuite and clicking View all roles.\u00a0Your environment should be listed under Account Type.\nObtaining Your Token ID and Token Secret\nTo create a Token and ID and Token Secret,\nIn NetSuite, choose the role you want to access data in.Go to your main page by clicking the house icon in the top left corner of the screen.In the\u00a0Settings\u00a0box in the bottom left corner, click\u00a0Manage Access Tokens.", "source": "../../raw_kb/article/netsuite_app_tba_connector/index.html", "title": "NetSuite App TBA Connector"}, {"objectID": "b6f87e5f712c-2", "text": "Note: If you have not configured your\u00a0role to use access tokens, you will not see the\u00a0Manage Access Tokens\u00a0link. To enable access tokens for your role, do the following:\u00a0 \nNavigate to Setup > Company > Enable Features, then open the SuiteCloud tab.Under Manage Authentication, enable Token-Based Authentication.", "source": "../../raw_kb/article/netsuite_app_tba_connector/index.html", "title": "NetSuite App TBA Connector"}, {"objectID": "b6f87e5f712c-3", "text": "Click\u00a0New Access Token\u00a0and choose \"Domo Data Connection 2.0.\"Choose a token name.Click\u00a0Save.Your Token ID and Token Secret should appear under the other information.Store the newly generated credentials securely (they will not be shown again).\nFinding Your Account ID\nTo find your account ID, select\u00a0Setup > Integration > Web Services Preferences\u00a0in NetSuite.Your account ID will be located under \"Primary  .\"\nFinding Your Script ID and Deploy ID\nTo find your script ID,\nIn Netsuite, select\u00a0Customization > Scripting > Scripts.\u00a0\u00a0Click on Domo Data Connection 2.0.The script ID is found under ID in the form: customscriptXXXX. Note that, you need to enter the entire script id, including the word \"customscript\" as well.\n \nTo find your deploy ID,\nTo obtain the deployment id, the script must first be deployed. To do this, click the Deploy Script box.Go to Customization -> Scripting -> Script Deployments.\u00a0Now, find the Domo Data Connection 2.0 script.\u00a0The deployment ID is found under ID in the form customdeployX. Note that you need to provide the entire deployment id, including the word \"customdeploy\" as well.\n \nDetails Pane\nThis pane contains a single\u00a0Report\u00a0menu in which you enter the ID for the NetSuite saved search you want to pull into Domo.\u00a0\nThe NetSuite App TBA connector only pulls in data from saved searches.\u00a0\nTo find the report ID for a saved search,\nIn Netsuite, select\u00a0Reports > Saved Searches > All Saved Searches.Locate the report you want to pull data from.Copy the ID found in the\u00a0ID\u00a0column corresponding to the saved search you want.This will be in the form customsearchXXXX , where XXXX is the report ID.", "source": "../../raw_kb/article/netsuite_app_tba_connector/index.html", "title": "NetSuite App TBA Connector"}, {"objectID": "b6f87e5f712c-4", "text": "Tip:\u00a0If the ID from the ID column does not work, click\u00a0View\u00a0and use the saved search ID in the URL.", "source": "../../raw_kb/article/netsuite_app_tba_connector/index.html", "title": "NetSuite App TBA Connector"}, {"objectID": "b6f87e5f712c-5", "text": "MenuDescriptionSaved Searched IDPlease provide the custom search ID for the NetSuite saved search you wish to run.Search TypeSelect the Search Type. If you wish to have no search type, select the blank option at the top and click save.Date FormatSelect the date format.Duplicate Row HandlingSelect an option to keep or remove duplicate rows from your data.Use SQLLite to Prevent duplicate records caused by modifying data during the connector runCheck this box to remove duplicate records, bringing in only the most recently modified data. These duplicates are caused if your data is modified while the connector is running. Duplicates are removed using an SQLite query that keeps the most recently modified row selected by the [row id].Checking this box will slow your connector run, so use this feature only when necessary. It only works when you select the update method as\u00a0Merge.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nFAQ\nWhy do I need a script ID?\nNetSuite requires a script to access their information (through Saved Searches). Domo's NetSuite App TBA connector interacts with this script to get your data.\nWhat is the difference between this connector and other NetSuite connectors?\nNetSuite App TBA uses the new version of the NetSuite API, which supports many new features. While this connector uses some of these new features to more efficiently provide data, it has the same functionality as the other NetSuite connectors.\nHow do I know my NetSuite data is being accessed securely?\nThe NetSuiteAppTBA uses token-based authentication, so Domo never sees your actual credentials. Your token can be revoked at any time through the NetSuite UI.\nHow do I know which NetSuite role the connector is using?", "source": "../../raw_kb/article/netsuite_app_tba_connector/index.html", "title": "NetSuite App TBA Connector"}, {"objectID": "b6f87e5f712c-6", "text": "How do I know which NetSuite role the connector is using?\nNetSuite roles are attached to the tokens you create. To use a different role in the NetSuite connector, you must create a new token in the role you desire. To do so...\u00a0\u00a0\u00a0\nHover over your name in the top right corner, then\u00a0choose the role you wish to use from the dropdown.Follow the directions to create a token in this role.", "source": "../../raw_kb/article/netsuite_app_tba_connector/index.html", "title": "NetSuite App TBA Connector"}, {"objectID": "b6f87e5f712c-7", "text": "Note:\u00a0All roles may not have the ability to create access tokens.", "source": "../../raw_kb/article/netsuite_app_tba_connector/index.html", "title": "NetSuite App TBA Connector"}, {"objectID": "9515e6b943a8-0", "text": "TitleNetSuite ConnectorArticle BodyIntro\nNetSuite allows for data to be extracted via REST in JSON formats by accessing the endpoints as detailed below. The Domo connector expects JSON format, so all endpoints must include a parameter of format=JSON. The Domo Bundle uses the SuiteScript API (which is JavaScript-based) to extract data from Netsuite.\nThe connector has two components:\nThe Domo Bundle running inside your NetSuite instanceThe connector code running in Domo\nPrimary Use CasesThis connector is great for extracting REST data in JSON format.Primary Company RolesMost appropriate for ERP/finance roles.Average Implementation Time4-8 hoursEase of Use (on a 1-to-10 scale with 1 being easiest)8\nPrerequisites\nTo connect to your NetSuite account and create a DataSet using this connector, you must have the following:\nYour NetSuite username and passwordYour NetSuite Role ID (only required if no default role is specified or if you do not want to use the default role)A NetSuite account IDA NetSuite script bundle and deploy bundle IDA NetSuite report ID\nEach of these items is discussed in more detail in the next sections.\nConfiguration Instructions", "source": "../../raw_kb/article/netsuite_connector/index.html", "title": "NetSuite Connector"}, {"objectID": "9515e6b943a8-1", "text": "Each of these items is discussed in more detail in the next sections.\nConfiguration Instructions\nDownload the following SuiteScript files.EC_Libs-4.0.0.jsEC_RestletDataExtractor.jsIn NetSuite, go to Documents > Files > File Cabinet.Create a new folder inside the SuiteScripts folder named \"Domo.\"Upload the two files (EC_Libs-4.0.0.js and EC_RestletDataExtractor.js).Go to Customization > Scripting > Scripts.Under\u00a0File, search for and then select the script file (EC_RestletDataExtractor.js).A form now opens in which you can create the restlet.Fill out the form with the recommendations below (case-sensitive):Name = Domo Data ConnectionID = _domo_data_extractorScript File = EC_RestletDataExtractor.jsGET Function = EC.getLibrary Script File = EC_Libs-4.0.0.jsClick Save and Deploy.You will now be taken to the Script Deployment center.For the Deployment ID, enter _domo_deployment.For the Status, select Released and leave the Log Level at Debug.For the Audience, please check Select All for Roles, Employees, and Partners.Ensure the Deployed checkbox is checked.Save and deploy the script.After the script is deployed it will present you with the Script Deployment status screen.Copy the External URL link for use in the next step.Once you complete the installation in the NetSuite instance, you will need to make the connection in your Domo instance.\nConnecting to Your NetSuite Data in Domo\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the NetSuiteApp Connector page. The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane", "source": "../../raw_kb/article/netsuite_connector/index.html", "title": "NetSuite Connector"}, {"objectID": "9515e6b943a8-2", "text": "Credentials Pane\nThis pane contains fields for to connecting to your NetSuite account. Each connection option is discussed in detail in continuation.\u00a0\nOnce you have connected to NetSuite, you can use the same account any time you go to create a new NetSuiteApp DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the Data Center. For more information about this tab, see\u00a0Managing User Accounts for Connectors.\nFieldDescriptionEnvironmentSelect the environment (Production or Sandbox).UsernameEnter your NetSuite username.PasswordEnter your NetSuite password.Role IDEnter your NetSuite Role ID. It's only required if no default role is specified or if you do not want to use the default role.Account IDEnter your NetSuite account ID.NetSuite Script Bundle IDEnter the script variable from the NetSuite bundle URL.NetSuite Deploy Bundle IDEnter the deploy variable from the NetSuite bundle URL.\nChoosing Your Environment\nIn the\u00a0Environment\u00a0menu, select\u00a0Sandbox\u00a0if your NetSuite account is a sandbox account. You can find this by hovering over your name/account in the top right corner of NetSuite and clicking\u00a0View all roles.\u00a0Your environment should be listed under\u00a0Account Type.\nFinding Your Account ID\nTo find your account ID, select\u00a0Setup > Integration > Web Services Preferences\u00a0in NetSuite.", "source": "../../raw_kb/article/netsuite_connector/index.html", "title": "NetSuite Connector"}, {"objectID": "9515e6b943a8-3", "text": "Your account ID will be located under \"Primary  .\"\n\nFinding Your Script ID and Deploy ID\nTo find your script ID and deploy ID,\n1. In NetSuite, select Customization > Scripting > Scripts.\u00a0\u00a0\n2. Locate \"Domo Data Connection\" either by scrolling through the results or typing \"netsuite.js\" in the Script File\u00a0box at the top.\n\n3. Click Deploy Script\u00a0and follow instructions to get to the Script Deployment page. The External URL on this page will provide the script and deploy ID where the Script ID is the XXXX in 'script=XXXX' and the Deploy ID is the X in 'deploy=X'.", "source": "../../raw_kb/article/netsuite_connector/index.html", "title": "NetSuite Connector"}, {"objectID": "9515e6b943a8-4", "text": "Once you have established the connection to NetSuite, you can now create DataSets from Saved Searches.\nDetails Pane\nThis pane contains a single\u00a0Report\u00a0menu in which you enter the ID for the NetSuite saved search you want to pull into Domo.\u00a0\nMenuDescriptionSaved Search IDEnter the NetSuite Saved Search you want to run.\nExample: For customsearch776, you would only enter 776.Date FromSelect the report date using relative or specific dates. Relative meaning number of days from today or a specific date using the date selector.Date From OffsetThis adjusts the current date to the given number of days into the past. Example: 0 for today, 1 for yesterday.Select Specific Date FromSelect the report date using the date picker. This option is only available when Report Date is set to 'Specific.'Date ToSelect report date using relative or specific dates. Relative meaning number of days from today or a specific date using the date selector.Date To OffsetThis adjusts the current date the given number of days into the past. Example: 0 for today, 1 for yesterday.Select Specific Date ToSelect the report date using the date picker. This option is only available when Report Date is set to 'Specific.'Duplicate Row HandlingSelect\u00a0Remove Duplicate Rows\u00a0to remove duplicate rows in your dataset.Select\u00a0Keep Duplicate Rows\u00a0to keep duplicate rows in your dataset.Big Number HandlingSelect\u00a0Treat Big Numbers As Strings\u00a0to treat numbers with over 35 digits as strings. \nSelect\u00a0Truncate Big Numbers\u00a0to truncate them.\nUseful Links\nThe following NetSuite document describes the SuiteScript API, which is what we use for the NetSuite connector. Specifically the chapter on RESTLets (chapter 22) pertains to our connector architecture.", "source": "../../raw_kb/article/netsuite_connector/index.html", "title": "NetSuite Connector"}, {"objectID": "9515e6b943a8-5", "text": "https://system.netsuite.com/core/media/media.nl?id  =5732122&c=NLCORP&h=5fca4bf5dd825a28ab41&_xt=.pdf&  ... \nLimitations\nSaved searches will never connect to NetSuite financial statements because of balancing entries that NetSuite doesn't expose in the saved search results.", "source": "../../raw_kb/article/netsuite_connector/index.html", "title": "NetSuite Connector"}, {"objectID": "9515e6b943a8-6", "text": "NetSuite.docx\n\n\nTroubleshooting\nIf you get an \"Unexpected Error\" message after configuring the connection, check your column names for invalid characters such as apostrophes, quotation marks, backslashes, etc.\u00a0Verify that the External Script URL, Script ID, and Deploy ID in NetSuite match what is in the connector.Verify that the saved search ID in NetSuite matches what is in Domo and that it is the internal ID.Verify that the saved search runs without issue in NetSuite.", "source": "../../raw_kb/article/netsuite_connector/index.html", "title": "NetSuite Connector"}, {"objectID": "6523f70eddb8-0", "text": "Title\n\nNetSuite OpenAir Connector\n\nArticle Body", "source": "../../raw_kb/article/netsuite_openair_connector/index.html", "title": "NetSuite OpenAir Connector"}, {"objectID": "6523f70eddb8-1", "text": "Intro\nNetSuite OpenAir gives professional services organizations the ability to run their core business operations including project management, resource optimization, project accounting, time and expense management, and billing and revenue recognition. To learn more about the NetSuite OpenAir API, visit their page (https://www.openair.com/download/OpenAirXMLAPIGuide.pdf).\nYou connect to your NetSuite OpenAir account in the Data Center. This topic discusses the fields and menus that are specific to the NetSuite OpenAir connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your NetSuite OpenAir account and create a DataSet, you must have the following:\nThe user ID and password for your company's NetSuite OpenAir account.The company ID for the account.The URL for the account's OpenAir instance.The account's API namespace.The account's API key.\nTo obtain the API namespace and key, reach out to your NetSuite OpenAir account representative.\nConnecting to Your NetSuite OpenAir Account\nThis section enumerates the options in the Credentials and Details panes in the NetSuite OpenAir Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your NetSuite OpenAir account. The following table describes what is needed for each field:", "source": "../../raw_kb/article/netsuite_openair_connector/index.html", "title": "NetSuite OpenAir Connector"}, {"objectID": "6523f70eddb8-2", "text": "FieldDescriptionUser IDEnter the user ID for your company's NetSuite OpenAir account.PasswordEnter the password for your company's NetSuite OpenAir account.Company IDEnter the company ID associated with the account.URLEnter the URL for the account's NetSuite OpenAir instance.NamespaceEnter the account's API namespace as received from NetSuite.API KeyEnter the account's API key as received from NetSuite.\nOnce you have entered valid NetSuite OpenAir credentials, you can use the same account any time you go to create a new NetSuite OpenAir DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a single menu from which you select a report.", "source": "../../raw_kb/article/netsuite_openair_connector/index.html", "title": "NetSuite OpenAir Connector"}, {"objectID": "6523f70eddb8-3", "text": "MenuDescriptionReportSelect the NetSuite OpenAir report you want to run.\u00a0The following reports are available:AttributeReceives data about NetSuite OpenAir Attribute reports.Attribute SetReceives data about NetSuite OpenAir Attribute Set reports.BookingReceives data about NetSuite OpenAir Booking reports.Booking By DayReceives data about NetSuite OpenAir Booking By Day reports.Booking RequestReceives data about NetSuite OpenAir Booking Request reports.Booking TypeReceives data about NetSuite OpenAir Booking Type reports.BudgetReceives data about NetSuite OpenAir Budget reports.Budget AllocationReceives data about NetSuite OpenAir Budget Allocation reports.CategoryReceives data about NetSuite OpenAir Category reports.CustomersReceives data about NetSuite OpenAir Customers reports.DepartmentReceives data about NetSuite OpenAir Department reports.Entity TagReceives data about NetSuite OpenAir Entity Tag reports.HierarchyReceives data about NetSuite OpenAir Hierarchy reports.Hierarchy NodeReceives data about NetSuite OpenAir Hierarchy Node reports.InvoiceReceives data about NetSuite OpenAir Invoice reports.ItemReceives data about NetSuite OpenAir Item reports.Job CodeReceives data about NetSuite OpenAir Job Code reports.Loaded CostReceives data about NetSuite", "source": "../../raw_kb/article/netsuite_openair_connector/index.html", "title": "NetSuite OpenAir Connector"}, {"objectID": "6523f70eddb8-4", "text": "Job Code reports.Loaded CostReceives data about NetSuite OpenAir Loaded Cost reports.ProductReceives data about NetSuite OpenAir Product reports.Project AssignReceives data about NetSuite OpenAir Project Assign reports.Project Assignment ProfileReceives data about NetSuite OpenAir Project Assignment Profile reports.Project Billing RuleReceives data about NetSuite OpenAir Project Billing Rule reports.Project Billing TransactionReceives data about NetSuite OpenAir Project Billing Transaction reports.Project Budget GroupReceives data about NetSuite OpenAir Project Budget Group reports.Project Budget RuleReceives data about NetSuite OpenAir Project Budget Rule reports.Project Budget TransactionReceives data about NetSuite OpenAir Project Budget Transaction reports.Project LocationReceives data about NetSuite OpenAir Project Location reports.Project GroupReceives data about NetSuite OpenAir Project Group reports.Project StageReceives data about NetSuite OpenAir Project Stage reports.Project TaskReceives data about NetSuite OpenAir Project Task reports.Project Task AssignReceives data about NetSuite OpenAir Project Task Assign reports.Project Task TypeReceives data about NetSuite OpenAir Project Task Type reports.ProjectsReceives data about NetSuite OpenAir Projects reports.RatecardReceives data about NetSuite OpenAir", "source": "../../raw_kb/article/netsuite_openair_connector/index.html", "title": "NetSuite OpenAir Connector"}, {"objectID": "6523f70eddb8-5", "text": "Projects reports.RatecardReceives data about NetSuite OpenAir Ratecard reports.Ratecard ItemReceives data about NetSuite OpenAir Ratecard Item reports.Resource ProfileReceives data about NetSuite OpenAir Resource Profile reports.Resource Profile TypeReceives data about NetSuite OpenAir Resource Profile Type reports.Resource RequestReceives data about NetSuite OpenAir Resource Request reports.Revenue ContainerReceives data about NetSuite OpenAir Revenue Container reports.Revenue ProjectionReceives data about NetSuite OpenAir Revenue Projection reports.Revenue Recognition RuleReceives data about NetSuite OpenAir Revenue Recognition Rule reports.Revenue Recognition Rule AmountReceives data about NetSuite OpenAir Revenue Recognition Rule Amount reports.Revenue Recognition TransactionReceives data about NetSuite OpenAir Revenue Recognition Transaction reports.Revenue StageReceives data about NetSuite OpenAir Revenue Stage reports.RoleReceives data about NetSuite OpenAir Role reports.Schedule By DayReceives data about NetSuite OpenAir Schedule By Day reports.Schedule ExceptionReceives data about NetSuite OpenAir Schedule Exception reports.Schedule RequestReceives data about NetSuite OpenAir Schedule Request reports.Schedule Request ItemReceives data about NetSuite OpenAir Schedule Request Item reports.SlipsReceives data about NetSuite", "source": "../../raw_kb/article/netsuite_openair_connector/index.html", "title": "NetSuite OpenAir Connector"}, {"objectID": "6523f70eddb8-6", "text": "Schedule Request Item reports.SlipsReceives data about NetSuite OpenAir Slips reports.Slips ProjectionReceives data about NetSuite OpenAir Slips Projection reports.Slips StageReceives data about NetSuite OpenAir Slips Stage reports.Tag GroupReceives data about NetSuite OpenAir Tag Group reports.Tag Group AttributeReceives data about NetSuite OpenAir Tag Group Attribute reports.Target UtilizationReceives data about NetSuite OpenAir Target Utilization reports.TaskReceives data about NetSuite OpenAir Task reports.Task Time CardsReceives data about NetSuite OpenAir Task Time Cards reports.TimecardReceives data about NetSuite OpenAir Timecard reports.TimesheetReceives data about NetSuite OpenAir Timesheet reports.TimetypeReceives data about NetSuite OpenAir Timetype reports.UprateReceives data about NetSuite OpenAir Uprate reports.UsersReceives data about NetSuite OpenAir Users reports.Users LocationReceives data about NetSuite OpenAir Users Location reports.VendorReceives data about NetSuite OpenAir Vendor reports.Include Custom FieldsSelect this option if you would like custom fields to be returned with the dataset you have selected.Date Type FilterSelect the required Date Type Filter to filter the", "source": "../../raw_kb/article/netsuite_openair_connector/index.html", "title": "NetSuite OpenAir Connector"}, {"objectID": "6523f70eddb8-7", "text": "Type FilterSelect the required Date Type Filter to filter the records.Note: Please select None, to return complete dataUser IDsEnter the comma separated (,) values of User Ids for which the report should run. User Ids can be found in Users report.Note: If User Id's are not provided, then report will run for the current user.DurationSelect the duration for the report (a Single Date, or a Date Range).Single DateSelect whether the report data is for a specific date or for a relative number of days back from today.Specific DateSelect the specific date using the date selector.Relative DateEnter the number of days back that you would like to get data for in the\u00a0Days Back\u00a0field. Specify either today or 0, yesterday or 1, or today-7 or 7 to get data for 7 days into the past.Date RangeSelect the specific or relative date range.Start Date - SpecificSelect\u00a0the first date in your date range using the date selector.End Date - SpecificSelect the last date in your date range\u00a0using the date selector.Start Date - RelativeEnter the number of days back that you would", "source": "../../raw_kb/article/netsuite_openair_connector/index.html", "title": "NetSuite OpenAir Connector"}, {"objectID": "6523f70eddb8-8", "text": "- RelativeEnter the number of days back that you would like to get data from (start day). Combine with\u00a0End Date\u00a0to create a range of represented days.", "source": "../../raw_kb/article/netsuite_openair_connector/index.html", "title": "NetSuite OpenAir Connector"}, {"objectID": "6523f70eddb8-9", "text": "For example, if you entered\u00a010\u00a0for\u00a0Start Date\u00a0and\u00a05\u00a0for\u00a0End Date, the report would contain data for\u00a010 days ago up until\u00a05 days ago.End Date - RelativeEnter the number of days back that you would like to get data to (end day). Combine with\u00a0Start Date\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Start Date\u00a0and\u00a05\u00a0for\u00a0End Date, the report would contain data for\u00a010 days ago up until\u00a05 days ago.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/netsuite_openair_connector/index.html", "title": "NetSuite OpenAir Connector"}, {"objectID": "027612add6a5-0", "text": "TitleNetSuite SuiteAnalytics ConnectorArticle BodyIntro\n\nNetSuite creates products for enterprise resource planning, financial management, e-commerce, and customer relationship management.\u00a0You can use Domo's\u00a0NetSuite SuiteAnalytics\u00a0Connect Connector to pull data from tables you have access to through NetSuite\u00a0using custom SQL queries.\u00a0For more information about\u00a0NetSuite SuiteAnalytics, visit their website. (http://www.netsuite.com/portal/products/business-intelligence.shtml)\nThe NetSuite Suite Analytics connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking Cloud App in the toolbar at the top of the window.\nYou connect to NetSuite in the\u00a0Data Center. This topic discusses the fields and menus that are specific to the\u00a0NetSuite\u00a0SuiteAnalytics Connect\u00a0connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\n\n\n \n\n\nNote: This connector does not allow you to retrieve already created Saved Searches.\u00a0If you need to see the same results provided by these Save Search reports in Domo, you should create a new DataSet for each raw table involved in your end results and use Domo\u2019s ETL tools to combine these DataSets.", "source": "../../raw_kb/article/netsuite_suiteanalytics_connector/index.html", "title": "NetSuite SuiteAnalytics Connector"}, {"objectID": "027612add6a5-1", "text": "Primary Use CasesUse this connector to pull data from tables you access through NetSuite using custom SQL queries.Primary MetricsRevenueCostProjected RevenueCustomer/Lead DatesPrimary Company RolesFinance (P&L data)Sales managersAverage Implementation Time5-10 hoursEase of Use (on a 1-to-10 scale with 1 being easiest)6\nPrerequisites\nTo connect to NetSuite and create a DataSet, you must have the following:\nAccess to the SuiteAnalytics API, which you or your company must have purchased already (you can check to see if you have access by opening NetSuite Help Center in your NetSuite instance)\u00a0Your NetSuite username and passwordThe name of your NetSuite Service HostThe number of your NetSuite Service PortYour NetSuite DataSetYour NetSuite Role IDYour NetSuite Account ID\nYou can find instructions for configuring SuiteAnalytics Connect by opening Suite Analytics (Dashboards, Searches, & Reports) > SuiteAnalytics Connect > Introducing SuiteAnalytics\u00a0Connect > Getting Started.\nYour Service Host, Service Port, DataSet, Role ID, and Account ID can be found in the \"SuiteAnalytics Connect: JDBC Driver Setup\" screen in NetSuite. Follow these instructions to access this screen:\nSign into Netsuite\u00a0at\u00a0https://system.netsuite.com/pages/login.jsp.Click\u00a0Set Up\u00a0SuiteAnalytics Connect, which is located under\u00a0Settings\u00a0in the bottom left corner of the screen.Click\u00a0JDBC.Click\u00a0Default Configuration.Copy all of the information into the required fields in Domo.\u00a0\u00a0\nFollow the link below for instructions to setup:\nSetup Guide\nConnecting to NetSuite SuiteAnalytics Connect", "source": "../../raw_kb/article/netsuite_suiteanalytics_connector/index.html", "title": "NetSuite SuiteAnalytics Connector"}, {"objectID": "027612add6a5-2", "text": "Follow the link below for instructions to setup:\nSetup Guide\nConnecting to NetSuite SuiteAnalytics Connect\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the\u00a0NetSuite SuiteAnalytics Connect\u00a0Connector page. The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your database. The following table describes what is needed for each field: \u00a0\nFieldDescriptionService HostEnter the name of your NetSuite Service Host. For more information, see \"Prerequisites,\" above.Service PortEnter your NetSuite Service Port number. For more information, see \"Prerequisites,\" above.Service DataSetEnter the name of your NetSuite Service DataSet. For more information, see \"Prerequisites,\" above.UsernameEnter\u00a0your NetSuite username.PasswordEnter your NetSuite password.Role IDEnter your NetSuite Role ID number. For more information, see \"Prerequisites,\" above.Account IDEnter your NetSuite Account ID number. For more information, see \"Prerequisites,\" above.\nOnce you have entered valid NetSuite credentials, you can use the same account any time you go to create a new\u00a0NetSuite SuiteAnalytics Connect\u00a0DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see\u00a0Managing User Accounts for Connectors.\nDetails Pane\nIn this pane you create an SQL query to retrieve data from NetSuite database tables.\nMenuDescriptionQueryEnter the Structured Query Language (SQL) query to use in selecting the data you want. For example:\nselect * from Employees", "source": "../../raw_kb/article/netsuite_suiteanalytics_connector/index.html", "title": "NetSuite SuiteAnalytics Connector"}, {"objectID": "027612add6a5-3", "text": "select * from Employees\nYou can see the available columns to use in building a query by selecting the desired table in the Database Tables menu. The columns for that table then appear in the Table Columns field.Database TablesSelect a database table to see the columns in that table in the Table Columns field.Table ColumnsBrowse to see the available columns in the table selected in the Database Tables menu. You can also select columns. Selected columns appear in the sample SQL query in the Query Helper field.Query HelperUse this to help build SQL queries. When you select a column in the Table Columns field, a sample query referencing that column appears in this field. If you select additional columns, those columns are added to the query. You can edit the sample query as desired. Queries you build here can be copied and pasted into the Query field for use in retrieving data.\n\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nTroubleshooting", "source": "../../raw_kb/article/netsuite_suiteanalytics_connector/index.html", "title": "NetSuite SuiteAnalytics Connector"}, {"objectID": "027612add6a5-4", "text": "Troubleshooting\nYou can find field IDs in NetSuite by clicking on a given label. For example, if you have a field whose label was changed to from \"Category\" to \"Class,\" you can navigate to a customer record and click on the \"Class\" label. You should see \u201cCategory\u201d as the field ID within a pop-up.Even though Field IDs might display in the connector configuration, the API will not return data that a user does not have access to. Likewise, if a user has filtered settings, e.g. to only see Income Statement accounts and not Balance Sheet accounts, only permissioned data will return (so the user would not get balance sheet accounts in the DataSet). Data access is managed by a NetSuite Admin within a customer's organization.You may not have access to all the available data in your NetSuite instance.\u00a0If you try to pull data\u00a0that you don\u2019t have access too, you will get an error or incomplete results. If this happens, you may have to talk to a NetSuite administrator to get access to the specific data.", "source": "../../raw_kb/article/netsuite_suiteanalytics_connector/index.html", "title": "NetSuite SuiteAnalytics Connector"}, {"objectID": "f3fb125a8a57-0", "text": "TitleNetSuite SuiteAnalytics Partition ConnectorArticle BodyIntro\nNetSuite creates products for enterprise resource planning, financial management, e-commerce, and customer relationship management.\u00a0You can use Domo's\u00a0NetSuite SuiteAnalytics\u00a0Connect Partition Connector to pull data from tables you have access to through NetSuite\u00a0using custom SQL queries.\u00a0For more information about\u00a0NetSuite SuiteAnalytics, visit their website. (http://www.netsuite.com/portal/products/business-intelligence.shtml)\nThe NetSuite Suite Analytics Partition connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking\u00a0Cloud App\u00a0in the toolbar at the top of the window.\nYou connect to NetSuite in the\u00a0Data Center. This topic discusses the fields and menus that are specific to the\u00a0NetSuite\u00a0SuiteAnalytics Connect Partition connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\u00a0\u00a0\n\n\n \n\n\nNote: This connector does not allow you to retrieve already created Saved Searches.\u00a0If you need to see the same results provided by these Save Search reports in Domo, you should create a new DataSet for each raw table involved in your end results and use Domo\u2019s ETL tools to combine these DataSets.", "source": "../../raw_kb/article/netsuite_suiteanalytics_partition_connector/index.html", "title": "NetSuite SuiteAnalytics Partition Connector"}, {"objectID": "f3fb125a8a57-1", "text": "Prerequisites\nTo connect to NetSuite and create a DataSet, you must have the following:\nAccess to the SuiteAnalytics API, which you or your company must have purchased already (you can check to see if you have access by opening NetSuite Help Center in your NetSuite instance)\u00a0Your NetSuite username and passwordThe name of your NetSuite Service HostThe number of your NetSuite Service PortYour NetSuite DataSourceYour NetSuite Role IDYour NetSuite Account ID\nYou can find instructions for configuring\u00a0SuiteAnalytics Connect by opening Suite Analytics (Dashboards, Searches, & Reports) > SuiteAnalytics Connect > Introducing SuiteAnalytics\u00a0Connect > Getting Started.\nYour Service Host, Service Port, DataSet, Role ID, and Account ID can be found in the \"SuiteAnalytics Connect: JDBC Driver Setup\" screen in NetSuite. Follow these instructions to access this screen:\nSign into Netsuite\u00a0at\u00a0https://system.netsuite.com/pages/login.jsp.Click\u00a0Set Up\u00a0SuiteAnalytics Connect, which is located under\u00a0Settings\u00a0in the bottom left corner of the screen.Click\u00a0JDBC.Click\u00a0Default Configuration.Copy all of the information into the required fields in Domo.\u00a0\u00a0\nConnecting to NetSuite SuiteAnalytics Connect\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the\u00a0NetSuite SuiteAnalytics Connect\u00a0Connector page. The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your database. The following table describes what is needed for each field:", "source": "../../raw_kb/article/netsuite_suiteanalytics_partition_connector/index.html", "title": "NetSuite SuiteAnalytics Partition Connector"}, {"objectID": "f3fb125a8a57-2", "text": "FieldDescriptionService HostEnter the name of your NetSuite Service Host. For more information, see \"Prerequisites,\" above.Service PortEnter your NetSuite Service Port number. For more information, see \"Prerequisites,\" above.Service Data SourceEnter the name of your NetSuite Service Data Source.\u00a0For more information, see \"Prerequisites,\" above.UsernameEnter\u00a0your NetSuite username.PasswordEnter your NetSuite password.Role IDEnter your NetSuite Role ID number.\u00a0For more information, see \"Prerequisites,\" above.Account IDEnter your NetSuite Account ID number.\u00a0For more information, see \"Prerequisites,\" above.\nOnce you have entered valid NetSuite credentials, you can use the same account any time you go to create a new\u00a0NetSuite SuiteAnalytics Connect Partition DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see\u00a0Managing User Accounts for Connectors.\nDetails Pane\nIn this pane you create an SQL query to retrieve data from NetSuite database tables.\u00a0You can choose a specific database table and\u00a0partition column name. You can also specify the number of past days you want to get data for.\nMenuDescriptionQueryEnter the SQL query to execute. Example:\u00a0select DATE from employeeTable NameSelect the database table.Partition Column NameSelect partition column name.Past DaysEnter the number of past days that you want to get data for. Value can be X, where X is a positive integer. Example: 30.Date FormatSelect the required date format. By default\u00a0yyyy-MM-dd\u00a0will be used.Custom Date FormatEnter the custom date format you wish to apply to your data.\n\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nTroubleshooting", "source": "../../raw_kb/article/netsuite_suiteanalytics_partition_connector/index.html", "title": "NetSuite SuiteAnalytics Partition Connector"}, {"objectID": "f3fb125a8a57-3", "text": "Troubleshooting\nThe API will not return data that the user does not have access to. Likewise, if a user has filtered settings, e.g. to only see Income Statement accounts and not Balance Sheet accounts, only the data with\u00a0permission will be\u00a0returned (so the user would not get balance sheet accounts in the DataSet.)\u00a0Data access is managed by a NetSuite Admin within a customer's organization.You may not have access to all the available data in your NetSuite instance.\u00a0If you try to pull data\u00a0that you don\u2019t have access to, you will get an error or incomplete results. If this happens, you may have to talk to a NetSuite administrator to get access to the specific data.", "source": "../../raw_kb/article/netsuite_suiteanalytics_partition_connector/index.html", "title": "NetSuite SuiteAnalytics Partition Connector"}, {"objectID": "b1869bec4d02-0", "text": "Title\n\nNeurio Connector\n\nArticle Body\n\nIntro\nNeurio is a residential electricity usage monitoring service. Using smart devices installed in the home, Neurio can report your energy usage through a web-based dashboard. To learn more about the Neurio\u00a0API, visit their page (https://api-docs.neur.io/).\nYou connect to your Neurio account in the Data Center. This topic discusses the fields and menus that are specific to the Neurio connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Neurio account and create a DataSet, you must have the email address and password you use to log into Neurio.\nConnecting to Your Neurio Account\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the Neurio Connector page.\u00a0The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThe Domo Neurio connector uses OAuth to connect, so there is no need to enter credentials within Domo. Click\u00a0Connect\u00a0(or select\u00a0Add Account\u00a0if\u00a0you have\u00a0existing Neurio accounts in Domo) to open the Neurio OAuth screen where you can enter your Neurio credentials. Once you have entered valid Neurio credentials, you can use the same account any time you go to create a new Neurio DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see\u00a0Managing User Accounts for Connectors.", "source": "../../raw_kb/article/neurio_connector/index.html", "title": "Neurio Connector"}, {"objectID": "b1869bec4d02-1", "text": "Note:\u00a0If you are already logged into Neurio\u00a0when you connect in Domo, you are authenticated automatically when you click Add account. If you want to connect to an account that is different from the one you are logged into, you must first log out of Neurio.", "source": "../../raw_kb/article/neurio_connector/index.html", "title": "Neurio Connector"}, {"objectID": "b1869bec4d02-2", "text": "Details Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/neurio_connector/index.html", "title": "Neurio Connector"}, {"objectID": "b1869bec4d02-3", "text": "MenuDescriptionReportSelect the Neurio report you want to run.\u00a0The following reports are available:AppliancesReturns data about Neurio appliances for a specified location.Appliance EventsReturns data about Neurio appliance events for a specified location.Appliance Statistics for a Specific ApplianceReturns statistical data for a specific Neurio appliance within a given time range.Appliance Statistics by LocationReturns statistical data for appliances in a specified location within a given time range.Energy StatisticsReturns statistics for energy consumed within a given time interval.Last SampleReturns the last sample returned by a given sensor.Recent Appliance EventsReturns data about appliance events created or updated after a specified time.\u00a0Recent SamplesReturns recent samples, one sample per second for up to the last 2 minutes.SamplesReturns a given sensor's samples for a specified time period.Specific ApplianceReturns data about a specified Neurio appliance.Location IDEnter the ID for the location you want to retrieve data for.Sensor IDSelect the sensor you want to retrieve data for.Appliance IDSelect the appliance you want to retrieve data for.GranularitySelect how you want the data in your report", "source": "../../raw_kb/article/neurio_connector/index.html", "title": "Neurio Connector"}, {"objectID": "b1869bec4d02-4", "text": "how you want the data in your report to be broken down. For example, if you choose\u00a0Days, the data will be broken down by day.FrequencyEnter the frequency\u00a0of the sampled data. This\u00a0should be a multiple of 5 when using Minutes\u00a0granularity.Duration\u00a0Select whether you want to pull data for a specific date or a date range.\u00a0Report Date\u00a0Select whether the report data is for a specific date or for a relative number of days back from today.\u00a0Select Specific Date\u00a0Select the date for the report.\u00a0Days BackEnter the number of past days that should appear in the report.\u00a0\u00a0Start DateSpecify whether the\u00a0first date in your date range is a specific or relative date.\u00a0You select the last date in your range in\u00a0End Date.\u00a0End DateSpecify whether the second date in your date range is a specific or relative date. You select the first date in your range in\u00a0Start Date.\u00a0\u00a0Select Specific Start DateSelect\u00a0the first date in your date range.\u00a0Select Specific End DateSelect the second date in your date range.\u00a0Days Back to Start FromEnter the number of", "source": "../../raw_kb/article/neurio_connector/index.html", "title": "Neurio Connector"}, {"objectID": "b1869bec4d02-5", "text": "range.\u00a0Days Back to Start FromEnter the number of the farthest day back that should be represented in the report. Combine with\u00a0Days Back to End At\u00a0to create a range of represented days.", "source": "../../raw_kb/article/neurio_connector/index.html", "title": "Neurio Connector"}, {"objectID": "b1869bec4d02-6", "text": "For example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Days Back to End AtEnter the number of the most recent day back that should be represented in the report. Combine with\u00a0Days Back to Start From\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.\nOther Panes\u00a0\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/neurio_connector/index.html", "title": "Neurio Connector"}, {"objectID": "16930009409d-0", "text": "Title\n\nNew Navigation Announcement\n\nArticle Body\n\nIntro\nDomo's new navigation makes it easy to organize and manage your Pages so that they are easier to find, regardless of whether you have just a few Pages or a few hundred. It also makes is possible to navigate to all of Domo\u2019s most used features in fewer clicks, decreasing the time it takes you to perform actions in Domo and get answers. For more information, watch this\u00a0demo video.\nThe new navigation will be released to all Domo customers in March\u00a02020.\u00a0Until then, all customers have the option to turn on the new navigation by going into the Admin Settings and selecting\u00a0Company Settings > Feature control, then switching\u00a0on the option reading \"Enable updated navigation for all users.\" (You must have Admin security privileges to do this.) This way, your organization has the freedom to make the transition whenever it is ready. Note that third-level and favorited Pages are only supported in the updated navigation, so if you switch back to the old navigation from the new navigation, these Pages won't be visible in the UI.\u00a0\u00a0\nHere\u2019s a highlight list of some of the most notable improvements:\nImproved UI\nThe Pages menu has been moved to the left side\u00a0of the screen in a scrollable\u00a0\"Dashboards\" list. You can collapse this list by\u00a0clicking the\u00a0 icon, giving more space when you want to focus on important dashboard content. You can still show the list when it is in its collapsed state by mousing over the icon, or \"repin\" the list by clicking\u00a0.\u00a0\n\nThe list is searchable too, allowing you to quickly filter\u00a0down the list of Pages as you type.", "source": "../../raw_kb/article/new_navigation_announcement/index.html", "title": "New Navigation Announcement"}, {"objectID": "16930009409d-1", "text": "You will also find shortcuts to your most important Domo functions now exposed at the top of the screen, giving you quicker access.\n\u00a0\nThird-level Pages\nAn additional level of Page\u00a0hierarchy lets you create Subpages\u00a0of your Subpages. You have more options than ever for how you organize your Pages\u00a0to show related information.\u00a0\n\nFavorite Pages\nYou can now mark Pages as \"favorites,\"\u00a0making it easier for you to get to your most important content in Domo. You can add any Page as a\u00a0\"favorite\" Page by choosing the Add to favorites\u00a0option in the wrench menu for the Page.\u00a0\n\nOnce a Page is added as a Favorite, you can jump to it quickly by clicking\u00a0Favorites\u00a0at the top of the Pages list and selecting the Page you want to open.", "source": "../../raw_kb/article/new_navigation_announcement/index.html", "title": "New Navigation Announcement"}, {"objectID": "90a629ba03a3-0", "text": "TitleNew Relic ConnectorArticle BodyIntro\nNew Relic is a software analytics tool suite. \u00a0To learn more about\u00a0the New Relic\u00a0API, visit their\u00a0website (https://docs.newrelic.com/docs/apis/...ic-rest-api-v2).\nThe New Relic connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking Cloud App in the toolbar at the top of the window. \u00a0\nYou connect to your New Relic account in the\u00a0Data Center. This topic discusses the fields and menus that are specific to the\u00a0New Relic\u00a0connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrimary Use CasesThis connector is useful for understanding how a new software product is performing with regards to user experience.Primary MetricsApdexResponse timeThroughputError rateCPU usageMemoryPrimary Company RolesSoftware developersProduct managersAverage Implementation TimeIt takes about 15 to 30 minutes to set up an API key. The rest of the implementation is straightforward and should not take long.Ease of Use (on a 1-to-10 scale with 1 being easiest)3\nBest Practices\nEnsure that your tags for tracking user experience are clearly defined in New Relic and you are tagging the specifics of what you want to measure.\nPrerequisites\nTo connect to your\u00a0New Relic\u00a0account and create a DataSet, you must have a New Relic API key. For information about generating an API key, see\u00a0https://docs.newrelic.com/docs/apm/apis/requirements/api-key.\nConnecting to Your\u00a0New Relic\u00a0Account", "source": "../../raw_kb/article/new_relic_connector/index.html", "title": "New Relic Connector"}, {"objectID": "90a629ba03a3-1", "text": "Connecting to Your\u00a0New Relic\u00a0Account\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the\u00a0New Relic\u00a0Connector page.\u00a0The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your\u00a0New Relic\u00a0account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter the API key you use to log into your\u00a0New Relic account.\nOnce you have entered valid credentials, you can use the same account any time you go to create a new\u00a0New Relic\u00a0DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see\u00a0Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains\u00a0two primary\u00a0menus,\u00a0Connector Version\u00a0and\u00a0Report,\u00a0along with various other menus which may or may not appear depending on the connector version and report type you select.", "source": "../../raw_kb/article/new_relic_connector/index.html", "title": "New Relic Connector"}, {"objectID": "90a629ba03a3-2", "text": "MenuDescriptionReportSelect a New Relic report. The following reports are available:Application Metrics\u00a0Returns information about applications monitored by New Relic, including response time, Apdex, throughput and settings.\u00a0List Application Metric ValuesReturns a list of data for the\u00a0Application Metric.Mobile Applications ListReturns a list of Mobile Applications.Mobile Applications Metric NamesReturns a list of Mobile Metrics.Mobile Application Metric DataReturns the list of Mobile Metrics Data.Mobile Crash Metrics DataReturns the list of Mobile Crash Metrics Data.\u00a0ApplicationsSelect the application(s) you want to retrieve data for.\u00a0The connector version determines how many applications you may select.\u00a0Metric Names\u00a0(version 2 only)Select\u00a0the metrics you want to appear in your report. You can select as many\u00a0metrics as you like.\u00a0Start Date (for version 1)\u00a0Enter the start date for the report using the format\u00a0yyyy-MM-dd.\u00a0You can also\u00a0utilize relative start dates by inputting the keywords\u00a0today or\u00a0yesterday.\u00a0Or you can specify offsets like\u00a0yesterday-3,\u00a0which would set the\u00a0start date to 3 days in the past, starting from yesterday's date. \u00a0Start Date (for version 2)Select the start date for the report.End Date (for version 1)\u00a0Enter the\u00a0end date for the report using the format\u00a0yyyy-MM-dd.\u00a0You can also\u00a0utilize relative\u00a0end dates by inputting the keywords\u00a0today or\u00a0yesterday.\u00a0Or you can specify offsets like\u00a0yesterday-3,\u00a0which would set the\u00a0end date to 3 days in the past, starting from yesterday's date.End Date\u00a0(for version 2)Select the end date for the report.\u00a0Backfill\u00a0(version 1 only)Enter the number of past days\u00a0you want to retrieve data for on\u00a0the first run (based on the End Date value). Subsequent runs do not backfill data.", "source": "../../raw_kb/article/new_relic_connector/index.html", "title": "New Relic Connector"}, {"objectID": "90a629ba03a3-3", "text": "For example, if you entered yesterday for End Date and 30 for Backfill, the report would gather the last 31 days of data on its first run. On subsequent runs, the report would gather only yesterday's data.Time Zone\u00a0Select\u00a0the UTC time zone for your data.\u00a0\n\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding a DataSet Using a Data Connector.\nTroubleshooting\nMake sure access and logins have not changed for the New Relic system. Often if an account is deleted, you will need to generate another API Token.Sometimes event tagging will not be setup correctly in the New Relic system and will not pull the metrics needed. Sometimes adjustments with even tracking and tagging are needed to facilitate the reporting desired.", "source": "../../raw_kb/article/new_relic_connector/index.html", "title": "New Relic Connector"}, {"objectID": "01d9a8398450-0", "text": "TitleNew Relic for NRQL ConnectorArticle BodyIntro\nNew Relic is a software analytics tool suite. Use Domo\u2019s New Relic NRQL connector to pull New Relic data based on an NRQL query. To learn more about the New Relic API, visit their page (https://docs.newrelic.com/docs/apis).\nYou connect to your New Relic account in the Data Center. This topic discusses the fields and menus that are specific to the New Relic connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to New Relic\u00a0and create a DataSet, you must have the following:\nA New Relic API account ID. For information about finding your account ID, visit\u00a0https://docs.newrelic.com/docs/accou...tup/account-id.\u00a0The New Relic API URL. For information about finding your URl, see\u00a0https://docs.newrelic.com/docs/apis/...t-api-v2#appid.\u00a0Your New Relic API query key. For information about registering for a query key, see\u00a0https://docs.newrelic.com/docs/insig...a-api#register.\u00a0\nConnecting to Your New Relic Account\nThis section enumerates the options in the Credentials and Details panes in the New Relic Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your New Relic account. The following table describes what is needed for each field:", "source": "../../raw_kb/article/new_relic_for_nrql_connector/index.html", "title": "New Relic for NRQL Connector"}, {"objectID": "01d9a8398450-1", "text": "FieldDescriptionAccount IDEnter your New Relic API account ID.API URLEnter your New Relic API URL.Query KeyEnter your New Relic API query key.\nFor information about obtaining these credentials, see \"Prerequisites,\" above.\nOnce you have entered valid New Relic credentials, you can use the same account any time you go to create a new New Relic DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains options for pulling your desired report data and configuring the report.\nMenuDescriptionQueryEnter your New Relic NRQL\u00a0query. For information about NRQL query language, see\u00a0https://docs.newrelic.com/docs/insig...roduction-nrql.\u00a0Timestamp Column Names (Optional)Enter timestamp column names for your report, separating multiple names with commas. The connector recognizes the \"timestamp\" column as epoch even if you do not provide a value here. Enter other column names as necessary to be processed for epoch format changes.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding a DataSet Using a Data Connector.", "source": "../../raw_kb/article/new_relic_for_nrql_connector/index.html", "title": "New Relic for NRQL Connector"}, {"objectID": "ff2141b72a1e-0", "text": "TitleNew User GlossaryArticle BodyTo download this Word document, click here: Domo_Glossary_v4.docx", "source": "../../raw_kb/article/new_user_glossary/index.html", "title": "New User Glossary"}, {"objectID": "41b250788a37-0", "text": "TitleNHTSA ConnectorArticle BodyIntro\nNHTSA (National Highway Traffic Safety Administration) is an organization under the U.S. Department of Transportation (DOT). Domo's NHTSA connectors provide\u00a0access to NHTSA safety information, including locations of child safety seat inspection stations, Civil Penalty Payments collected, complaints submitted, and more. For information about the NHTSA API, visit their page (https://one.nhtsa.gov/webapi/Default.aspx?Recalls/API/83).\nThere are 4 NHTSA connectors in Domo, all of which are discussed in this article. The first of these is a standard Domo\u00a0API connector, while the other three are used to pull public datasets (which are discussed in more detail here). These connectors are as follows:\nNHTSA. Provides access to numerous categories of NHTSA\u00a0data, such as child safety seat inspection information, civil penalty payments, recalls, and so on. This connector lets you choose from a number of reports and configure filters, whereas the others in this list are automatically set to pull a specific report without filters.\u00a0NHTSA Complaints. Pulls all NHTSA complaint data,\u00a0with summary, incident date, vehicle make and model, number of injuries, and more.\u00a0NHTSA Recalls. Pulls all NHTSA recall data, with list of recalls with summary, manufacturer, make and model, and more.NHTSA Safety Ratings. Pulls all NHTSA safety rating data, with\u00a0a list of safety ratings, such as overall rating, crash ratings, rollover ratings, and more.\nYou connect to NHTSA\u00a0reports\u00a0in the Data Center. This topic discusses the fields and menus that are specific to the NHTSA connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites", "source": "../../raw_kb/article/nhtsa_connector/index.html", "title": "NHTSA Connector"}, {"objectID": "41b250788a37-1", "text": "Prerequisites\nNone. Because this data is public, there is no need to enter connection information.\nConnecting to Your NHTSA Account\nThis section enumerates the options in the Details panes in the NHTSA Connector page. (Note these options appear for the NHTSA connector only, not\u00a0the NHTSA Complaints, Recalls, or Safety Ratings connectors.) The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/nhtsa_connector/index.html", "title": "NHTSA Connector"}, {"objectID": "41b250788a37-2", "text": "MenuDescriptionReportSelect the NHTSA report you want to run.\u00a0The following reports are available:All ComplaintsReturns a list of complaints with summary, incident date, vehicle make and model, number of injuries, and more.\u00a0All Complaints by Model YearReturns a list of complains for a selected model year.\u00a0All RecallsReturns a list of recalls with summary, manufacturer, make and model, and more.All Recalls by Model YearReturns a list of recalls for a selected model year.All Safety RatingsReturns a list of safety ratings, such as overall rating, crash ratings, rollover ratings, and more.All Safety Ratings by Model YearReturns a list of safety ratings for a selected model year.Child Safety Seat Inspection Station Locator By Geo LocationReturns a list of CSSI Stations near the interested geographical location by its latitude and longitude.Child Safety Seat Inspection Station Locator By StateReturns a list of CSSI Stations in a given state.Child Safety Seat Inspection Station Locator By ZipReturns a list of CSSI Stations for a given zip code.Civil Penalty PaymentsReturns a list of civil", "source": "../../raw_kb/article/nhtsa_connector/index.html", "title": "NHTSA Connector"}, {"objectID": "41b250788a37-3", "text": "zip code.Civil Penalty PaymentsReturns a list of civil penalty\u00a0entries in the repository.Civil Penalty Payments By Fiscal YearReturns a list of civil penalty entries in the repository for a given fiscal year.ComplaintsReturns a list of complaints for the given model year, make, and model.Complaints By ODI NumberReturns a list of complaints for the specified ODI number.RecallsReturns a list of recalls for the given model year, make and model.Recalls By Campaign NumberReturns a list of recalls for the specified NHTSA\u00a0recall campaign number.Safety RatingsReturns a list of safety ratings for the given vehicle variant.LatitudeEnter the latitude you want to retrieve information for. Only numbers are accepted (e.g. 40.357494).LongitudeEnter the longitude you want to retrieve information for. Only numbers are accepted (e.g. -111.777995).MilesEnter the number of miles from the specified\u00a0Latitude\u00a0and\u00a0Longitude\u00a0for which you want to retrieve information.\u00a0Filter by Stations Participating in CPS WeekSelect\u00a0True\u00a0if you only want to retrieve data for stations participating in CPS Week.", "source": "../../raw_kb/article/nhtsa_connector/index.html", "title": "NHTSA Connector"}, {"objectID": "41b250788a37-4", "text": "retrieve data for stations participating in CPS Week. Select\u00a0False\u00a0to pull data for all stations.Filter by Spanish-Speaking StationsSelect\u00a0True\u00a0if you only want to retrieve data for Spanish-speaking stations. Select\u00a0False\u00a0to pull data for all stations.StateEnter the two-letter abbreviation for the state you want to retrieve information for.ZIP CodeEnter the ZIP\u00a0code for the area you want to retrieve information for.Fiscal YearEnter the fiscal year you want to retrieve information for.Model YearsSelect the vehicle model year you want to retrieve information for.Makes for the Model YearSelect the vehicle make you want to retrieve information for.Model for the Make and Model YearSelect the vehicle model you want to retrieve information for.ODI NumberEnter the ODI\u00a0number of the vehicle you want to retrieve information for.Campaign NumberEnter the campaign number of the recall you want to retrieve information for.", "source": "../../raw_kb/article/nhtsa_connector/index.html", "title": "NHTSA Connector"}, {"objectID": "41b250788a37-5", "text": "Other Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/nhtsa_connector/index.html", "title": "NHTSA Connector"}, {"objectID": "435aacf2221f-0", "text": "TitleNielsen Music Connect ConnectorArticle BodyIntro\nNielson Music Connect delivers granular and up-to-date data across multiple measurement metrics for artists, albums and songs as a complete view of performance and trends. To learn more about the Nielsen Music Connect API, visit their page (https://portal.developer.nielsen.com/home).\nYou connect to your Nielsen Music Connect account in the Data Center. This topic discusses the fields and menus that are specific to the Nielsen Music Connect connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding\u00a0a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Nielsen Music Connect account and create a DataSet, you must have the following:\nThe credentials (username and password) for your Nielsen Music Connect accountA Nielsen Music Connect client IDA Nielsen Music Connect password\nFor help finding your credentials, reach out to your Nielsen representative.\nConnecting to Your Nielsen Music Connect Account\nThis section enumerates the options in the Credentials and Details panes in the Nielsen Music Connect Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Nielsen Music Connect account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionUsernameEnter the username for your Nielsen Music Connect account.PasswordEnter the password for your Nielsen Music Connect account.Client IDEnter your Nielsen Music Connect client ID.Client SecretEnter your Nielsen Music Connect client secret.\nOnce you have entered valid Nielsen Music Connect credentials, you can use the same account any time you go to create a new Nielsen Music Connect DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.", "source": "../../raw_kb/article/nielsen_music_connect_connector/index.html", "title": "Nielsen Music Connect Connector"}, {"objectID": "435aacf2221f-1", "text": "Details Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.\nMenuDescriptionReportSelect the Nielsen Music Connect report you want to run.\u00a0The following reports are available:Barcode DataReturns metrics data for a given barcode.Chart DataReturns data for a specific chart.Chart ListReturns a list of charts.Chart OptionsReturns a detailed list of available markets and metrics.Data FeedRetrieves data feed results.ISRC DataReturns metrics for a given ISRC.BarcodeEnter the barcode you want to retrieve data for.ISRCEnter the ISRC you want to retrieve data for.Week Number (Optional)Enter the week number you want to retrieve data for, in the format YYYYWW, in which YYYY is the year and WW is the week number. For example, if you entered 201801, you would get data for the first week of 2018. If you leave this blank, data for the current week will be returned.\u00a0CountrySelect the country you want to retrieve data for.Chart NameSelect the name of the chart you want to retrieve data for.FiltersSelect all filters you want to apply to your chart.Market CodeSelect the market code you want to retrieve data for.Genre CodeSelect the genre code you want to retrieve data for.Metric CideSelect the metric code you want to retrieve data for.Request TypeSelect the desired request type.Chart Filter KeySelect the desired chart filter key.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nFAQs\nCan I use the same account to create multiple DataSets?\nYes.\nHow often can the data be updated?\nAs often as needed.\nAre there any API limits I should be aware of?\nNay.", "source": "../../raw_kb/article/nielsen_music_connect_connector/index.html", "title": "Nielsen Music Connect Connector"}, {"objectID": "b8170624c1dd-0", "text": "TitleNOAA Historical Weather ConnectorArticle BodyIntro\nNOAA's National Climatic Data Center (NCDC) is responsible for preserving, monitoring, assessing, and providing public access to climate and historical weather data and information.\u00a0 To learn more about the NOAA Historical Weather API, visit their page (http://www.ncdc.noaa.gov/cdo-web/webservices/v2).\nYou connect to your NOAA Historical Weather account in the Data Center. This topic discusses the fields and menus that are specific to the NOAA Historical Weather connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your NOAA Historical Weather account and create a DataSet, you must have an NOAA CDO\u00a0token. For information about obtaining a token, visit this page:\u00a0https://www.ncdc.noaa.gov/cdo-web/token\nConnecting to Your NOAA Historical Weather Account\nThis section enumerates the options in the Credentials and Details panes in the NOAA Historical Weather Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your NOAA Historical Weather account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionTokenEnter your NOAA CDO\u00a0token.\u00a0For information about obtaining a token, visit this page:\u00a0https://www.ncdc.noaa.gov/cdo-web/token\nOnce you have entered valid NOAA Historical Weather credentials, you can use the same account any time you go to create a new NOAA Historical Weather DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane", "source": "../../raw_kb/article/noaa_historical_weather_connector/index.html", "title": "NOAA Historical Weather Connector"}, {"objectID": "b8170624c1dd-1", "text": "Details Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/noaa_historical_weather_connector/index.html", "title": "NOAA Historical Weather Connector"}, {"objectID": "b8170624c1dd-2", "text": "MenuDescriptionReportSelect the NOAA Historical Weather report you want to run.\u00a0The following reports are available:Annual SummariesReturns data about annual land surface observations from around the world.Daily SummariesReturns data about daily land surface observations from around the world.Data CategoriesReturns a grouping of data types.Data TypesReturns a list of data types.DatasetsReturns a list of CDO\u00a0datasets.Locations CategoriesReturns a grouping of locations.LocationsReturns location data.Monthly SummariesReturns data about monthly land surface observations from around the world.Normals Annual/SeasonalReturns the annual and seasonal climate normals. This is computed for the 30-year period from 1981 to 2010.Normals DailyReturns data about the daily climate normals computed from 1981 to 2010.Normals HourlyReturns hourly climate normals that are computed for the 30-year period from 1981 to 2010.Normals MonthlyReturns monthly normals that are computed for the 30-year period from 1981 to 2010Precipitation 15 minuteReturns data of historical 15-minute precipitation observations.Precipitation HourlyReturns historical hourly precipitation observations.StationsReturns a list of stations.Days OffsetEnter the number of days back you want to end the report at. Use 0 for today. Combine with Days\u00a0to create a range of days. For example, if you entered 14 for\u00a0Days\u00a0and 7 for Days Offset, the report would include data for a two-week period, ending 7 days before today.DaysEnter the number of days to run the report for. Combine with Days Offset\u00a0to create a range of days.\u00a0For example, if you entered 14 for\u00a0Days\u00a0and 7 for Days Offset, the report would include data for a two-week period, ending 7 days before today.\nOther Panes", "source": "../../raw_kb/article/noaa_historical_weather_connector/index.html", "title": "NOAA Historical Weather Connector"}, {"objectID": "b8170624c1dd-3", "text": "Other Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/noaa_historical_weather_connector/index.html", "title": "NOAA Historical Weather Connector"}, {"objectID": "ea62688dffd6-0", "text": "TitleNOAA Weather Alerts ConnectorArticle BodyIntro\n\nYou can use Domo's NOAA Weather Alerts connector to retrieve weather alerts for any U.S. state or territory from the public\u00a0National Oceanic and Atmospheric Administration (NOAA) data.\nYou create an NOAA Weather Alerts DataSet in the\u00a0Data Center. This topic discusses the fields and menus that are specific to the\u00a0NOAA Weather Alerts connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nThe NOAA Weather Alerts connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking Cloud App in the toolbar at the top of the window.\nPrimary Use CasesThis connector is useful for getting severe weather alerts when planning outside events.Primary Company RolesHR roles, especially those involved in event planningAnyone interested in getting weather alertsAverage Implementation TimeLess than 1 minuteEase of Use (on a 1-to-10 scale with 1 being easiest)1\nPrerequisites\nNone. Because this data is public, there is no need to enter connection information.\nDetails Pane\n\n\nFieldDescriptionState NameSelect the State from the dropdown that you want to receive weather alerts for.", "source": "../../raw_kb/article/noaa_weather_alerts_connector/index.html", "title": "NOAA Weather Alerts Connector"}, {"objectID": "ea62688dffd6-1", "text": "FieldDescriptionState NameSelect the State from the dropdown that you want to receive weather alerts for.\n\n\u00a0\n\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nCreating a NOAA\u00a0DataSet\nTo create a NOAA Weather Alerts DataSet, simply select\u00a0the state or territory you wish to retrieve alerts for in the\u00a0State Name\u00a0menu in the\u00a0Details\u00a0pane.\u00a0Then schedule updates and name and describe your new DataSet in the\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet\u00a0panes. These panes are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nTroubleshooting\nReach out to DomoSupport if you experience issues with this connector. Because no credentials are needed, any issues that arise are likely be internal Domo issues or problems with the NOAA API.", "source": "../../raw_kb/article/noaa_weather_alerts_connector/index.html", "title": "NOAA Weather Alerts Connector"}, {"objectID": "0651c18afa26-0", "text": "TitleNOAA Weather ConnectorArticle BodyIntro\n\nYou can use Domo's NOAA Weather connector to retrieve a weather forecast or current observations for a specified latitude and longitude from the public National Oceanic and Atmospheric Administration (NOAA) data.\nYou create an NOAA Weather DataSet in the\u00a0Data Center.\nThe NOAA Weather connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking Cloud App in the toolbar at the top of the window.\nThis topic discusses the fields and menus that are specific to the\u00a0NOAA Weather connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\u00a0\nPrerequisites\nNone\nCreating an NOAA Weather DataSet\nDetails Pane\nReport\nThere are two types of reports to choose from:\nThe Forecast report returns future forecast weather data at either a daily or hourly period.The Current Observations report returns 1 row of the last recorded values\u00a0for a specific weather station.\u00a0\nLatitude and Longitude\nProvide the latitude and longitude for the coordinates you would like to return data for.\u00a0\n\n\n \n\nTip:\u00a0These fields will only handle positive and negative numbers. Adding an N at the end of your latitude will case an error. (Ex: 40.3452 N)\n\n\n\nWeather Station\nYou must select a weather station when choosing the current observations report. The weather station drop-down list is populated with the closest stations to the latitude and longitude provided.\u00a0\nOther Panes\nThen, schedule updates for your new DataSet in the\u00a0Scheduling\u00a0pane. For information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/noaa_weather_connector/index.html", "title": "NOAA Weather Connector"}, {"objectID": "a825ce73c854-0", "text": "TitleNon-queryable DataSetsArticle BodyIntro\nNot all DataSets are created equal. For example, some DataSets may be used strictly as\u00a0DataFlow inputs or have not been accessed for a while and\u00a0therefore\u00a0are not being actively queried (i.e. used and viewed regularly in Cards or Dashboards). These DataSets will continue to run as scheduled, perform normally as expected, and are optimized for their current use, but must be brought into an actively queried state to use in visualizations.\nDataSets that cannot be actively queried\nWhen a DataSet is not optimized for querying, the following message will appear in the DataSet Details.\n\nYou will also be notified of a DataSet's\u00a0status when you\u00a0click\u00a0Open With\u00a0menu in\u00a0the DataSet Details view. You must bring the DataSet back to an actively queried state\u00a0to begin building new content with it.\n\nBringing DataSets to an actively queried state\nTo optimize a DataSet\u00a0for querying\u00a0to be used in Cards, Dashboards, and more, click the\u00a0Start\u00a0button in the Details View Overview tab. You may begin using that DataSet\u00a0as soon as it is done preparing.", "source": "../../raw_kb/article/nonqueryable_datasets/index.html", "title": "Non-queryable DataSets"}, {"objectID": "a825ce73c854-1", "text": "From the Data Center\nNavigate to the Data Center and search for the DataSet\u00a0you want to actively query.Click on the DataSet\u00a0to view the Overview tab in the DataSet Details.Click\u00a0Start.\nIn Analyzer\nIn Analyzer, you will be presented with the following message if a DataSet is not actively queried.Click\u00a0Get Details\u00a0to be taken directly to the DataSet\u00a0Details view.Click\u00a0Start.\nFrom\u00a0Card Details\nIn the Card Details view, you will be presented with the following message if a DataSet is not actively queried.Click\u00a0Get Details\u00a0to be taken directly to the DataSet Details view.Click\u00a0Start.\nIn DataFusions\nIn DataFusions, you will be presented with the following message if a DataSet you are attempting to use as an input is not actively queried.Navigate to the Data Center. Find and select the DataSet to access the DataSet Details view.Click\u00a0Start.", "source": "../../raw_kb/article/nonqueryable_datasets/index.html", "title": "Non-queryable DataSets"}, {"objectID": "cb0372c46b5c-0", "text": "Title\n\nNovember 2015 Release Notes\n\nArticle Body\n\nNote: Depending on the product version you are using, the documentation may include information about features that may not be available or may have changed.\n\n\n\nNew features and enhancements\nFeatures and enhancements in this release include the following:\nThe Data Warehouse\nThe\u00a0Data Warehouse provides a visually engaging way for\u00a0you to interact with\u00a0your data warehouse that has been built within Domo. The Data Warehouse\u00a0gives you\u00a0quick insight into the breadth of your data and also allows\u00a0you to drive into the depth of individual data providers. You can then\u00a0take\u00a0your newly gained insights and take effective action on a specific data source or create new data source where a gap was discovered.\nThe\u00a0Data Warehouse\u00a0provides a three-dimensional visual representation of all data sources and Magic connectors in your Domo, along with data currently flowing into and between them.\u00a0These are represented as stacks on a rotating palette.\u00a0You can configure the order and height of the stacks to indicate different metrics.\nData Warehouse main view", "source": "../../raw_kb/article/november_2015_release_notes/index.html", "title": "November 2015 Release Notes"}, {"objectID": "cb0372c46b5c-1", "text": "Mousing over a stack causes the palette to\u00a0stop rotating, and an information panel appears for the data source or Magic connector. This panel shows information such as the number of DataSets for the data source or connector, the number of cards built, the number of successful and failed runs, etc.\nYou can click and drag the panel to\u00a0move it manually. The panel can be\u00a0moved in three dimensions.\nStacks are colored differently depending on their type and current activity. Green indicates a functional data source, blue indicates a Magic connector,\u00a0orange indicates a warning state for a data source, and red indicates that one or more DataSets\u00a0for a data source\u00a0is broken and needs immediate attention.\nThe arrangement of stacks around the palette and the height of the individual stacks\u00a0indicate\u00a0specified metrics. By default, stack arrangement indicates status and stack height indicates the number of rows of data. If you want, you can change the criteria determined by arrangement and height.\u00a0For example, you could set the arrangement\u00a0of stacks around the palette to indicate the number of cards built using the\u00a0data\u00a0source or Magic connector\u00a0and the height of the stacks to indicate the number of DataSets.\nClicking a connector stack\u00a0changes the view to show three-dimensional representations of all DataSets for the connector. This view also shows the data sources, the number of DataSets, and the number of rows for the data source or connector.\nConnector stack view for The Data Warehouse", "source": "../../raw_kb/article/november_2015_release_notes/index.html", "title": "November 2015 Release Notes"}, {"objectID": "cb0372c46b5c-2", "text": "For information about The Data Warehouse, see\u00a0Using The Data Warehouse to Manage Data.\nWorkbench 4\nWorkbench\u00a0version 4 is here.\u00a0The latest version of Domo Workbench provides a clean and intuitive user experience that will help you get the most out of Workbench. New features like API token login and parallel job processing improve security and performance while new connections like the external process plugin will extend the reach to Workbench to almost any data you have in your Data Center.\nThe user interface has been updated with all of the following improvements:\nUses .Net and Windows best practicesProvides wizards for executing primary activitiesUses a tree navigation system to provide\u00a0a\u00a0cleaner flow for the creation of\u00a0accounts, DataSet Jobs, and transformsProvides enhanced logging", "source": "../../raw_kb/article/november_2015_release_notes/index.html", "title": "November 2015 Release Notes"}, {"objectID": "cb0372c46b5c-3", "text": "In Workbench 4 you also have access to numerous security and performance upgrades, including the following:\nThe use of API tokens for all Workbench usersImplementation of multi-part uploading for all large DataSet JobsAutomated proxy setting determinationSimplification of multiple instance connectionsParallel job processing\nWorkbench 4 also includes a new developer plugin model that will enable you to do all of the following:\nInstall new plugins directly in WorkbenchCreate data provider, transport, and transform plugins that can be consumed in a common format (DLL)\nIn addition to all this, this release includes other new functionality such as the ability to connect to OLAP cubes; the ability to define connections using external\u00a0process file providers; the ability to create groups of DataSet Jobs on the same update schedule; and more.\nFor information about Workbench 4, see\u00a0Workbench 4.\nBuzz v3\nBuzz has been updated to provide\u00a0more enjoyable and meaningful social experiences with your colleagues in Domo.\nYou can view a discussion in the Buzz panel or expand it to fill the screen. The Buzz panel now displays only the first and last comments in each conversation in chronological order; however,\u00a0you can expand any particular conversation to show only that conversation in its entirety. You can also filter the feed activity to show only discussions that are connected to a trending topic, card, or project.\nIn addition, you can now do all of the following in Buzz:", "source": "../../raw_kb/article/november_2015_release_notes/index.html", "title": "November 2015 Release Notes"}, {"objectID": "cb0372c46b5c-4", "text": "In addition, you can now do all of the following in Buzz:\n@ mention the users or groups you want to see your message@\u00a0mention cards or projects you want to reference in the messagereference specific users, cards, groups, or projects using @\u00a0or popular topics using #add new hash tags #select images for URLsattach documents and images by selecting from the browser, dragging and dropping, or entering the image URLattach YouTube videos that can be played inlinenavigate through previews of referenced cards using a card carouselfilter by browse mode or trending topic, card, or projectspecify a post as public or private\"mute\" discussions\u00a0so you\u00a0don't receive notifications when\u00a0new comments are added to that discussion\nBuzz - Main panel\u00a0\nBuzz - New discussion\u00a0view\u00a0\nFor more information about Buzz, see\u00a0Buzz.\nNotifications\u00a0Management\nNotifications provide a way for you to know when important things happen in Domo that demand your attention.\u00a0The new Manage Notifications & Alerts page in Domo gives you the flexibility to determine how, when, and which\u00a0notifications come to you. This page lets you set options for Notifications, Instant Alerts, Daily Alerts, and Weekly Alerts.\nIn the Notifications tab, you can toggle global settings for receiving notifications via email, mobile app, or SMS. You can also\u00a0specify if and how you receive notifications for all of the following:\nSomeone @ mentioning you or a group you're inSomeone commenting on a conversation you're mentioned inSomeone liking something you postedSomeone sharing a card or page with youSomeone assigning a task to you or updating your taskSomeone uploading a new version of a document card you've favorite\nYou can also\u00a0toggle subscription emails in the Notifications tab.\nManage Notifications & Alerts - Notifications tab", "source": "../../raw_kb/article/november_2015_release_notes/index.html", "title": "November 2015 Release Notes"}, {"objectID": "cb0372c46b5c-5", "text": "Manage Notifications & Alerts - Notifications tab\u00a0\nIn the Instant Alerts tab, you can set options for instant notifications for triggered alerts. In the Daily Alerts\u00a0tab, you can\u00a0set the time at which\u00a0daily summary emails\u00a0(lists of alerts) are sent to you.\u00a0You can also specify whether updates to \"Favorited\" cards are included in the email.\u00a0In the Weekly Alerts  tab you can set the day of the week and time when weekly summary emails are sent.\nManage\u00a0Notifications & Alerts - Daily Alerts tab\u00a0\nFor any alert, you can\u00a0now select whether you want to receive instant,\u00a0daily, and/or weekly notifications.\u00a0Alerts with\u00a0Daily selected appear\u00a0in your daily summary email, and alerts with\u00a0Weekly selected appear in your weekly summary email.\nFor more information, see\u00a0Customizing Notification and Alert Settings.\nAlert Summary card\nDomo's existing alert interface has been updated in the form of an alert summary card.\u00a0This card contains all of the information and options necessary for understanding, editing, and deleting alerts. The card is available from the\u00a0Alerts Center, the\u00a0card\u00a0Details view, and the Profile page.\nThe alert summary card\u00a0allows you to do all of the following from one place:\nSet instant, daily, and weekly notifications on the alertEdit the alertDelete the alertView the\u00a0Details view for the card in which the alert has been setSee the creator and followers of the alertView the 180-day history for the alertView a list of\u00a0events when the alert has been triggered\nFor more information, see\u00a0Notifications and Alerts.\nDomo University training videos access", "source": "../../raw_kb/article/november_2015_release_notes/index.html", "title": "November 2015 Release Notes"}, {"objectID": "cb0372c46b5c-6", "text": "For more information, see\u00a0Notifications and Alerts.\nDomo University training videos access\nYou can now access and authenticate to Domo University using a link in the Domo product. This link provides access to a new Domo University page where hundreds of training videos can be viewed. No separate login is required, and new videos are added at frequent intervals. Customers should visit the Help Center to register for webinars and/or public courses.\nImproved document card\nThe document card has been\u00a0updated with a\u00a0number of exciting new capabilities. Now you can make Domo the place where all of your documents are stored so you can collaborate around them, compare them with data, and easily view the version history. You'll know exactly when a file has been updated, and you'll never have to leave Domo to view your documents.\nNew document card features include the following:\nThe ability to show your\u00a0actual document in Domo, rather than just a placeholder.A number of new supported file types, including images. (Image cards will still be available in Domo with all of the same functionality before; however, they will gradually be phased out\u00a0as more and more users switch to using document cards to\u00a0display images.)\u00a0All of these file types will be available for use in document cards:PDFDOCXDOCXLSXXLSPPTXPPTTXTPNGJPGBMPA maximum upload file size of 100 MB.A\u00a0panel in the document card\u00a0Details view in which old versions of the document are stored as thumbnails. You can see any old version of the document by clicking its thumbnail, as well as delete any version.A document preview mode with standard and full-screen viewing modes, page navigation controls, and a download icon.An option that allows you to receive notifications when a document card you have added as a Favorite gets a new version.\u00a0\nDocument Details view\nDocument preview\u00a0mode", "source": "../../raw_kb/article/november_2015_release_notes/index.html", "title": "November 2015 Release Notes"}, {"objectID": "cb0372c46b5c-7", "text": "Document Details view\nDocument preview\u00a0mode\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nFor more information about document cards, see\u00a0Adding a Document Card to Domo.\nAbility to change page owner\nYou can now change the owner of a\u00a0card page as long as you are already the owner or have an \"Admin\" security role.\nFor more information about changing the owner of a page, see\u00a0Managing Pages.\nAbility to rename pages\nYou can now rename card pages inline instead of having to\u00a0make the change in the\u00a0Manage Pages dialog.\nFor more information about renaming a page, see\u00a0Managing Pages.\nNotebook card non-owner editing\nNotebook cards can now be edited by any Admin, Privileged, or Editor user with access to the card.\nFor more information about notebook cards, see Notebook Cards.\nCountry maps for Portugal and United Arab Emirates\nYou can now add map cards for Portugal and United Arab Emirates.\nPortugal\nUnited Arab Emirates\nFor more information, see\u00a0Country Map.\nRegression lines\nYou can now add regression lines to single-series Vertical Bar and Line charts and most Line chart subtypes. You can specify the color of regression lines as well as the style (dashed or plain). You can also indicate whether the last date point in your chart is included in the calculation for the regression line.\nBar\u00a0chart with regression line\u00a0\n\u00a0Line chart with regression line\nFor more information, see\u00a0Line Chart.\nFirst day of week selection in Calendar charts\nIn Calendar charts, you can now specify the day that begins each week instead of\u00a0using the default day of Sunday.\nFor more information about building calendars, see\u00a0Calendar.\nExpanded hover functionality for Donut graphs", "source": "../../raw_kb/article/november_2015_release_notes/index.html", "title": "November 2015 Release Notes"}, {"objectID": "cb0372c46b5c-8", "text": "For more information about building calendars, see\u00a0Calendar.\nExpanded hover functionality for Donut graphs\nDetails views for Donut graphs now include additional hover functionality similar to that found in Pie charts. When you hover\u00a0over a section of a Donut graph,\u00a0hover text\u00a0next to the graph indicating the name of the section and the\u00a0total of all sections of\u00a0the graph.\nFor more information about Donut graphs, see\u00a0Donut Chart.\nDataFlow\u00a0Improvements\nA number of improvements have been made to our DataFlows functionality. These include the following:\nImproved error messages for Magic DataFlows.The ability to click and drag\u00a0multiple items in a Magic DataFlow.The ability to delete multiple items in a Magic DataFlow.The\u00a0ability\u00a0to restrict edit access for a Redshift or MySQL DataFlow to\u00a0the owner and users with an \"Admin\" security profile.DataFlow versioning. A new Versions tab in the DataFlow Details view lists all versions of a DataFlow. Each time you save changes to a DataFlow, a new version entry appears here. When saving, you\u00a0also have the option of describing the changes you made, similar to saving edits to a\u00a0KPI card.\u00a0Each version entry includes the save time, editor, inputs and outputs, runs vs. success rate, and change description (if one has been provided). In addition, for any version you have the option of making it the current version. This functionality is available for all DataFlow types.The ability to choose the columns in an input DataSet for a Redshift of MySQL DataFlow. This speeds up the processing time and allows for columns to have more room for values.\nDataFlow edit restriction control\nSave DataFlow dialog\u00a0\nDataFlow Versions tab\nInput DataSet column selection\nFor more information about DataFlows, see\u00a0SQL DataFlows.\nTable encoding protection", "source": "../../raw_kb/article/november_2015_release_notes/index.html", "title": "November 2015 Release Notes"}, {"objectID": "cb0372c46b5c-9", "text": "For more information about DataFlows, see\u00a0SQL DataFlows.\nTable encoding protection\nWe are turning on a higher level of security on all table cards. This will reduce the vulnerability of malicious attacks using cross site scripting and other methods. Domo will only allow tags in tables that are part of our \"whitelist group.\" In addition, only approved style attributes will be allowed.\nRelease guides\nAdmin users in Domo\u00a0will now have access to\u00a0release guides that describe all of the features for\u00a0an upcoming product release. These will be\u00a0accessible in an admin user's Domo one week before the release.\u00a0\u00a0\u00a0\nGetting Help\nYou can view the latest release notes information in the Help Center, which you can access from Domo by clicking\u00a0> Help Center.\nIf you have questions about Domo,\nsearch for a topic in the Help Centertrain in Domo University at http://www.domo.com/universityget answers in the Domo Community at dojo.domo.comcontact Technical Supportreach out to your Domo Customer Success Manager or Technical Consultant\nIf you have feedback, please send it from within Domo Or send an email to product.feedback@domo.com.\nFor more information about getting help, see Getting Help.", "source": "../../raw_kb/article/november_2015_release_notes/index.html", "title": "November 2015 Release Notes"}, {"objectID": "b467e818a8c0-0", "text": "Title\n\nNovember 2017 Release Notes\n\nArticle Body\n\nNew Features and Enhancements\nFeatures and enhancements in this release include the following:\nFreemium Upgrade Capability\nDomo now provides the capability for Freemium customers to upgrade to Domo's standard offering.\u00a0\nGetting Help\nFor a list of the features that were pushed to Domo in October, see 1.\nIf you have questions about Domo,\nsearch for a topic in the Knowledge Basetrain in Domo University at http://www.domo.com/universityget answers in the Domo Community at https://dojo.domo.comcontact Technical Support by entering a help ticket in the Domo Support Portal, by sending a Buzz message to \\support, or by emailing support@domo.com.reach out to your Domo Customer Success Manager or Technical Consultant\nIf you have feedback, please send it from within Domo (\u00a0> Feedback). Or send an email to product.feedback@domo.com.\nFor more information about getting help, see Getting Help.", "source": "../../raw_kb/article/november_2017_release_notes/index.html", "title": "November 2017 Release Notes"}, {"objectID": "5fba3ff1fc45-0", "text": "Title\n\nNovember 2018 Release Notes\n\nArticle Body", "source": "../../raw_kb/article/november_2018_release_notes/index.html", "title": "November 2018 Release Notes"}, {"objectID": "5fba3ff1fc45-1", "text": "New Features and Enhancements\u00a0\nFeatures and enhancements in this release include the following:\nOpenID Connect (OIDC)\nDomo customers can now access Domo through OpenID Connect--an industry standard, lightweight method for Single Sign-On (SSO). Domo already supports the industry leading protocol SAML 2.0 for SSO. The addition of OpenID Connect provides customers with a simpler, lower cost option. OpenID Connect is also better-suited than SAML 2.0 for developers, mobile users, and Domo Embed users.\u00a0\u00a0\u00a0OpenID Connect can be run in conjunction with SAML, which makes it easy for users to include both internal and external personnel in a single instance. This is particularly useful for companies that already utilize a stable SSO connection for their employees\u00a0but want to extend Domo to their suppliers and customers.\u00a0\nOpenID Connect is available now available for all customers.\n\u00a0\nFor more information, see Configuring Domo SSO Using OpenID Connect.\u00a0\nCustom Security Roles\nDomo has always provided\u00a0built-in security roles\u00a0such as \"Admin,\"\u00a0\"Privileged,\" and \"Participant\"\u00a0that are used to restrict access to sensitive Domo features. These\u00a0roles govern which users in your Domo instance can perform sensitive tasks\u00a0such as exporting data, inviting users, and changing company settings. These built-in roles have not always provided the flexibility needed to meet the security needs of larger organizations. Now, with the Role Management tool, you can create and manage custom security roles, giving you\u00a0more\u00a0flexibility and finer granularity in assigning access to Domo's powerful features.\nUsing Role Management, you can...", "source": "../../raw_kb/article/november_2018_release_notes/index.html", "title": "November 2018 Release Notes"}, {"objectID": "5fba3ff1fc45-2", "text": "Using Role Management, you can...\nExpand the list of roles beyond the current built-in roles (Admin, Privileged, Editor, Participant, and Social).Manage the privileges assigned to each new role.Delete unused roles.Get easy reporting on the privileges and list of assigned users in each new role.Use SSO\u00a0to automatically assign people to appropriate roles through a SAML\u00a0assertion at each login.\nYou can create as many custom roles as needed for your organization.\n\u00a0\nThis feature is available\u00a0on demand.\u00a0To request that this feature be enabled...\nContact Technical Support by using\u00a0/support\u00a0in Buzz or by emailing\u00a0support@domo.com.Reach out to your Domo Customer Success Manager or Technical Consultant.\nFor more information, see\u00a0Managing Roles.\nGetting Help\u00a0\nNeed help with Domo? Click the\u00a0 \u00a0icon in the top navigation bar to access a wealth of knowledge in the Help Center. \u00a0\nIf you have questions about Domo,\nsearch for a topic in the Help Centertrain in Domo University at\u00a0http://university.domo.comsearch for training apps in the Appstoreget answers in the Domo Community at\u00a0https://dojo.domo.comcontact Technical Support by entering a help ticket in the Domo Support Portal or\u00a0by sending a Buzz message to\u00a0/support.reach out to your Domo Customer Success Manager or Technical Consultant\nIf you have feedback, please send it from within Domo (\u00a0> Feedback). Or send an email to\u00a0product.feedback@domo.com.\nFor more information about getting help, see\u00a0Getting Help.", "source": "../../raw_kb/article/november_2018_release_notes/index.html", "title": "November 2018 Release Notes"}, {"objectID": "c777937ce856-0", "text": "TitleNutshell ConnectorArticle BodyIntro\nNutshell is a user-friendly small business CRM that helps sales reps win more deals, with sales process automation, fast onboarding, and free support. To learn more about the Nutshell API, visit their page (https://developers.nutshell.com/).", "source": "../../raw_kb/article/nutshell_connector/index.html", "title": "Nutshell Connector"}, {"objectID": "c777937ce856-1", "text": "You connect to your Nutshell account in the Data Center. This topic discusses the fields and menus that are specific to the Nutshell connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Nutshell account and create a DataSet, you must have the following:\nThe username you use to log into your Nutshell accountA Nutshell API key\nTo obtain a Nutshell API key, do the following:\nLog into your Nutshell account.Navigate to the Setup menu.Click API Keys (in the \"Third-party\" category).Click Add API key.Enter a name for the API key.Under \"Permissions,\" select the button for API Access.Click New API key.Copy the newly generated API key.\nConnecting to Your Nutshell Account\nThis section enumerates the options in the Credentials and Details panes in the Nutshell Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Nutshell account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionUsernameEnter the username for your Nutshell account.API KeyEnter your Nutshell API key. For steps for obtaining an API key, see \"Prerequisites\" above.\nOnce you have entered valid Nutshell credentials, you can use the same account any time you go to create a new Nutshell DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/nutshell_connector/index.html", "title": "Nutshell Connector"}, {"objectID": "c777937ce856-2", "text": "MenuDescriptionReportSelect the Nutshell report you want to run.\u00a0The following reports are available:Find AccountsReturns accounts matching the specified criteria.Find ActivitiesReturns activities matching the specified criteria and date range.Find ContactsReturns contacts matching the specified criteria.Find TagsReturns tags for a given entity (Accounts, Contacts, or Leads).Get AccountReturns details for the selected account.Get ActivityReturns details for the selected activity.Get ContactReturns details for the selected contact.Search AccountsReturns account information based on a provided search string. A maximum of 100 search results can be returned.Search Activity ParticipantsReturns activity participant information based on a provided search string. A maximum of 100 search results can be returned.Search ContactsReturns contact information based on a provided search string. A maximum of 100 search results can be returned.Add FiltersSelect Yes if you want to include search filters in this report.Account TypeSelect the account type you want to retrieve information for.IndustriesSelect the industries you want to retrieve information for.TerritoriesSelect the territories you want to retrieve information for.OriginsSelect the origins you want to retrieve information for.Open LeadsSelect True to return data for accounts", "source": "../../raw_kb/article/nutshell_connector/index.html", "title": "Nutshell Connector"}, {"objectID": "c777937ce856-3", "text": "information for.Open LeadsSelect True to return data for accounts associated with open leads. Select False to return data for all accounts.EntitySelect the entity you want to retrieve information for.TagsCheck the boxes for all tags you want to retrieve information for.Flagged Important?Select True to return data for activities that has been flagged as \"Important\" in Nutshell. Otherwise select False.Activity StatusSelect the activity status you want to retrieve information for. Note that \"Overdue\" status implies \"Scheduled.\"ContactsCheck the boxes for all contacts you want to retrieve information for.AccountsCheck the boxes for all accounts you want to retrieve information for.UsersCheck the boxes for all users you want to retrieve information for.Activity TypesCheck the boxes for all activity types you want to retrieve information for.Start DateSpecify whether the\u00a0first date in your date range is a specific or relative date.\u00a0You select the last date in your range in\u00a0End Date.\u00a0End DateSpecify whether the second date in your date range is a specific or relative date. You select the first date in your range in\u00a0Start Date.\u00a0\u00a0Select Specific Start DateSelect\u00a0the", "source": "../../raw_kb/article/nutshell_connector/index.html", "title": "Nutshell Connector"}, {"objectID": "c777937ce856-4", "text": "range in\u00a0Start Date.\u00a0\u00a0Select Specific Start DateSelect\u00a0the first date in your date range.\u00a0Select Specific End DateSelect the second date in your date range.\u00a0Days Back to Start FromEnter the number of the farthest day back that should be represented in the report. Combine with\u00a0Days Back to End At\u00a0to create a range of represented days.", "source": "../../raw_kb/article/nutshell_connector/index.html", "title": "Nutshell Connector"}, {"objectID": "c777937ce856-5", "text": "For example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Days Back to End AtEnter the number of the most recent day back that should be represented in the report. Combine with\u00a0Days Back to Start From\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.AccountSelect the account you want to retrieve information for.LeadSelect the lead you want to retrieve information for.ActivitySelect the activity you want to retrieve information for.ContactSelect the contact you want to retrieve information for.Search StringEnter a search term to retrieve information for.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/nutshell_connector/index.html", "title": "Nutshell Connector"}, {"objectID": "e2c1373006f9-0", "text": "TitleNUVI ConnectorArticle BodyIntro\nNUVI is a real-time analytics platform for social media. NUVI does not have API documentation available, but you can visit their website at\u00a0https://www.nuvi.com/.\u00a0\nYou connect to your NUVI account in the Data Center using PostgreSQL\u00a0credentials. This topic discusses the fields and menus that are specific to the NUVI connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nDomo's NUVI connector pulls data from a PostgreSQL database. To connect to your NUVI account and create a DataSet, you must have PostgreSQL credentials, as follows:\nThe username and password you use to log into your PostgreSQL databaseThe host name for the databaseThe port number for the databaseThe database name\nCA certificate text or URL path is required\u00a0only\u00a0if you select\u00a0Certificate text\u00a0or\u00a0URL path,\u00a0respectively, in the\u00a0Certificate type\u00a0menu.\nBefore you can connect to a PostgreSQL database, you must also whitelist a number of IP addresses on your database server on the\u00a0port\u00a0you want to connect to. For the full list of IP addresses, see\u00a0Whitelisting IP Addresses.\nConnecting to Your NUVI Account\nThis section enumerates the options in the Credentials and Details panes in the NUVI Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to NUVI's PostgreSQL database. The following table describes what is needed for each field:", "source": "../../raw_kb/article/nuvi_connector/index.html", "title": "NUVI Connector"}, {"objectID": "e2c1373006f9-1", "text": "FieldDescriptionUsernameEnter your PostgreSQL username.PasswordEnter your PostgreSQL password.HostEnter the host name for the SQL database. For example: db.company.comPortEnter the port number for the database.CertificatePaste the text for your CA certificate or enter the URL where your certificate is located.\u00a0This is optional. If you do not want to include a certificate, select No certificate in the Certificate Type menu.Certificate Type\u00a0Select a certificate type. If you do not want to include a certificate, select\u00a0No certificate. If you select\u00a0Certificate\u00a0text, you must paste the text for your certificate in the\u00a0Certificate field. If you select\u00a0URL path, you must enter the URL where your certificate is located in the\u00a0Certificate field. \u00a0\u00a0DatabaseEnter the name of the SQL database.\nOnce you have entered valid credentials, you can use the same account any time you go to create a new NUVI DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/nuvi_connector/index.html", "title": "NUVI Connector"}, {"objectID": "e2c1373006f9-2", "text": "MenuDescriptionReportSelect the NUVI report you want to run.\u00a0The following reports are available:Authors and SentimentReturns author and sentiment data.Authors, Genders, Posts, and SharingReturns data about authors, genders, posts, and sharing.\u00a0CategoriesReturns a list of categories.HashtagsReturns a list of hashtags.\u00a0KeywordsReturns a list of keywords.Last 100,000 MentionsReturns a list of the last 100,000 mentions.LocationsReturns a list of locations.SentimentReturns a list of sentiments.ThemesReturns a list of themes.User MentionsReturns a list of user mentions.Custom QueryReturns data based on a specified query.QueryEnter a custom query to return data based on that query.Table NameSelect the table containing the data you want to pull into Domo.Column NamesSelect the columns containing the data you want to pull into Domo.Query Helper\u00a0(Optional)Copy and paste the SQL statement in this field into the\u00a0Query\u00a0field. For more information, see\u00a0Query, above.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding a DataSet Using a Data Connector.", "source": "../../raw_kb/article/nuvi_connector/index.html", "title": "NUVI Connector"}, {"objectID": "7f52bf0e6d70-0", "text": "TitleObservePoint ConnectorArticle BodyIntro\nObservePoint\u00a0produces a data quality assurance tool for testing and validating\u00a0the accuracy of web tags, critical user paths, and more. Use Domo's ObservePoint connector to\u00a0bring\u00a0in audit report data to help you monitor and validate your analytics and marketing tags.\u00a0To learn more about the ObservePoint API, visit their page (https://docs.api.observepoint.com/v2...etting-started).\nYou connect to your ObservePoint account in the Data Center. This topic discusses the fields and menus that are specific to the ObservePoint connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your ObservePoint account and create a DataSet, you must have an ObservePoint API key.\u00a0You can find your API Key under ObservePoint\u00a0Account Settings\u00a0after you've logged in to the ObservePoint platform.\u00a0\nConnecting to Your ObservePoint Account\nThis section enumerates the options in the Credentials and Details panes in the ObservePoint Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your ObservePoint account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter your ObservePoint API\u00a0key.\nOnce you have entered valid ObservePoint credentials, you can use the same account any time you go to create a new ObservePoint DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane", "source": "../../raw_kb/article/observepoint_connector/index.html", "title": "ObservePoint Connector"}, {"objectID": "7f52bf0e6d70-1", "text": "Details Pane\nThis pane contains single menu from which you select an ObservePoint report.\nMenuDescriptionReportSelect the ObservePoint report you want to run.\u00a0The following reports are available:AuditsReturns a list of audits that the user has access to.Audit Failed Vendor ComplianceReturns a list of failed audit pages.Audit HistoriesReturns a list of history objects for the specified audit.Audit ImplementationsReturns information about audit implementations.Audit PageReturns information about a specific page in an audit.Audit PagesReturns a list of pages involved in an audit.Audit SummariesReturns a list of audit summaries.Audit TagsReturns a list of all tags involved in audit.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding a DataSet Using a Data Connector.", "source": "../../raw_kb/article/observepoint_connector/index.html", "title": "ObservePoint Connector"}, {"objectID": "78233feed760-0", "text": "TitleObservePoint V2 ConnectorArticle BodyIntro\nObservePoint\u00a0produces a data quality assurance tool for testing and validating\u00a0the accuracy of web tags, critical user paths, and more. With Domo's ObservePoint V2 connector, you can\u00a0bring\u00a0in ObservePoint analytics data to help you monitor and validate your analytics and marketing tags.\u00a0To learn more about the ObservePoint\u00a0API, visit their page (https://docs.api.observepoint.com/v2...etting-started).\nYou connect to your ObservePoint\u00a0account in the Data Center. This topic discusses the fields and menus that are specific to the ObservePoint\u00a0V2 connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your ObservePoint account and create a DataSet, you must have an ObservePoint API key.\u00a0You can find your API Key under ObservePoint\u00a0Account Settings\u00a0after you've logged in to the ObservePoint platform.\u00a0\nConnecting to Your ObservePoint Account\nThis section enumerates the options in the Credentials and Details panes in the ObservePoint\u00a0V2 Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your ObservePoint account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter your ObservePoint API\u00a0key.", "source": "../../raw_kb/article/observepoint_v2_connector/index.html", "title": "ObservePoint V2 Connector"}, {"objectID": "78233feed760-1", "text": "FieldDescriptionAPI KeyEnter your ObservePoint API\u00a0key.\nOnce you have entered valid ObservePoint credentials, you can use the same account any time you go to create a new ObservePoint\u00a0V2 DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a single menu from which you select an ObservePoint\u00a0V2 report.", "source": "../../raw_kb/article/observepoint_v2_connector/index.html", "title": "ObservePoint V2 Connector"}, {"objectID": "78233feed760-2", "text": "MenuDescriptionReportSelect the ObservePoint\u00a0V2 report you want to run.\u00a0The following reports are available:AccountReturns account information.AppsReturns a list of apps.App JourneysReturns a list of app journeys.App Journey ActionsReturns a list of app journey actions.App Journey CountriesReturns a list of app journey countries.App Journey LocationsReturns a list of app journey locations.App Journey RunsReturns a list of app journey runs.App Journey Result ActionsReturns a list of app journey result actions.App Journey Result Global Rules ResultsReturns a list of app journey result global rules results.Business Rules ComplianceReturns business rule compliance data.DomainsReturns a list of domains.Duplicate RequestsReturns a list of duplicate requests.FoldersReturns a list of folders.Folder UsersReturns a list of folder users.LabelsReturns a list of labels.Missing TagsReturns a list of missing tags.Multiple RequestsReturns a list of multiple requests.Page Load TimeReturns page load time data.Page Status CodesReturns a list of page status codes.RulesReturns a list of rules.Rule TagsReturns a list of rule tags.Rule LabelsReturns a list of rule labels.TagsReturns a list of tags.Tag PresenceReturns", "source": "../../raw_kb/article/observepoint_v2_connector/index.html", "title": "ObservePoint V2 Connector"}, {"objectID": "78233feed760-3", "text": "of rule labels.TagsReturns a list of tags.Tag PresenceReturns tag presence data.Tag Status CodesReturns a list of tag status codes.Tag SummaryReturns tag summary data.Tag Summary ReportReturns tag summary report data.Tag VersionsReturns tag versions data.UsersReturns a list of users.Vendor Rules ComplianceReturns vendor rules compliance data.Web AuditsReturns a list of web audits.Web Audit LabelsReturns a list of web audit labels.Web Audit LocationsReturns a list of web audit locations.Web Audit RulesReturns a list of web audit rules.Web Audit RunsReturns a list of web audit runs.Web Audit User AgentsReturns a list of web audit user agents.Web JourneysReturns web journey data.Web Journey LocationsReturns a list of web journey locations.Web Journey RulesReturns a list of web journey rules.Web Journey RunsReturns a list of web journey runs.Web Journey User AgentsReturns a list of web journey user agents.Web Journey Result ActionsReturns a list of web journey result actions.Web Journey Results Global Rules ResultsReturns web journey results global rules results.", "source": "../../raw_kb/article/observepoint_v2_connector/index.html", "title": "ObservePoint V2 Connector"}, {"objectID": "78233feed760-4", "text": "Other Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding a DataSet Using a Data Connector.\nFAQ\nHow often can the data be updated?\nAs often as necessary.\nAre there any API restrictions I should be aware of?\nNo.", "source": "../../raw_kb/article/observepoint_v2_connector/index.html", "title": "ObservePoint V2 Connector"}, {"objectID": "04bb853dfc56-0", "text": "Title\n\nOctober 2015 Release 1\n\nArticle Body\n\nNote: Depending on the product version you are using, the documentation may include information about features that may not be available or may have changed.\n\n\n\nNew features and enhancements\nFeatures and enhancements in this release include the following:\nSearching for Publication group configurations\nNow you can search for a publication group configuration using the\u00a0Search\u00a0pane. You can also create a publication group by clicking\u00a0New Publication Group\u00a0or delete a publication group by clicking\u00a0Delete Publication Group.\nFor more information, see\u00a0Using Publication Groups.\n\u00a0\nExporting DataSets\nYou can now export\u00a0DataSets in the Data Center as\u00a0Excel or CSV files.\nFor more information, see Exporting DataSets.\nOn-demand features and enhancements\n\n\n \n\n\nNote: This feature is available on demand.\u00a0\nTo request that this feature be enabled,\ncontact Technical Supportreach out to your Domo Customer Success Manager or Technical Consultant.\nDepending on the feature, you may be required to complete training before you can use the feature.", "source": "../../raw_kb/article/october_2015_release_1/index.html", "title": "October 2015 Release 1"}, {"objectID": "04bb853dfc56-1", "text": "Features and enhancements in this release include the following:\nManaging User Licenses\nNow Domo administrators can view how many users there are in Domo, how many user licenses have been purchased, and whether the number of licenses in use exceeds the allotted number of licenses. If over the license count, Domo administrators can order licenses from Domo.\nIf you have an \"Admin\" security role,\u00a0you can review your user license usage and order licenses from Domo. When you confirm a license purchase order, Domo sends an email to a Domo sales representative who sends you a purchase order invoice.\nYou access the Licensing page by clicking >\u00a0Admin > Licenses.\nFor more information, see\u00a0Adding User Licenses in Domo.\nGetting Help\nYou can view the latest release notes information in the Help Center, which you can access from Domo by clicking Help Center.\nIf you have questions about Domo,\nsearch for a topic in the Help Centertrain in Domo University at http://www.domo.com/universityget answers in the Domo Community at dojo.domo.comcontact Technical Supportreach out to your Domo Customer Success Manager or Technical Consultant\nIf you have feedback, please send it from within Domo (> Feedback). Or send an email to product.feedback@domo.com.\nFor more information about getting help, see Getting Help.", "source": "../../raw_kb/article/october_2015_release_1/index.html", "title": "October 2015 Release 1"}, {"objectID": "32933cd07703-0", "text": "Title\n\nOctober 2016 Release Notes\n\nArticle Body\n\nNote: These features will be turned on for all instances on or before October 25, 2016.\n\n\n\nNew features and enhancements\nFeatures and enhancements in this release include the following:\nDomo PowerPoint Plugin\nUse the Domo PowerPoint plugin to\u00a0pull Domo cards into a PowerPoint presentation. This plugin provides much more power and flexibility than the other available methods for showing cards in PowerPoint. You can download this plugin in Admin > Tool Downloads.\nUsing this plugin, you can do all of the following:\nConnect to the server for the desired Domo instance.Create a template for displaying cards in your presentation. You can include or exclude attributes such as card title, description, owner name, last modify date, and so on.Specify the page in Domo that cards are being pulled from.Refresh the cards in a presentation.Specify the types of cards that are pulled into Domo (KPI cards, document cards, custom Apps, etc.).", "source": "../../raw_kb/article/october_2016_release_notes/index.html", "title": "October 2016 Release Notes"}, {"objectID": "32933cd07703-1", "text": "For more information, see Using the Domo PowerPoint Plugin.\nDomo Excel Plugin\nUse the Domo Excel plugin to download DataSets from Domo\u00a0into Excel. You can then edit the data in Excel just as you could with any Excel spreadsheet. After editing DataSet data in Excel, you can upload the edited data into the same DataSet you downloaded it from, create a new Domo DataSet from this data, or upload the data to another existing DataSet. You can download this plugin in Admin > Tool Downloads.\nUsing this plugin, you can do all of the following:\nConnect to the server for the desired Domo instance.Download any DataSet from your connected instance as an Excel file.\u00a0Edit the data in your downloaded DataSet.Upload your edited DataSet as a new DataSet, into the same DataSet you pulled the data from, or into a different existing DataSet.\u00a0Refresh the DataSet\u2014if anything has changed in this DataSet, it will be \"redownloaded.\"  \nFor more information, see Using the Domo Excel Plugin.\nDomoR Plugin\nThe new DomoR plugin allows you to retrieve a DataSet from Domo, complete further processing on it in R, and then upload the changes back to Domo. The plugin can also be used to create a new DataSet in Domo directly from R. You can access installation information, an instructional video, and help links for the plugin from within Domo, by navigating to the Data Center and clicking R Plugin in the toolbar at the top of the screen.", "source": "../../raw_kb/article/october_2016_release_notes/index.html", "title": "October 2016 Release Notes"}, {"objectID": "32933cd07703-2", "text": "For information about the DomoR plugin, see DomoR Plugin.\nHelp Center Page\nWhen you now click the Help Center link in the main menu, a page opens within Domo from which you can navigate to Domo University, the Domo Dojo, the Knowledge Base, or Domo's Developer Portal. The page also contains several featured videos, which you can play right in this page instead of first having to navigate to the video library in Domo University, as well as the help guides found within Domo.\nNote that to access Domo's user documentation, you now click Domo Knowledge Base in the new Help Center page. Previously, clicking Help Center would open the user documentation directly.\u00a0\n\u00a0\u00a0\u00a0\nFor more information, see Getting Help.\nAdd to Domo\nThe new \"Add to Domo\" tool lets you open the \"Add\" interface for almost any object from anywhere in Domo. With just a few mouse clicks, this features brings to the forefront the tools that are available within Domo, similar to the new Data Center user interface. Objects you can add include the following:\nAPI, file, or database connectors.Magic ETL, SQL, and DataFusion transforms.All types of cards\u2014KPI cards, Sumo cards, document cards, etc.Card pages.Projects and tasks.People and groups.\nYou can also open the Workbench information/download screen (by selecting Data > On Premise).\n\u00a0\u00a0\u00a0\u00a0\nFor more information, see Domo Application Layout.\nNew Data Center UI\nThe user interface for the Data Center has been revamped to provide a more consistent experience. Changes to the UI include:", "source": "../../raw_kb/article/october_2016_release_notes/index.html", "title": "October 2016 Release Notes"}, {"objectID": "32933cd07703-3", "text": "Navigation between tabs is now accomplished through links on the left side of the screen.The Data Warehouse tab is the initially selected tab when you open the Data Center. This view includes a new toolbar with icons for connecting to third-party connectors (categorized as Cloud App, File, and Database connectors); opening the Workbench download page; switching over to Domo's developer environment; and opening the Magic ETL and DataFlow creation views. On all other tabs, you can access these options by clicking the New button.All options in the Accounts tab have been consolidated into two different menus, eliminating the need to remember various icons.\n\u00a0\u00a0\u00a0\u00a0\nFor more information, see Data Center Layout.\nNew Workbench Download Page\nThe Workbench download page has been updated to provide a more visually pleasing user experience, more thorough information about Workbench, and \"What's New\" notes and download buttons for all of the most recent releases. In addition, it has been moved out of the Admin Settings and into a more fitting location in the Data Center. To access the new Workbench download page, select  > Data Center then click On Premise in the toolbar at the top of the window.", "source": "../../raw_kb/article/october_2016_release_notes/index.html", "title": "October 2016 Release Notes"}, {"objectID": "32933cd07703-4", "text": "For more information about Workbench installation, see\u00a0Installing Workbench.\nNew public-facing connectors\nThe following Domo connectors are officially being released to customers:\nAmazon S3CallRailFlurryMixpanelOoyalaQuickBaseServiceNow\nFor more information about these and other connectors, see Configuring Each Connector.\nDataFlow Details view UI changes\nA new DataFlow details view is being released, with some changes to the user experience:\nClicking on an individual DataFlow on the listings page will now take you to the details page instead of the edit page. You can select\u00a0 > Edit on the listings page or click\u00a0 on the details page to edit the DataFlow.The details page itself is redesigned.A new Settings tab shows input DataSets for a DataFlow. For any DataSet, you can specify whether to run the DataFlow when that DataSet updates. A new DataSets tab shows all input and output DataSetsThe History tab now surfaces the amounts of input and output data. It also shows the version number.", "source": "../../raw_kb/article/october_2016_release_notes/index.html", "title": "October 2016 Release Notes"}, {"objectID": "32933cd07703-5", "text": "Chart Properties improvements\nIn the interest of making a simpler and more pleasing user experience, various changes have been made in the Chart Properties. These include the following:\nA number of properties have been marked as deprecated and removed from the product. For a list of deprecated properties, see Deprecated Chart Properties. Note that for any deprecated checkbox-activated properties, if that property was set to \"on\" before the property was deprecated, the property still appears in your Chart Properties and is still set to \"on.\" However, if you then turn off the property and resave the chart, the deprecated property will no longer be available.Numbers to the right of property categories indicate the number of enabled properties within that category. For example, in the following screenshot, one property has been set for General, two for Bar Settings, and so on.  \u00a0Chart properties that only apply when certain other properties are applied are now grayed out when those properties are not applied. For example, the following screenshot shows the Chart Properties dialog for Data Labels. Because all properties after Text are only applicable when a text string has been entered, those properties are grayed out, thereby eliminating user confusion.  The Large View Legend Position and Details View Legend Position properties have been replaced with the more user-friendly Portrait View Legend Position and Landscape View Legend Position properties. In addition, all chart types with legends now include the same chart properties for formatting legends.\nFor more information about chart properties, see\u00a0Chart Properties.\nGetting Help\nYou can view the latest release notes information in the Help Center, which you can access from Domo by clicking\u00a0\u00a0> Help Center.\nIf you have questions about Domo,\nsearch for a topic in the Help Centertrain in Domo University at http://www.domo.com/universityget answers in the Domo Community at dojo.domo.comreach out to your Domo Customer Success Manager or Technical Consultant", "source": "../../raw_kb/article/october_2016_release_notes/index.html", "title": "October 2016 Release Notes"}, {"objectID": "32933cd07703-6", "text": "If you have feedback, please send it from within Domo (\u00a0> Feedback). Or send an email to product.feedback@domo.com.\nFor more information about getting help, see Getting Help.", "source": "../../raw_kb/article/october_2016_release_notes/index.html", "title": "October 2016 Release Notes"}, {"objectID": "e9e219ce4f4e-0", "text": "Title\n\nOctober 2017 Release Notes\n\nArticle Body\n\nNew features and enhancements\nFeatures and enhancements in this release include the following:\nDomo Everywhere: Public Embed\nWith the new Domo Everywhere: Public Embed feature, Domo card creators can publish their visualizations on public websites and social platforms. This opens the door for many companies who want to scale their data on other websites for others to self-serve themselves by answering business questions and getting access to data they never had before. You can also show off your\u00a0data insights on blogs\u00a0and social sites. Who doesn\u2019t love interesting and beautiful content? With Domo Everywhere: Public Embed,\u00a0data will never look so cool to so many people, whether on their mobile device or on the web.\u00a0\n\nIf for security reasons you\u00a0do not\u00a0want this functionality available to your employees, you can turn it off by going into\u00a0Admin Settings > Company Settings > Company Overview\u00a0then unchecking the box for \"Publicly embed cards.\"", "source": "../../raw_kb/article/october_2017_release_notes/index.html", "title": "October 2017 Release Notes"}, {"objectID": "e9e219ce4f4e-1", "text": "For paying customers, there is a 30-day trial when using this feature.\u00a0\nAlso be aware of the following when using this feature:\nTitles, drilldown, summary number, and the chart picker are all available when embedding cards publicly; however, filters are not yet available.For security reasons, the end-of-card table view is not available with this feature.Currently, KPI cards and custom apps can be publicly embedded. Other types of cards (notebook, document, etc.) also cannot be publicly embedded. \u00a0\nFor more information, see\u00a0Sharing Cards Outside of Domo.\nDomo Everywhere Screen in Admin Settings\nIn the Admin Settings, as an Admin-level user you can also keep track of all cards in your instance that have been publicly embedded. You do this in the new\u00a0Domo Everywhere\u00a0screen. In this screen you can view all of the following:\nThe names of all publicly embedded cardsThe card\u00a0ownersThe users who embedded the cardsThe embed linksThe link access, either public or disabledThe number of public viewsThe creation date of the embed links\u00a0\nThis screen also includes an options menu from which you can update the link access for one or more links as well as change card owners.", "source": "../../raw_kb/article/october_2017_release_notes/index.html", "title": "October 2017 Release Notes"}, {"objectID": "e9e219ce4f4e-2", "text": "For more information, see\u00a0Admin Settings Layout.\nUser-Level Languages\nDomo\u00a0has just released a User Language setting that enables users to use Domo in their preferred language.\u00a0This brings yet another level of personalization to the already highly-customizable platform.\u00a0With the addition of the User Language setting, new and existing users can easily work within Domo in the language that they feel the most comfortable. With this feature, managers and team leaders can improve their teams' overall operational efficiency and get even more value out of using Domo.\u00a0Domo is launching the User Language feature with full support for five written languages: English, French, German, Japanese and Simplified Chinese. The Domo platform is prepared to scale to any number of languages to support Domo's steady international expansion.\nFor more information, see Configuring Languages in Domo.\nConnectors Details Pages in Appstore\nEach connector now includes an Appstore details page\u00a0that shows you the version number, release notes, details on what is needed to authenticate, a rating on how difficult it is to configure, a list of the reports with a description of what each one contains, common questions with answers, and any related apps, Quickstarts, or other connectors. There is even a place for you to input reviews of a connector and share information about your experience with others.\u00a0This interface gives you\u00a0the ability to self-serve connectors like never before\u00a0and start feeling good about your data in Domo from the moment you connect.Using this new feature is as easy as using the Appstore. Log in to Domo, open the Appstore and search for a connector. Once you find the one you want, as soon as you click on the results in your search you will see all the new details for the connector.", "source": "../../raw_kb/article/october_2017_release_notes/index.html", "title": "October 2017 Release Notes"}, {"objectID": "e9e219ce4f4e-3", "text": "For more information, see Appstore Layout - Connectors Tab.\nAlert Sharing with Social Users\nSharing alerts helps you create business alignment by providing a common understanding on critical data conditions. With no added cost to the business, you can now share any alert with team members who don't yet have a license in Domo to get everyone on the same page. \u00a0\nBy adding someone to an alert, Domo will now automatically create a free social user license and notify that person whenever the alert is triggered.\n\nWhen an alert is triggered, you need enough context to make decisions. \u00a0A new Alert view for free social users helps everyone get the information needed to take action.\n\nSmart\u00a0Alerts\nWith smart alerts, you can now be notified when outliers appear in your data,\u00a0without having to constantly change your\u00a0alert criteria. These alerts can provide a greater understanding of the possible risks in your business.\nAll of the following statistical alerts are now available:\nSumAverageMinimumMaximumStandard deviationVarianceKurtosisSkewness\u00a0\nYou can apply any of these options to any category or series item on the card and then specify a condition and value as usual. For example, if you wanted an alert to trigger whenever the variance of the \"West Region\" category increased by 5%, you would select\u00a0Variance of\u00a0> West Region\u00a0in the\u00a0Metric\u00a0menu and\u00a0Increases\u00a0by (+%)\u00a0in the\u00a0Meets this condition\u00a0menu, then enter 5 in the\u00a0For this value\u00a0menu.\n\nFor more information about creating alerts, see Creating a Custom Alert for a KPI Card.\nFile Upload Connector\nUse the File Upload connector to pull both Excel and CSV spreadsheet data into Domo and begin making decisions faster. This connector combines all of the functionality of our existing Excel and CSV connectors into a single simple-to-use interface.", "source": "../../raw_kb/article/october_2017_release_notes/index.html", "title": "October 2017 Release Notes"}, {"objectID": "e9e219ce4f4e-4", "text": "For more information, see\u00a0File Upload Connector.\nHelp Results in Search\nWith the new Global Search Help results feature, you can quickly find relevant help articles in one central location. Simply enter a keyword for a feature or topic you want to know more about, and if any Knowledge Base articles have been written on that topic, they will pop up in your results,\u00a0under the \"Help Center\" category. From there, all you have to do is click on the desired result, and the article will open directly in Knowledge Base.\u00a0\nFor more information, see Searching in Domo.\nSend Emails to Buzz\nWith the new Send Email to Buzz capability, you\u00a0can now\u00a0easily move slow-moving, long email threads to Buzz\u00a0and take advantage of the clear context visibility and speed to collaborate that Buzz provides. You\u00a0don't have to wait for responses in a slow-moving email chain anymore. Now you can\u00a0forward any email thread to Buzz and have all the collaborators, context, and attachments be used to kickstart a real time conversation. They simply obtain a unique email address for themselves from Buzz and use it as they Reply To or Forward any email thread from their inbox.", "source": "../../raw_kb/article/october_2017_release_notes/index.html", "title": "October 2017 Release Notes"}, {"objectID": "e9e219ce4f4e-5", "text": "For more information, see\u00a0Importing an Email Thread into Buzz.\nImproved Appstore Power-Up Experience\nThe deploy process for apps in the Appstore has been updated to provide a quicker and more pleasing experience. New improvements include the following:\nNew\u00a0options available after you set up an app with sample data:\u00a0Assign to Data Specialist\u00a0and\u00a0Do It Yourself. If you choose\u00a0Assign to Data Specialist, you can select a user in your company's Domo and send them an email to inform them about the new assignment.\u00a0  Progress gauges\u00a0for the deployment. Two new graphics show you how close you are to getting your data connected.\u00a0  Simplified process for powering up Card Builder apps. One pane lists all of the columns in your selected DataSet and another shows the columns necessary to power the app. You simply drag columns from the DataSet\u00a0pane onto the matching columns in the app pane. That's all there is to it. If data types do not match between columns, those columns cannot be matched.\u00a0  \nFor more information, see Deploying Apps from the Appstore.\nNew Self-Service Connectors\u00a0\nThis month we have polished and released another 103 connectors that are now available to all customers in their Domo account. These connectors are self-service, so you no longer need to contact support to get help powering them up. A partial list of these connectors is as follows:\u00a0\nDr. ChronoToutSimply MeasuredSprinklrRedditHuffington Post PollsterJiveBox GovernanceInformix SSHGithubHipchatCybase SSHOracle SSHMistOpenfireChangepoint10k'Sugar CRM OAuth\nGetting Help\nYou can view the latest release notes information in the Help Center, which you can access from Domo by clicking\u00a0\u00a0> Help Center.\nIf you have questions about Domo,", "source": "../../raw_kb/article/october_2017_release_notes/index.html", "title": "October 2017 Release Notes"}, {"objectID": "e9e219ce4f4e-6", "text": "If you have questions about Domo,\nsearch for a topic in the Help Centertrain in Domo University at http://www.domo.com/universityget answers in the Domo Community at https://dojo.domo.comcontact Technical Support by entering a help ticket in the Domo Support Portal, by sending a Buzz message to \\support, or by emailing support@domo.com.reach out to your Domo Customer Success Manager or Technical Consultant\nIf you have feedback, please send it from within Domo (\u00a0> Feedback). Or send an email to product.feedback@domo.com.\nFor more information about getting help, see Getting Help.", "source": "../../raw_kb/article/october_2017_release_notes/index.html", "title": "October 2017 Release Notes"}, {"objectID": "651ad69a489d-0", "text": "Title\n\nOctober 2018 Release Notes\n\nArticle Body\n\nNew Features and Enhancements\nFeatures and enhancements in this release include the following:\nCertified Content\nThe more people you bring into Domo, the more people you have in your company making good business decisions. But how can you be sure that the content you're all looking at is the same? How do you know if you brought in the right data? Introducing certified content in Domo.\nUsing the power of Certification Center, you can now certify your cards so your users know which content has been approved, just by looking at the card.\u00a0Certified content\u00a0gives your business the flexibility to customize certification\u00a0to the specific needs of your company. This means that when your users see a certification badge, it\u2019s been through a unique process tailored to your unique needs.\nCertifying a card is as easy as choosing Request certification from the wrench menu, selecting the appropriate certification process, and clicking Submit.\nWhile a card is\u00a0in the approval process, a badge will appear on the card so users can check the status of the certification. Because it\u2019s powered by Certification Center, anyone in the approval chain can send the request back if any changes need to be made.\u00a0Once the card has been through the approval process, it will receive a certification badge so everyone knows\u00a0they can\u00a0and should make business decisions based off this card.\nCertified content in Domo. Not just content, but data you can bet your company on.", "source": "../../raw_kb/article/october_2018_release_notes/index.html", "title": "October 2018 Release Notes"}, {"objectID": "651ad69a489d-1", "text": "For more information, see\u00a0Certifying Content.\nData Science and Scripting Actions in ETL\nData Science actions are now available by request in ETL. Domo has made it possible for every data owner to leverage powerful data science functions in their DataFlows\u00a0without the need to be an expert in data science modeling languages. This means you can enhance your data with powerful analytics just by adding the desired ETL action.\nThe following data science functions/methods are available:\nClassification (including Random Forest Classification and Naive Bayes)Clustering (including K Means and K Median)Forecasting (including ARIMA)MultivariateOutlier Detection (including Standard Deviation and Mean Absolute Deviation)Prediction (including Linear Regression and Random Forest)\nIn addition to all of the above, Python and R scripting actions are also available.\u00a0\n\u00a0\nDue to their complexity, Data Science and Scripting actions are currently available only by request. Please reach out to your CSM if you are interested in adding these actions to your company Domo\u00a0instance.\u00a0\u00a0\nFor more information, see\u00a0ETL Actions: Scripting.\nWorkbench 5 Beta Release\nWe are excited to announce that a brand new version of Workbench is going into an OPEN\u00a0BETA\u00a0release on October 23rd. This version will provide a cleaner, easier-to-navigate user interface and a\u00a0Home\u00a0screen that shows you the status of all of your jobs (shown below).", "source": "../../raw_kb/article/october_2018_release_notes/index.html", "title": "October 2018 Release Notes"}, {"objectID": "651ad69a489d-2", "text": "For more information, see\u00a0Connecting to Data Using Workbench 5.\nInsights and NLG Analysis\nBusinesses collect\u00a0massive amounts of data to inform their decision making. Using the story that the data tells them, business leaders are able to make critical decisions that impact their business. However, trying to find that story gets increasingly difficult as the size of the data grows at exponential rates, and the data changes every second.\u00a0Now Domo makes it easier than ever to find insights in your data.\nNLG (Natural Language Generation) Analysis uses natural language to tell you\u00a0what is interesting or exceptional about your\u00a0data. Where analysts have had to review data using statistical tools and write summaries as data changes, Domo\u2019s narratives automatically expose statistical information and interesting trends about your data, no matter the size of the DataSet or the frequency of updates, delivered in a language every business user can understand.\u00a0With the new Insights feature, you can now view a number of automatically-generated alerts for any given card. Insights\u00a0may be based on anomaly detection, discovered correlations, distribution mapping, and so on.\nBoth of these features are now available in a new Insights\u00a0feed that appears on the right side of the Details view for any KPI card. You can tailor your\u00a0feed to show you the most meaningful Insights and NLG Analyses by rating each one using a \"thumbs up\" or \"thumbs down\" icon.\nFor more information, see\u00a0KPI Card Details View.\nAlert Improvements\nContextual Alerts\nUsing Personalized Data Permissions is a great way to filter your data for different users. But just because it's useful\u00a0doesn't mean it needs to be complex.\u00a0With Contextual Alerts, by default any Alert you create automatically analyzes all the PDP policies that apply to the subscriber and notifies them accordingly. You no longer have to select specific policies to apply.", "source": "../../raw_kb/article/october_2018_release_notes/index.html", "title": "October 2018 Release Notes"}, {"objectID": "651ad69a489d-3", "text": "For more information, see\u00a0PDP and Alerts.\nFilter Support for Alerts\nNow when you set filters on either a page or card, those filters are honored when you go to create an alert on that page or card. A new option appears in the Create Alert Wizard that lets you choose whether or not to set the alert on the filtered view of the card. You can find this option selected by default when you create an alert from a card or page on which filters have been applied.", "source": "../../raw_kb/article/october_2018_release_notes/index.html", "title": "October 2018 Release Notes"}, {"objectID": "651ad69a489d-4", "text": "For more information, see\u00a0Creating a Custom Alert for a KPI Card.\nDisabled Alerts\nInstantly learn\u00a0when\u00a0alerts are broken as well as\u00a0how to correct the problem and get those\u00a0alerts back up and running again. When an alert gets into a broken state, it becomes disabled and shows up in red. It also gives you clear directions on how to solve the problem.\u00a0\nPayment Method Management\nUsers can now\u00a0instantly gain access to the full features of Domo simply by entering their billing information in Domo. This feature enables trial users to upgrade to full Domo\u00a0and also enables existing customers to add Domo licenses at will. Domo accepts any form of payment card as well as corporate invoicing from directly in the product.\u00a0\nSelf-service payment is now available for all users and all platforms. Freemium users can access the feature by clicking on the Buy Full Domo button or by clicking on\u00a0any of the locked features. Administrators of existing instances can add users to their instance by clicking on Licenses\u00a0in the Admin Settings.\u00a0\nHelp Center Updates\n,The following improvements have been made to our Help Center:\nTo enable you to more quickly find the Domo University resources, videos, Knowledge Base articles, and Dojo content you need, the Domo Help Center icon has been moved out of the\u00a0\u00a0menu and into the top navigation bar.  The navigation tiles in the Help Center have been updated to provide a cleaner and simpler experience. In addition, in the interest of making it easier to access our Video Library, a new \"How-to Videos\" tile has been added.  \nFor more information, see\u00a0Getting Help.\nJSON Webhooks", "source": "../../raw_kb/article/october_2018_release_notes/index.html", "title": "October 2018 Release Notes"}, {"objectID": "651ad69a489d-5", "text": "For more information, see\u00a0Getting Help.\nJSON Webhooks\nOur new\u00a0JSON Webhook connector allows you to connect to data sources that push JSON-formatted data, such as IFTTT, Github,and Fitbit.\u00a0Using JSON Webhooks, you can get access to real-time data from weather devices, vending machines, wearables, and more. The Webhook link includes a long-living single use token so anyone with the link can publish data to your DataSet.\nFor more information, see\u00a0JSON Webhook Connector.\u00a0\nAbility to Disable Chart Preview\nSave time editing your cards by turning off the new\u00a0Auto preview\u00a0toggle in Analyzer. By default, any changes you make to a card in Analyzer are reflected instantly in the preview for that card. When you turn off\u00a0Auto preview, the card\u00a0preview does not refresh\u00a0until you click the\u00a0Run Preview\u00a0button.\u00a0Because you have control over when you refresh, you can choose when to apply your changes, resulting in a more efficient card-building experience.", "source": "../../raw_kb/article/october_2018_release_notes/index.html", "title": "October 2018 Release Notes"}, {"objectID": "651ad69a489d-6", "text": "For more information, see\u00a0Analyzer Layout.\nDataFlow Scheduling\nDataFlow scheduling allows you to schedule a day and/or time when a\u00a0DataFlow will run. DataFlows that are configured with a schedule will only run when the scheduled time is due. Scheduling cannot be combined with the \"run automatically\" option.\u00a0\n\nFor more information, see\u00a0DataFlow Schedules.\nMobile Instance Switching\nDomo is pleased to announce another tool to ensure an uninterrupted experience when running your business from your phone: mobile app instance switching. Now no matter how big your company is or how many Domo accounts you have, you can easily access them all while on the go from the palm of your hand without having to log out and back in.\u00a0\nUpdate to the latest version of the Domo iOS or Android application and you're all set.\nGetting Help\u00a0\nYou can view the latest release notes information in the Help Center, which you can access from Domo by clicking\u00a0by clicking \u00a0in the top navigation bar .\nIf you have questions about Domo,\nsearch for a topic in the Help Centertrain in Domo University at\u00a0http://university.domo.comsearch for training apps in the Appstoreget answers in the Domo Community at\u00a0https://dojo.domo.comcontact Technical Support by entering a help ticket in the Domo Support Portal or\u00a0by sending a Buzz message to\u00a0/support.reach out to your Domo Customer Success Manager or Technical Consultant\nIf you have feedback, please send it from within Domo (\u00a0> Feedback). Or send an email to\u00a0product.feedback@domo.com.\nFor more information about getting help, see\u00a0Getting Help.", "source": "../../raw_kb/article/october_2018_release_notes/index.html", "title": "October 2018 Release Notes"}, {"objectID": "27dedc7a9118-0", "text": "Title\n\nOctober 2019 Release Notes\n\nArticle Body", "source": "../../raw_kb/article/october_2019_release_notes/index.html", "title": "October 2019 Release Notes"}, {"objectID": "27dedc7a9118-1", "text": "New features and enhancements\nFeatures and enhancements in this release include the following:\nBusiness Automation Engine: Alert Actions\nAlert Actions drive powerful action for your business by triggering events such as Webhook integration with third-party systems and Projects & Tasks integrations in Domo. The possibilities for Alert Actions are literally endless. For example...\nAs a retail store manager, you might already have an Alert that notifies you when a certain product has reached a threshold of units sold; with Alert Actions you could expand upon this basic Alert by having it also activate\u00a0a \"reorder\"\u00a0action in your\u00a0inventory system when it is triggered.As a sales leader, you could set an Alert Action to turn on sirens or music in your office when you've closed a large deal so everyone can celebrate together.As a support manager, you could set Alert Actions to automatically create tasks\u00a0in Domo\u00a0and assign them\u00a0to specified individuals whenever the number of open bugs exceeds a certain number.\u00a0\nTwo types of Alert Actions are currently available in Domo\u2014Webhooks and Tasks. With the Webhook action, you can connect to any of a number of third-party systems. With Task actions, you can create a Task in a specified Project and assign it to a certain person. You configure these actions in the Alert Wizard when you create an Alert or edit an existing Alert.\n  \nFor more information, see .\u00a0\u00a0\u00a0\u00a0\u00a0\nUpdated navigation\nDomo's new navigation makes it easy to organize and manage your Pages so that they are easier to find, regardless of whether you have just a few Pages or a few hundred. It also makes is possible to navigate to all of Domo\u2019s most used features in fewer clicks, decreasing the time it takes you to perform actions in Domo and get answers. For more information, watch this\u00a0demo video.", "source": "../../raw_kb/article/october_2019_release_notes/index.html", "title": "October 2019 Release Notes"}, {"objectID": "27dedc7a9118-2", "text": "The updated navigation will be available to all customers in our October release. Because of the magnitude of this change, the new navigation structure will not officially replace the old structure until March of 2020. Until then, all customers have the option to turn on the new navigation by going into the Admin Settings and selecting\u00a0Company Settings > Feature control, then switching\u00a0on the option reading \"Enable updated navigation for all users.\" (You must have Admin security privileges to do this.) This way, your organization has the freedom to make the transition whenever it is ready. Note that third-level and favorited Pages are only supported in the updated navigation, so if you switch back to the old navigation from the new navigation, these Pages won't be visible in the UI.\u00a0\nHere\u2019s a highlight list of some of the most notable improvements:\nImproved UI\nThe Pages menu has been moved to the left side\u00a0of the screen in a scrollable\u00a0\"Dashboards\" list. You can collapse this list, providing\u00a0more space when you want to focus on important dashboard content. If you want you can still show the list when it is in its collapsed state.\u00a0The list is searchable too, allowing you to quickly filter\u00a0down the list of Pages as you type.\n  You will also find shortcuts to your most important Domo functions now exposed at the top of the screen, giving you quicker access.", "source": "../../raw_kb/article/october_2019_release_notes/index.html", "title": "October 2019 Release Notes"}, {"objectID": "27dedc7a9118-3", "text": "Third-level Pages\nAn additional level of Page\u00a0hierarchy lets you create Subpages\u00a0of your Subpages. You have more options than ever for how you organize your Pages\u00a0to show related information.", "source": "../../raw_kb/article/october_2019_release_notes/index.html", "title": "October 2019 Release Notes"}, {"objectID": "27dedc7a9118-4", "text": "Favorite Pages\nYou can now mark Pages as \"favorites,\"\u00a0making it easier for you to get to your most important content in Domo. You can add any Page as a\u00a0\"favorite\" Page by choosing the Add to favorites\u00a0option in the wrench menu for the Page.\u00a0\n \u00a0\nOnce a Page is added as a Favorite, you can jump to it quickly by clicking\u00a0Favorites\u00a0at the top of the Pages list and selecting the Page you want to open. \u00a0\u00a0\nGetting Started Page\nThe new Getting Started Page gives users an improved login experience with easier access to several of the most important Domo functions.\u00a0This Page\u00a0enables you to get value out of Domo\u00a0faster by helping you find\u00a0important Cards and Pages, create Alerts, and join Buzz conversations. This will help guide new users to what they should be doing in Domo\u00a0and give them a meaningful login experience.\n \u00a0\nFor companies that have processes already in place to onboard new users\u00a0or that already have company landing Pages configured, there is an option to \u201cshut off\u201d this Page at the company settings level. This will allow Admin-level users\u00a0to hide the Getting Started\u00a0Page for all users at the company and keep their existing onboarding/login process, should they choose to.\u00a0\nFor more information, see\u00a0New Navigation Announcement.\nStreaming MP4 videos in Doc Cards\nEasily create more clarity for your viewers with MP4\u00a0video streaming in Doc Cards. You can view these videos either from the Page level (standard Pages and Domo Stories are both supported) or from the Doc Card Details view. You can also choose a custom image for your video's thumbnail or let Domo\u00a0choose a default thumbnail for you.", "source": "../../raw_kb/article/october_2019_release_notes/index.html", "title": "October 2019 Release Notes"}, {"objectID": "27dedc7a9118-5", "text": "Videos can be viewed in both Web and Mobile versions of Domo. Please note that\u00a0only\u00a0MP4 videos are supported at this time (no AVI, WMV, QuickTime, etc.). If your video is not an MP4\u00a0file, the video will not stream; you will just see the file icon. Also note that the file size limit for videos is 1GB\u00a0and the limit for custom thumbnail images is 10MB.\u00a0\n  \u00a0\nNo Code JSON Connector\nConnect custom data to Domo without writing any code using the No Code JSON Connector.\nUp until now, if you wanted to bring your custom data into Domo, you had to either ask someone at Domo to build a custom connector for you or create the connection using our API or Connector IDE, both code-intensive options. Now you can pull in your custom data just by following the steps in a simple wizard interface. The wizard will help you connect to your data as a JSON file and pull it into Domo.\u00a0\nTo use this tool, you will need the following:\nA client ID and client secret from developer.domo.comAn authorization URL and access token URL from your data providerThe URL to access the JSON file\nAccess the interface for this connector by searching for \"No-Code JSON OAuth Connector\" in the Appstore.", "source": "../../raw_kb/article/october_2019_release_notes/index.html", "title": "October 2019 Release Notes"}, {"objectID": "27dedc7a9118-6", "text": "DomoStats -\u00a0DataSets and DataFlows\nThe DataSets and DataFlows\u00a0App, the newest addition to our ever-expanding repertoire of DomoStats\u00a0Apps, comes with a pre-built dashboard that allows Admin users to...\nClean up Domo quickly by seeing which DataSets and DataFlows need attention, are orphaned or duplicated, etc., then selecting a direct link to take immediate action.Understand where to target efforts to fix DataSets and DataFlows with Cards that show what needs attention based on Card counts, owners, etc.Keep Domo secure by watching who is creating data and what data is coming into Domo.\nReady to take this App for a spin? Simply search for \"DomoStats\" in the Appstore, select the \"DomoStats - DataSets and DataFlows\" App, then click\u00a0Try it.\u00a0Note that you must have an \"Admin\"-level security role to deploy DomoStats Apps in Domo.\u00a0\n\n\u00a0\nNew Help Center\nFind all Domo learning materials in one place with our revamped Help Center. The Help Center provides access to all of the following:\n1700 Knowledge Base articles450+ how-to videos (embedded from YouTube)80+ free online training modulesOur Dojo user communityOptions for booking professional trainers\u00a0Support resources\nThe Help Center is public-facing, meaning you can access all of the above resources from Google.\u00a0\nTo access the Help Center, just click on the\u00a0\u00a0icon in the upper right corner of the screen.", "source": "../../raw_kb/article/october_2019_release_notes/index.html", "title": "October 2019 Release Notes"}, {"objectID": "27dedc7a9118-7", "text": "Data Impact Analysis\nDomo's Data Impact Analysis tool, available in the details view for a DataSet, helps you understand\u00a0the impact of actions you take on your DataSets.\nThis tool includes all of the following functions:\nImpact card. A\u00a0new card in the\u00a0Overview\u00a0tab shows you the number of DataSets, DataFlows, Cards, and Alerts directly and indirectly impacted by changes to that DataSet. The card displays the direct impact for each, along with the total number of impacts.  Lineage view.\u00a0This view shows you the upstream and downstream impact of changes made to the DataSet. You can also see the lineage for a DataSet\u00a0simply by clicking on the\u00a0Lineage\u00a0tab.  Info panel. This panel shows the owner, the number of direct and indirect impacts on downstream elements, input and outset DataSets (for DataFlows and DataFusions), the update history, and the number of rows and columns (for DataSets).List panel. This panel allows you to see all of the individual DataSets, DataFlows, Cards, and Alerts powered by this DataSet.  \nThis tool is currently available by request for any user who wants it. For more information about obtaining this tool, reach out to your CSM or AE.\nFor more information about using this feature, see\u00a0Viewing the Impact of Changes to DataSets.\nGetting help\u00a0\nYou can view the latest release notes information in the Help Center, which you can access from Domo by clicking\u00a0by clicking \u00a0in the top navigation bar .\nIf you have questions about Domo,", "source": "../../raw_kb/article/october_2019_release_notes/index.html", "title": "October 2019 Release Notes"}, {"objectID": "27dedc7a9118-8", "text": "If you have questions about Domo,\nsearch for a topic in the Help Centertrain in Domo University at\u00a0http://university.domo.comsearch for training apps in the Appstoreget answers in the Domo Community at\u00a0https://dojo.domo.comcontact Technical Support by entering a help ticket in the Domo Support Portal or\u00a0by sending a Buzz message to\u00a0/support.reach out to your Domo Customer Success Manager or Technical Consultant\nIf you have feedback, please send it from within Domo (\u00a0> Feedback). Or send an email to\u00a0product.feedback@domo.com.\nFor more information about getting help, see\u00a0Getting Help.", "source": "../../raw_kb/article/october_2019_release_notes/index.html", "title": "October 2019 Release Notes"}, {"objectID": "d3fd20f9a3d9-0", "text": "Title\n\nOctober 2020 Release Notes\n\nArticle Body\n\nNew features and enhancements\nFeatures and enhancements in this release include the following:\nBeast Mode Manager\nImprovements to Beast Mode Manager make managing your Beast Modes even easier.\nArchive Beast Modes\nYou now have the ability to archive Beast Modes. This removes Beast Modes from Cards or DataSets. You are only able to archive a Beast Mode if it is not in use on a Card. The archive feature is also available for bulk use. You can select up to 100 Beast Modes at a time when using bulk\u00a0archive. There is no limit to the total amount of Beast Modes that you can archive.\nYou can then unarchive\u00a0Beast Modes and it will restore it to the Card or DataSet it originated from. If a Card or DataSet is deleted, then the Beast Mode is also deleted. For more information, see Beast Mode Manager.\n\nDuplicate Beast Mode name modal\nInside of Analyzer, there is a new modal that appears when there is a duplicate Beast Mode name. This allows you to rename the Beast Mode or delete duplicate Beast Modes. For more information, see\u00a0Adding a Beast Mode Calculation to Your Chart.\n\nEnhanced Connector scheduling\nThe new Connector scheduler showcases a simplified\u00a0and streamlined UI that is easier to understand and\u00a0displays\u00a0your time zone when scheduling.\u00a0Connectors\u00a0are still scheduled in UTC, but our new Scheduler\u00a0shows you what time that converts to in your chosen\u00a0time zone. For more information, see Adding a DataSet Using a Data Connector.\n\n\nCode Block Apps\nCode Blocks allow users to copy and paste several different code types that can be used to create solutions to complex questions. This makes advanced functionality much more accessible.\u00a0For more information, see Code Block Apps.\nAvailable Code Block types:\nBeast ModesSQLRPythonJupyter Notebooks", "source": "../../raw_kb/article/october_2020_release_notes/index.html", "title": "October 2020 Release Notes"}, {"objectID": "d3fd20f9a3d9-1", "text": "Public\u00a0Domo\u00a0App assets\nYou now have the ability\u00a0to share assets like pictures or javascript code between your custom Domo app and your public website. You also have the option\u00a0to build your public website directly on Domo instead of having to find another hosting provider. For more information, see Public Domo App Assets.\nBuzz Conversation toggle\nWith the new Buzz Conversation toggle arrows, you can easily switch between your\u00a0Buzz messages. Use the arrows to move back and forth through conversations as you viewed them. For more information, see Buzz Layout.\n\nGoals\nWith Domo Goals you can power your company objectives by measurable data, watch progress with automatic updates and alerts, and create top to bottom alignment. With Goals you also have visibility into everyone\u2019s goals and\u00a0track how goals interrelate and progress. For more information, see Creating and Editing Goals.\nWith Goals you can,\nSet company, department, and\u00a0personal goals that everyone can view.Measure the results with metrics powered by data in Domo.Align your objectives with your company, department,\u00a0and\u00a0team so everyone can see how your work fits into the big picture.View your progress as it updates in real-time with your data.Check-in with regular updates so everyone knows how you\u2019re progressing.Create powerful dashboards to analyze your company\u2019s progress.Easily show which individual objectives align with company goals.", "source": "../../raw_kb/article/october_2020_release_notes/index.html", "title": "October 2020 Release Notes"}, {"objectID": "d3fd20f9a3d9-2", "text": "Federated Data\nDomo's Federated Data model allows you to directly render Cards and other user-level interactions in the Domo platform using a database hosted outside of Domo's cloud. Instead of executing the visualization query against Domo, the query is executed at the target database and the results are sent to Domo to render the visualization. This model is especially relevant for users who would like to keep their data at rest in their infrastructure for security or logistical reasons. For more information, see Using the Federated Data Solution.\nMagic ETL v2 (Beta)\nMagic ETL v2 (Beta) has many backend\u00a0and tile improvements\u00a0as well as new tiles. When you open the edit view of a Magic ETL DataFlow, there is now a toggle switch to enable Magic ETL v2. It is important to note that some of the tiles have changed their functionality. For more information, see Magic ETL\u00a0v2 DataFlow Optimizations.\n\n\n\u00a0\n\nImportant: You MUST read through the following article before switching an existing Magic ETL DataFlow to v2 or you risk breaking your DataFlow as several tiles have changed their functionality:\u00a0Upgrading to Magic ETL v2", "source": "../../raw_kb/article/october_2020_release_notes/index.html", "title": "October 2020 Release Notes"}, {"objectID": "d3fd20f9a3d9-3", "text": "The following is a list of Magic ETL v2 features:\u00a0\nFaster runtimesNew tile categorizationsSearchable tooltip text\u00a0Color-coded and curved linesExpression support (Add Formula, Filter Rows, and Group By tiles)Views as InputsEnhancements to data type classifyingEnhancements to error handlingJoin tile updatesAppend tile optimizationsValue Mapper tile\u00a0updatesPivot and Unpivot tiles (renamed from Collapse\u00a0and Uncollapse\u00a0Columns)New Dynamic Unpivot tileImprovements to the Python Script and R Script tiles\u00a0(dropped required schema tab)\u00a0Selectable text in data previews\nGetting help\nYou can view the latest release notes information in the Help Center, which you can access from Domo by clicking \u00a0in the top navigation bar.\nIf you have questions about Domo,\nsearch for a topic in the Help Centertrain in Domo University at\u00a0http://domo.com/university/search for training apps in the Appstoreget answers in the Domo Community at\u00a0https://dojo.domo.comcontact Technical Support by entering a help ticket in the Domo Support Portalreach out to your Domo Customer Success Manager or Technical Consultant\nIf you have feedback, please send it from within Domo (More\u00a0> Feedback). Or send an email to\u00a0product.feedback@domo.com.\nFor more information about getting help, see\u00a0Getting Help.", "source": "../../raw_kb/article/october_2020_release_notes/index.html", "title": "October 2020 Release Notes"}, {"objectID": "9cd3a97328df-0", "text": "Title\n\nOctober 2021 Release Notes\n\nArticle Body\n\nNew features and enhancements\nFeatures and enhancements in this release include the following:\nNew Magic ETL\nThe new Magic ETL has many backend and tile improvements as well as new tiles. When you open the edit view of a Magic ETL DataFlow, there is now a toggle switch to enable the new Magic ETL. It is important to note that some of the tiles have changed their functionality. For more information, see What's New in the New Magic ETL.\n\n\n\n\n\n\nImportant: You MUST read through the following article before switching an existing Magic ETL DataFlow to the new Magic ETL or you risk breaking your DataFlow as several tiles have changed their functionality: Upgrading to the New Magic ETL.\n\n\n\nThe following is a list of the new Magic ETL features:\u00a0\nFaster runtimes.New tile categorizations.Searchable tooltip text.Color-coded and curved lines.Expression support (Add Formula, Filter Rows, and Group By tiles.)Views as Inputs.Enhancements to data type classifying.Enhancements to error handling.Join tile updates.Append tile optimizations.Value Mapper tile updates.Pivot and Unpivot tiles (renamed from Collapse and Uncollapse Columns.)New Dynamic Unpivot tile.Improvements to the Python Script and R Script tiles (dropped required schema tab.)\u00a0Selectable text in data previews.\nEnhanced DataFlow scheduling capabilities\nWith the enhanced DataFlow scheduling options, you can now schedule a DataFlow to run on a specific schedule, such as:\nSpecific calendar days (1st, 15th, and 28th of the month.)Specific day of the week (Last Friday.)Only during active hours (Every 2 hours between 8 AM to 5 PM.)Annually or Quarterly.\nYou are also able to set the time that it runs in your time zone, instead of the default of UTC. For more information, see Scheduling DataFlows.", "source": "../../raw_kb/article/october_2021_release_notes/index.html", "title": "October 2021 Release Notes"}, {"objectID": "9cd3a97328df-1", "text": "New Connector wizard in the Data Center\nWith the new Connector wizard in the Data Center, you are able to easily select the type of Connector you need with filtered tabs to specific Connector types. Preferred Connectors are listed first for easy access to the most popular or recommended Connectors. The wizard includes inline configuration for easy Connector setup. For more information, see Adding a DataSet Using a Connector.\n\nNew Resource Library\nThe Guide Center has been updated to the Resource Library. The new Resource Library allows you to view Guides and walkthroughs, find additional Resources, and review Product announcements. For more information, see Resource Library.\n\nUser-Specific Landing Pages\nWith User-Specific Landing Pages, both Admins and end-users can set a specific Page or Card to open when they log into Domo. This allows you to customize the view for users in a specific department or to bring up the Page/Card you use the most without extra navigation clicks. For more information, see Setting User-Specific Landing Pages.\n\u00a0\n\nNew DomoStats Reports\nThe DomoStats Connector now has four new reports to choose from:\nAccounts -\u00a0Shows the Accounts in an instance.Accounts with Permissions -\u00a0Shows the Accounts in an instance as well as who has access to these Accounts and at what permission level.DataSet Access - Shows which users or groups have access to which DataSets and what permission level they have.DataSet Tags - Shows which tags are assigned to which DataSets.\nFor more information, see DomoStats Connector.", "source": "../../raw_kb/article/october_2021_release_notes/index.html", "title": "October 2021 Release Notes"}, {"objectID": "9cd3a97328df-2", "text": "Premium features\nThese features are available on demand and paid. To request these features be enabled, reach out to your Domo Customer Success Manager, Technical Consultant,\u00a0or Account Executive. If you do not have contact information for your CSM, TC, or AE, contact Technical Support. For information on how to contact Support, please see\u00a0Getting Help. Depending on the feature, you may be required to complete training before you can use the feature.\nCard Details maximization modal in Dashboard Embed\nWith the Card Details maximization modal in Dashboard Embed, you can now click on the Expand details icon to see the Card Details view of the Card. In this view, you can now export the visuals to PDF or PowerPoint and it will reflect all Filters and interactions applied to the Card. For more information, see Sharing Cards and Dashboards Outside of Domo Using Domo Embed.\n\nCustom Login Screen\nCustom Login Screen gives Admins the ability to change the login screen to their desired background image or color. This allows you to display your brand and have a more consistent user experience. This is part of our Brand Kit features. For more information, see Custom Login Screen.\n\n\u00a0\nGetting help\nYou can view the latest release notes information in the Help Center, which you can access from Domo by clicking \u00a0in the top navigation bar.\nIf you have questions about Domo,\nsearch for a topic in the Help Centertrain in Domo University at\u00a0http://domo.com/university/search for training apps in the Appstoreget answers in the Domo Community at\u00a0https://dojo.domo.comcontact Technical Support by entering a help ticket in the Domo Support Portalreach out to your Domo Customer Success Manager or Technical Consultant\nIf you have feedback, please send it from within Domo (More\u00a0> Feedback). Or send an email to\u00a0product.feedback@domo.com.\nFor more information about getting help, see\u00a0Getting Help.", "source": "../../raw_kb/article/october_2021_release_notes/index.html", "title": "October 2021 Release Notes"}, {"objectID": "64e455af774e-0", "text": "TitleOData ConnectorArticle BodyIntro\nOData (Open Data Protocol) is an OASIS standard that defines the best practice for building and consuming queryable and interoperable REST APIs in a simple and standard way. OData helps you focus on your business logic while building RESTful APIs without having to worry about the various approaches to define request and response headers, status codes, HTTP methods, URL conventions, payload formats, query options, etc. Use Domo's OData connector to pull the data exposed through the OData endpoints.\u00a0To learn more about OData, visit their page https://www.odata.org/.\nYou connect to your OData account in the Data Center. This topic discusses the fields and menus that are specific to the OData connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your OData account and create a DataSet, you must have the username and password associated with your OData account.\nConnecting to Your OData Account\nThis section enumerates the options in the Credentials and Details panes in the OData\u00a0Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your OData\u00a0account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionUsernameEnter the username associated with your OData account.PasswordEnter the password associated with your OData account.URLEnter the OData endpoint URL.", "source": "../../raw_kb/article/odata_connector/index.html", "title": "OData Connector"}, {"objectID": "64e455af774e-1", "text": "Once you have entered valid OData credentials, you can use the same account any time you go to create a new OData DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.\nMenuDescriptionData TagEnter the data tag key.Fields To ExpandEnter the comma separated list of fields you would like to expand in the data. This will cause multiple rows to show each object for the entered fields.Select Data FilterSpecify the data filter method for your data.All DataReturns all available data.Use Date FilterFilters the data for the selected date range.Backfill DataBackfills the data for the specific field.Data Filter FieldEnter the same date filter field name available in response in order to filter the response.Backfill FieldEnter the field name that you want to backfill your data for. This functionality works only for the append mode. Note: The Backfill field must be present in the response and it must be of integer type.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding a DataSet Using a Data Connector.", "source": "../../raw_kb/article/odata_connector/index.html", "title": "OData Connector"}, {"objectID": "0f3765f4c753-0", "text": "TitleOfficeRnD ConnectorArticle BodyIntro\nThe OfficeRnD co-working and flex platform helps customers book office space. It simplifies the process by automating administrative tasks, providing key details to make data-driven decisions, and delivering an amazing digital experience to customers. It helps space administrators focus on work, get access to required knowledge, and connect with like-minded professionals to enable sustainable growth in their business.The Domo OfficeRnD connector enables you to retrieve various details about bookings, credits, contracts, offices, payments, and more. When you connect OfficeRnD with Domo, you\u2019ll see all the critical data you need to manage your workspaces along with costs and customer management. Your team will be able to use this data to have an all-in-one view of how your business is functioning and where potential problems may occur.You can create powerful visualizations and reports to track all the data your OfficeRnD solution captures to keep your business running. Combine your OfficeRnD data with all your information on Domo to see how your workspaces affect your bottom line and plan for future business demands. To learn more about the OfficeRnD API, visit their page (https://developer.officernd.com/docs).\nThe OfficeRnD Connector is a \"Cloud App\" Connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the Connector page for this and other Cloud App Connectors by clicking Cloud App in the toolbar at the top of the window.\nYou connect to your OfficeRnD account in the Data Center. This topic discusses the fields and menus that are specific to the our Officernd API\u00a0Connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your OfficeRnD account and create a DataSet, you must have the following:", "source": "../../raw_kb/article/officernd_connector/index.html", "title": "OfficeRnD Connector"}, {"objectID": "0f3765f4c753-1", "text": "To connect to your OfficeRnD account and create a DataSet, you must have the following:\nThe client ID and client secret associated with your OfficeRnD API.The Organization name for your OfficeRnD environment. You can find this in the API URL. For example, if your API URL is \"https://app.officernd.com/api/v1/organizations/domo\"\" then your organizations is \"domo\".\u00a0\nConnecting to Your OfficeRnD Account\nThis section enumerates the options in the Credentials and Details panes in the OfficeRnD  Connector page. The components of the other panes in this page, Scheduling and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your OfficeRnD account. The following table describes what is needed for each field:\nFieldDescriptionClient IDEnter the client ID associated with your OfficeRnD API.Client SecretEnter the client secret associated with your OfficeRnD API.OrganizationEnter the Organization name for your OfficeRnD environment. You can find this in the API URL. \nFor example, if your API URL is \"https://app.officernd.com/api/v1/organizations/domo\"\" then your organizations is \"domo\".\u00a0\nOnce you have entered valid OfficeRnD credentials, you can use the same account any time you go to create a new OfficeRnD DataSet. You can manage Connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary Reports menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/officernd_connector/index.html", "title": "OfficeRnD Connector"}, {"objectID": "0f3765f4c753-2", "text": "MenuDescriptionReportSelect the OfficeRnD report you want to run. The following reports are available:ReportDescriptionBookingsRetrieves all bookings made for reservation of resources.Booking OccurrencesRetrieves a list of all booking occurrences for a specified period.ChargesRetrieves all charge objects. A charge object describes a single payment associated with an invoice.CheckinsRetrieves all checkins. Checkins represent member presence at a certain office.ContractsRetrieves all contracts. A contract object allows one to associate contract data to the companies.Credit AccountsRetrieves coin credit balance for a team/member in a specific month.FeesRetrieves all fee objects. A fee object describes one-off charges or groups of one-off charges.FloorsRetrieves all floors in the space.IssuesRetrieves all issues.MembersRetrieves all members. A member has all the member's data in a single place like memberships, invoices, charges, fees, etc.MembershipsRetrieves all memberships. A membership object allows to assign recurring charges (price plans) to individual members or teams.OfficesRetrieves all separate physical locations in the space.PassesRetrieves all passes.PaymentsRetrieves", "source": "../../raw_kb/article/officernd_connector/index.html", "title": "OfficeRnD Connector"}, {"objectID": "0f3765f4c753-3", "text": "in the space.PassesRetrieves all passes.PaymentsRetrieves all payment objects (invoices / credit notes)PlansRetrieves all plans. A plan object allows to create one-off or recurring named charges.RatesRetrieves all resource rates.ResourcesRetrieves all types of resources.Resource TypesRetrieves all resource types in the organization.TeamsRetrieves all teams.VisitsRetrieves visits in the organization.Field To ExpandSelect the field that you would like to expand in the data. This will cause multiple rows to show each object in the selected field. You will not be able to expand any data, if \"None\" is selected.Date Selection CriteriaSelect the type of date you want to filter the data for. Select \"All Data\" if you don't want to filter the data or want to get all data.Filter Data By DateSelect this check box if you would like to filter the data for the selected duration.Date SelectionSelect the date format for your data.Single DateSelect whether the report data is for a specific date or for a relative number of days back from today.Specific DateSelect the specific date using the date selector.Relative", "source": "../../raw_kb/article/officernd_connector/index.html", "title": "OfficeRnD Connector"}, {"objectID": "0f3765f4c753-4", "text": "DateSelect the specific date using the date selector.Relative DateEnter the number of days back that you would like to get data for in the\u00a0Days Back\u00a0field. Specify either today or 0, yesterday or 1, or today-7 or 7 to get data for 7 days into the past.Date RangeSelect the specific or relative date range.Start Date - SpecificSelect\u00a0the first date in your date range using the date selector.End Date - SpecificSelect the last date in your date range\u00a0using the date selector.Start Date - RelativeEnter the number of days back that you would like to get data from (start day). Combine with\u00a0End Date\u00a0to create a range of represented days.", "source": "../../raw_kb/article/officernd_connector/index.html", "title": "OfficeRnD Connector"}, {"objectID": "0f3765f4c753-5", "text": "For example, if you entered\u00a010\u00a0for\u00a0Start Date\u00a0and\u00a05\u00a0for\u00a0End Date, the report would contain data for\u00a010 days ago up until\u00a05 days ago.End Date - RelativeEnter the number of days back that you would like to get data to (end day). Combine with\u00a0Start Date\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Start Date\u00a0and\u00a05\u00a0for\u00a0End Date, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Time PeriodSpecify the time period that you would like to receive data for.Starting Day of the WeekSelect the day you would like your week to start with.\nOther Panes\nFor information about the remaining sections of the Connector interface, including how to configure scheduling, retry, and update options, see Adding a DataSet Using a Data Connector.\nFAQs\nWhat endpoint is the base URL for this connector?\nThe base URL for the OfficeRnD connector is https://app.officernd.com/api/v1/organizations/{orgSlug}).\nWhich endpoint(s) does each report call in this connector?\nReport NameEndpoint URL(s)Bookings/bookingsBooking Occurrences/bookings/occurrencesCharges/chargesCheckins/checkinsContracts/contractsCredit Accounts/credit-accounts/statsFees/feesFloors/floorsIssues/issuesMembers/membersMemberships/membershipsOffices/officesPasses/passesPayments/paymentsPlans/plansRates/ratesResources/resourcesResource Types/resource-typesTeams/teamsVisits/visits\nWhat kind of credentials do I need to power up this connector?\nYou need your client ID and client secret associated with your OfficeRnD API. You also need the organization for your OfficeRnD environment.\nWhere can I find my organization?", "source": "../../raw_kb/article/officernd_connector/index.html", "title": "OfficeRnD Connector"}, {"objectID": "0f3765f4c753-6", "text": "Where can I find my organization?\nYou can find your organization in the API URL. For example, if your API URL is \"https://app.officernd.com/api/v1/organizations/domo\"\" then your organization is \"domo\".\nHow often can the data be updated?\nAs often as needed.\nAre there any API limits that I need to be aware of?\nNo\nTroubleshooting\nMake sure your authentication remains valid.Review the configuration to make sure that all required items have been selected.Review the Connector history for error messages.In rare cases, you may be requesting too much information and reaching API limitations or timeouts. If this is the case, you can review the history of the Connector run to see the error message and duration. If this is the case, you can reduce the number of accounts that are being pulled, choose a smaller number of metrics for the report that you are pulling, or reduce the timeframe that you are trying to pull.", "source": "../../raw_kb/article/officernd_connector/index.html", "title": "OfficeRnD Connector"}, {"objectID": "ed5c4a9a0321-0", "text": "TitleOfficeSpace ConnectorArticle BodyIntro\nOfficeSpace is more than just a workplace management software, it\u2019s a search engine for your workplace. OfficeSpace offers a platform for managing facilities of every size. It is designed to help you find simple and quick solutions for your complex workplace challenges. It also reduces real estate costs. Use Domo's OfficeSpace connector to understand and manage your workspace in a simpler, smarter, and easier way. To learn more about OfficeSpace, visit their page https://www.officespacesoftware.com/technology/integrations.\nYou connect to your OfficeSpace account in the Data Center. This topic discusses the fields and menus that are specific to the OfficeSpace connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your OfficeSpace account and create a DataSet, you must have the following:\nYour OfficeSpace domain name\u00a0Your OfficeSpace API Key\nConnecting to Your OfficeSpace Account\nThis section enumerates the options in the Credentials and Details panes in the OfficeSpace Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your (third-party tool) account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionDomain NameEnter your OfficeSpace domain name.API KeyEnter your OfficeSpace API Key.\nOnce you have entered valid OfficeSpace credentials, you can use the same account any time you go to create a new OfficeSpace DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane", "source": "../../raw_kb/article/officespace_connector/index.html", "title": "OfficeSpace Connector"}, {"objectID": "ed5c4a9a0321-1", "text": "Details Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/officespace_connector/index.html", "title": "OfficeSpace Connector"}, {"objectID": "ed5c4a9a0321-2", "text": "MenuDescriptionReportSelect the OfficeSpace report you want to run.\u00a0The following reports are available:Bookable DesksRetrieves a list of all currently available desks.Canceled MovesRetrieves a list of moves canceled within the date range.Completed MovesRetrieves a list of moves completed within the date range.DirectoriesRetrieves a list of all directories.EmployeesRetrieves a list of employees.Floor AttributesRetrieves\u00a0the floor attributes for the given floor ID.FloorsRetrieves a list of all floors.Form ExtensionRetrieves the list of field definitions.Pending MovesRetrieves a list of all pending moves.Room AttributesRetrieves a list of attributes in a room.RoomsRetrieves a list of all rooms.Seat AssetsRetrieves a list of assets on a seat.Seat AvailabilitiesRetrieves all seat availability.SeatsRetrieves a list of all seats.Site AttributesRetrieves a list of attributes on a site.SitesRetrieves a list of all sites.UsersRetrieves a list of all users.Filter Data By DateSelect this check box if you would like to filter the data for the selected duration.Floor IDSelect the floor ID to fetch the data", "source": "../../raw_kb/article/officespace_connector/index.html", "title": "OfficeSpace Connector"}, {"objectID": "ed5c4a9a0321-3", "text": "duration.Floor IDSelect the floor ID to fetch the data for.Room IDSelect the room ID to fetch the data for.Seat IDSelect the seat ID to fetch the data for.Site IDSelect the site ID to fetch the data for.Date SelectionSelect the date format for your data.Single DateSelect whether the report data is for a specific date or for a relative number of days back from today.Specific DateSelect the specific date using the date selector.Relative DateEnter the number of days back that you would like to get data for in the\u00a0Days Back\u00a0field. Specify either today or 0, yesterday or 1, or today-7 or 7 to get data for 7 days into the past.Date RangeSelect the specific or relative date range.Start Date - SpecificSelect\u00a0the first date in your date range using the date selector.End Date - SpecificSelect the last date in your date range\u00a0using the date selector.Start Date - RelativeEnter the number of days back that you would like to get data from (start day). Combine with\u00a0End Date\u00a0to create a range of represented days.", "source": "../../raw_kb/article/officespace_connector/index.html", "title": "OfficeSpace Connector"}, {"objectID": "ed5c4a9a0321-4", "text": "For example, if you entered\u00a010\u00a0for\u00a0Start Date\u00a0and\u00a05\u00a0for\u00a0End Date, the report would contain data for\u00a010 days ago up until\u00a05 days ago.End Date - RelativeEnter the number of days back that you would like to get data to (end day). Combine with\u00a0Start Date\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Start Date\u00a0and\u00a05\u00a0for\u00a0End Date, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Time PeriodSpecify the time period that you would like to receive data for.Starting Day of the WeekSelect the day you would like your week to start with.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/officespace_connector/index.html", "title": "OfficeSpace Connector"}, {"objectID": "fd173192448c-0", "text": "TitleOkta ConnectorArticle BodyIntro\nOkta provides secure identity management and Single Sign-On for\u00a0any application. To learn more about the Okta API, visit their page (https://developer.okta.com/docs/api/...ces/users.html).\nYou connect to your Okta account in the Data Center. This topic discusses the fields and menus that are specific to the Okta connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Okta account and create a DataSet, you must have the following:\nThe domain for your company Okta\u00a0instance (e.g. okta.mycompany.com).\u00a0An Okta API token. For information about obtaining a token, see\u00a0https://developer.okta.com/docs/api/...g_a_token.html.\u00a0\nConnecting to Your Okta Account\nThis section enumerates the options in the Credentials and Details panes in the Okta Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Okta account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionDomainEnter the domain for your company Okta instance\u00a0(e.g. okta.mycompany.com).API TokenEnter your\u00a0Okta API token. For information about obtaining a token, see\u00a0https://developer.okta.com/docs/api/...g_a_token.html.\nOnce you have entered valid Okta credentials, you can use the same account any time you go to create a new Okta DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.", "source": "../../raw_kb/article/okta_connector/index.html", "title": "Okta Connector"}, {"objectID": "fd173192448c-1", "text": "Details Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.\nMenuDescriptionReportSelect the Okta report you want to run.\u00a0The following reports are available:Applications (Apps)Returns a list of Okta-enabled apps added to your organization.EventsReturns a list of events from your Okta organization system log.GroupsReturns a list of Okta groups in your organization.UsersReturns a list of Okta users in your organization.ZonesReturns a list of zones.Search Term (Optional)Enter the term you want to return data for in your \"Groups\" report.\u00a0Published Start Date\u00a0Select the start date for your \"Events\" report. Pair with\u00a0Published End Date\u00a0to return a range of dates.Published End Date\u00a0Select the end date for your \"Events\" report. Pair with\u00a0Published Start Date\u00a0to return a range of dates.Filter By\u00a0Select whether you want to filter by group or user.User NameSelect the user you want to filter by.Group NameSelect the group you want to filter by.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/okta_connector/index.html", "title": "Okta Connector"}, {"objectID": "5006a61e4df4-0", "text": "TitleOld Magic ETL Tiles: DataSetsArticle BodyIntro\n\u00a0\n\n\n\u00a0\n\nNote: This article is for the old Magic ETL. For information on the new Magic ETL, see Magic ETL.\n\n\n\nInput and output DataSets are required for all Magic ETL transformation flows. At least one input DataSet is required, though you can include as many as necessary. One output DataSet is required at the end of a transformation flow; this is the DataSet you can then use to power Domo cards and apps.\u00a0\u00a0\nFor information about creating a Magic ETL DataFlow, see Creating a Magic ETL DataFlow.\nFor information about the Data Center, see Data Center Layout.\n\n\n\u00a0\n\n\nImportant:\u00a0Input DataSets\u00a0in a DataFlow\u00a0cannot be restricted by PDP policies\u2014all available rows\u00a0must\u00a0pass through the DataFlow. Because of this you must apply PDP policies to the output DataSets generated by a DataFlow.\u00a0\nWhen you build a DataFlow using an input DataSet\u00a0with PDP\u00a0policies in place,\u00a0the DataFlow breaks unless\u00a0at least one of the following criteria\u00a0applies:\nYou have an \"Admin\" security profile or a custom role with \"Manage DataFlows\" enabled.You are\u00a0the DataSet owner.You are\u00a0part of the \"All Rows\" policy. This gives you access to all of the rows in the DataSet.\nFor more information about using PDP with DataFlows, see\u00a0PDP and DataFusions/DataFlows.\u00a0\n\n\n\n\nInput DataSet\nYou can use the Input DataSet tile to add a DataSet to the transformation flow.\nThere must be at least one Input DataSet in a transformation flow.\n\n\n\u00a0\n\nNote: The maximum number of columns allowed in the Magic ETL is 1500 columns.", "source": "../../raw_kb/article/old_magic_etl_tiles_datasets/index.html", "title": "Old Magic ETL Tiles: DataSets"}, {"objectID": "5006a61e4df4-1", "text": "Configuration\nTo configure the Input DataSet tile,\nEnsure that the data you want to transform already exists in Domo as a DataSet.Click the\u00a0Input DataSet tile, then select the DataSet you want to transform.\u00a0\nDetails\nUnder the\u00a0Details\u00a0tab of the input tile, you can view the DataSets:\nNameOwnerNumber of rowsLast UpdatedColumn names and type\nData\nSelect the Data\u00a0tab to preview a\u00a0table of the input data.\nOutput DataSet\nYou can use the Output DataSet tile to output the transformed data as a DataSet.\u00a0You can use this new DataSet to power up cards (or other DataFlows).\nThere must be an Output DataSet in a transformation flow.\n\n\n\u00a0\n\nNote:\u00a0Based on scheduled run settings, whenever the specified Input DataSet changes, the Magic ETL Dataflow performs the transform, updating the Output DataSet. For information about scheduling a Magic ETL DataFlow, see Scheduling a Magic ETL\u00a0DataFlow.\n\n\n\nConfiguration\nTo configure the Output DataSet tile,\nEnsure that a tile is connected to the Output DataSet tile and that all tiles are connected and configured in the transformation flow.Click the\u00a0Output DataSet tile, then specify the name of the DataSet you want to output by clicking \u00a0and entering a name and a description.\n\n\n\u00a0\n\nTip:\u00a0You can preview the data in the output DataSet by running a preview, clicking the Output DataSet tile, then clicking the Preview tab.\n\n\n\nDetails\u00a0\nIf the DataFlow has not run yet, the details available are the\u00a0owner, column names, and column types. Once run successfully, you are able to view all of the same details listed above for the input tile.", "source": "../../raw_kb/article/old_magic_etl_tiles_datasets/index.html", "title": "Old Magic ETL Tiles: DataSets"}, {"objectID": "f6acc6b9c05d-0", "text": "TitleOld Magic ETL Tiles: Data ScienceArticle Body\n\n\u00a0\n\n\nNote: This premium feature is available on demand.\u00a0\nTo request\u00a0pricing and availability for this feature,\u00a0 reach out to your Domo Account Representative\n\u00a0\nDepending on the feature, you may be required to complete training before you can use the feature.\n\n\n\n\nIntro\n\u00a0\n\n\n\u00a0\n\nNote: This article is for the old Magic ETL. For information on the new Magic ETL, see Magic ETL.\n\n\n\nThis article describes in detail all of the\u00a0Data Science tiles in Magic ETL, including the following:\nClassificationClusteringForecastingMultivariate OutliersOutlier DetectionPrediction\n\n\n\u00a0\n\nNote:\u00a0To perform accurate and efficient data science analysis on your data, we recommend using clean data. See Data Cleaning and Feature Engineering for more information.\n\n\n\nVideo - Data Science Tiles in Magic ETL", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-1", "text": "Video - Data Science Tiles in Magic ETL\n\n\u00a0\nClassification\nThe classification (predicting categorical values instead of numeric) algorithms aim to build statistical models which predict a categorical column in your data. The models can then be used to classify values of that column on new data. It is recommended that multiple methods be used and compared by the user.\nThis tile requires one training DataSet and an optional testing/validation DataSet. The training DataSet will contain one categorical column (dependent column), and both the training and test DataSets will contain 1 or more numeric and/or categorical columns (predictor columns). Within the Classification tile, you can choose from either Na\u00efve Bayes or Random Forest.\nNa\u00efve Bayes Classifier\nNa\u00efve Bayes\u00a0classification is faster and simpler than other classification algorithms but also often less precise. It is recommended for use on larger DataSets.\nRandom Forest Classifier\nRandom forest classification is an ensemble learning method that\u00a0builds multiple decision trees and combines the results to obtain an overall classification. No assumptions of linearity are needed. The algorithm is more robust against extreme values in your data.\nExample\nThe following example illustrates how the Classification algorithm can be implemented and used in Magic ETL in Domo. The sample DataSets: Catastrophic_Train.xlsx\u00a0(800 rows) and\u00a0Catastrophic_Test.xlsx\u00a0(200 rows) are artificially generated DataSets\u00a0and can be downloaded if you would like to try this example.\u00a0 They contain data on insurance claims where the goal is to train a Classification algorithm which can accurately classify a new claim as catastrophic or not.\u00a0\nA snapshot of the \u201cCatastrophic\u00a0Train.xlsx\u201d DataSet is found below.", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-2", "text": "The column of interest that we\u00a0want to classify is \"catastrophic\"\u00a0which is observed in this DataSet.\u00a0This DataSet will be used to \"train\"\u00a0a classification algorithm that can\u00a0be used on future DataSets\u00a0where the \"catastrophic\"\u00a0status may not be known.\u00a0\nA snapshot of the \"Catastrophic\u00a0Test.xlsxWholesale_Distributor_Sales.xlsx\" DataSet is found below.", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-3", "text": "Note that \"catastrophic\"\u00a0is not in the test DataSet.\nTo configure the Classification tile,\u00a0\nAdd the Classification Data Science tile and connect it to your input DataSets.  First, you must select a DataSet that will be used to train the algorithm and one that will be predicted.\u00a0Note that these could be the same DataSet,\u00a0but may be separate if you have separate training and test/validation DataSets.  Next, select the column that you want to classify. Then, the columns that you believe may help classify must be selected next with the numeric columns selected first (note that this can be left blank).  The categorical classifier columns must be selected (note that this may be left blank if at least one column was selected as a numeric classifier in the previous step). The name of the classification column must also be named. In this case, the default name \"classification\" is used.  Lastly, select either Na\u00efve Bayes or Random Forest as the algorithm powering the Classification tile.  Connect and name the output DataSet. The resulting DataSet will include the original DataSet with the appended 'classification' column.  \nClustering\nThe Clustering algorithm aims to group\u00a0a set of objects in such a way that objects in the same group are more similar to each other than to those in other groups. This is particularly useful in the exploratory phase of data analysis as it allows the user to begin to uncover patterns and groupings that may not be obvious.\nThis tile requires at least 1 numeric column and a number of clusters to cluster by (K). You can also choose from either a K-means or K-medians algorithm.\u00a0\nK-means Clustering", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-4", "text": "K-means Clustering\nK-means forms clusters by randomly selecting k rows from the DataSet and treating them as cluster centers. The k clusters are then formed based on each row\u2019s distance to the cluster center. The mean of each cluster is then calculated and treated as the new cluster center. This process is repeated until cluster membership stabilizes.\nK-medians Clustering\nK-medians forms clusters by randomly selecting k rows from the DataSet and treating them as cluster centers. The k clusters are then formed based on each row\u2019s distance to the cluster center. The median of each cluster is then calculated and treated as the new cluster center. This process is repeated until cluster membership stabilizes.\nExample\nThe following example illustrates how the clustering algorithm can be implemented and used in Magic ETL in Domo. The sample DataSet:\u00a0 Wholesale_Distributor_Sales.xlsx\u00a0(440 rows) can be downloaded if you would like to try this example.It contains annual spending information (in monetary units, \u201cm.u.\u201d) on various product\u00a0categories from clients of a wholesale distributor. Each row contains data for a single client.\u00a0The first two columns are Region and Channel, which describe demographic information for\u00a0each client. The next 6 columns contain the spending information on each of the 6 product\u00a0categories: Fresh, Milk, Grocery, Frozen, Detergents_Paper, and Delicatessen. The Clustering algorithm can be used to cluster the clients according to how much was spent on the\u00a0various product categories.\nTo configure the Clustering tile,", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-5", "text": "To configure the Clustering tile,\u00a0\nAdd the Clustering tile to your Magic ETL and connect it to the input DataSet.\u00a0 Select the columns you want to use to determine the clusters. You must have at least one numeric column and only numeric columns can be selected. \t\u00a0Next, name the new column that will contain the cluster membership and the number of clusters (k) assumed to exist in the DataSet. Typically 2-5 clusters is a good starting point, although more can be used. It is recommended that different values of k be explored.", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-6", "text": "Note:\u00a0Using too many clusters is typically not beneficial as the\u00a0interpretations among the resulting clusters would be difficult.\n\n\n\nThen, select either K-means or K-medians as the algorithm powering this Clustering tile.\u00a0 Lastly, an output DataSet must be connected and named.\nThe resulting output DataSet will include the original DataSet with an appended column containing the cluster membership.\n\nBuilding a card with this DataSet\nA Scatter Plot is a\u00a0great way to visualize the data in this DataSet.\n\nThis Scatter Plot shows client spending on Fresh (X-axis) products against Grocery (Y-axis)\u00a0products. Each point is colored by its assigned cluster. In this example, 3 clusters were chosen\u00a0and it appears that clients in cluster 1 (blue) tend to spend more on Fresh products, clients in\u00a0cluster 3 (orange) tend to spend more on Grocery products, and clients in cluster 2 (green) do\u00a0not spend much on either. More Scatter Plots could be built to examine how the clients cluster\u00a0within different product categories (i.e., Milk by Frozen).\nForecasting\nTime series forecasting includes\u00a0methods which use a column of time-ordered data to generate forecasts of future observations.\nThis tile requires 1 date/time column and 1 numeric column. Forecasting uses the ARIMA algorithm.\nARIMA\nWith\u00a0ARIMA (Auto-Regressive Integrated Moving-Average), prediction parameters are automatically chosen based on model fit. This allows for the capture of trends and seasonality in the data. The forecasts are then based on the final model parameters.\nExample\u00a0\nThe following example illustrates how the ARIMA forecasting algorithm can be implemented and used in Magic ETL in Domo. The sample DataSet: Daily_Web_Sales.xlsx\u00a0(171 rows) is a\u00a0artificially generated DataSet\u00a0that contains\u00a0daily revenue totals.\u00a0 It can be downloaded if you would like to try this example.", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-7", "text": "To configure the Forecasting tile,\u00a0\nAdd the Forecasting tile to your Magic ETL and connect it to the input DataSet.  Next, select the column containing the date/time, followed by the column that you want to forecast. In this case, 'Revenue' will be forecasted.   \t\u00a0Now, let's choose the width of the prediction bands (default is 95%).\u00a0The higher the percentage of the value chosen, the smaller the width of the bands.\u00a0The number of dates to forecast can then be chosen next.\u00a0The forecasting algorithm will look at the past data and take the average distance (in time) between data points.\u00a0Future forecasted points will be based on this quantity.\u00a0In this case, the data is in days, so the future forecasted time points are also in days.   \t\u00a0Select the number\u00a0of rows back in time must be chosen to base the future predictions on.\u00a0By default, all of the rows will be used.\u00a0The name of the prediction column must also be named.\u00a0In this case, the default \u2018prediction\u2019 is used.   \t\u00a0Next, the prediction lower and upper bounds must be named. Here, the defaults \u2018prediction lower\u2019 and \u2018prediction upper\u2019 are used.  \t\u00a0Indicate the number of times you want each row to be observed per time period.\tIn this example, the number of times is 7. Finally, connect and name the output DataSet.  \nThe resulting output DataSet will include the original DataSet with the appended \u2018prediction,\u2019\u00a0\u2018prediction lower,\u2019\u00a0and \u2018prediction upper\u2019 columns. These three new columns will be blank, except for where predictions are made (at the bottom of the DataSet).\n\nBuilding a card with this DataSet\nA Forecasting card is a great way to visualize the data in this DataSet.", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-8", "text": "This Forecasting card shows the daily revenue with the forecasted values (with upper and lower bounds) shaded in blue.\u00a0\nMultivariate Outliers\nMultivariate outlier detection is an anomaly detection algorithm which aims to detect outlying or unusual observations on a set of one or more numeric columns in a DataSet. Multivariate outlier detection allows the user to detect an outlying observation (or row) in more than one dimension. In some scenarios, an observation may not be an outlier with respect to a single column but may be an outlier with respect to multiple columns. This is particularly useful as the number of columns increases.\nFor true multivariate outliers to be discovered, this tile requires 2 or more numeric columns. However, the tile task will operate with at least one numeric value.\u00a0\nExample\nThe following example illustrates how the outlier detection algorithm can be implemented and used in Magic ETL in Domo. The sample DataSet: Wholesale_Distributor_Sales.xlsx\u00a0(440 rows) can be downloaded if you would like to try this example.", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-9", "text": "It contains annual spending information (in monetary units, \u201cm.u.\u201d) on various product\u00a0categories from clients of a wholesale distributor. Each row contains data for a single client.\u00a0The first two columns are Region and Channel, which describe demographic information for\u00a0each client. The next 6 columns contain the spending information on each of the 6 product\u00a0categories: Fresh, Milk, Grocery, Frozen, Detergents_Paper, and Delicatessen. Multivariate\u00a0outlier detection can be used to detect outlying, or unusual, clients based on how much was spent on the various product categories.\nTo configure the Multivariate Outliers tile,\u00a0\nAdd the Multivariate Outliers tile to your Magic ETL and connect it to the input DataSet.\u00a0  Within the Multivariate Outliers tile, one or more of the 6 product categories must be chosen\u00a0as the columns for which outliers will be detected on. For this example, all of the product\u00a0categories are chosen.  \t\u00a0The quantile (a value between 0 and 1) of the Chi-square distribution that will be used as a\u00a0cutoff must be selected next as well as the name of the column (default is \u201coutlier\u201d) that contains either TRUE (observation is an outlier) or FALSE (observation is not an outlier) values.\u00a0Typically a quantile between .95 and .99 is a good starting point, with higher quantiles leading\u00a0to stricter cutoffs. It is recommended that different values be explored. Note that using too low of a quantile cutoff value will label most of the observations as outliers.  \t\u00a0Last, an output DataSet must be connected and named.\n\nThe resulting\u00a0output DataSet will include the original DataSet with an appended column\u00a0containing the outlier indicators (circled below in the preview pane).\u00a0\n\nBuilding a card with this DataSet\nA Scatter Plot graph is a great way to visualize the data in this DataSet.", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-10", "text": "This Scatter Plot shows client spending on Grocery (X-axis) products against Fresh (Y-axis)\u00a0products. Recall that all six product categories were chosen to detect outliers on. The clients\u00a0that are considered outliers are in red. Most of the outlying clients either spent a lot on Fresh\u00a0or Grocery or both. There also appeared to be some outlying clients that did not spend very\u00a0much on either Fresh or Grocery (located in the bottom left corner of the plot). These clients\u00a0may be high spenders in one of the other four product categories. Different scatter plots could\u00a0be used to gain insight into why some of the clients were considered outliers.\u00a0\nOutlier Detection\nAn outlier is an observation or point that is distant from other observations/points and has a low probability of occurrence. The outlier detection methods differ on their underlying assumptions about the data (roughly normal bell-curve data, high dimensional data, time series data, etc.) and how they detect outlying observations.\nThis tile requires 1 numeric column and you can choose between a standard deviation or mean absolute deviation algorithm.\u00a0\nMean Absolute Deviation\nMean Absolute Deviation outlier detection is an anomaly detection algorithm which aims to detect outlying or unusual observations on a numeric column in a DataSet. Unlike Standard Deviation detection, Mean Absolute Deviation outlier detection does not assume that the values in the column are normally distributed (i.e. have a bell-shaped distribution) and thus makes it most useful for columns that are non-normal or skewed (have a disproportionate number of observations that are large or small). Observations in the column are labeled as outliers if the value is greater than a pre-specified number of median absolute deviations (MADs) from the median in either direction.\nStandard Deviation", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-11", "text": "Standard Deviation outlier detection is an anomaly detection algorithm that attempts to detect outlying or unusual observations on a numeric column in a DataSet. Standard Deviation outlier detection specifically assumes that the values in the column are roughly normally distributed (i.e. have a bell-shaped distribution). Observations in the column are labeled as outliers if the value is greater than a pre-specified number of standard deviations from the mean in either direction.\nExample\nThe following example illustrates how the outlier detection algorithm can be implemented and used in Magic ETL in Domo. The sample DataSet: Wholesale_Distributor_Sales.xlsx\u00a0(440 rows) can be downloaded if you would like to try this example.", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-12", "text": "It contains annual spending information (in monetary units, \u201cm.u.\u201d) on various product\u00a0categories from clients of a wholesale distributor. Each row contains data for a single client.\u00a0The first two columns are Region and Channel, which describe demographic information for\u00a0each client. The next 6 columns contain the spending information on each of the 6 product\u00a0categories: Fresh, Milk, Grocery, Frozen, Detergents_Paper, and Delicatessen. Standard Deviation outlier detection can be used to detect outlying, or unusual, clients based on\u00a0how much was\u00a0spent on the various product categories.\nTo configure the Outliers Detection tile,\u00a0\nAdd the Outliers Detection tile to your Magic ETL and connect it to the input DataSet.\u00a0  Within the Outliers Detection tile, one of the 6 product categories must be chosen as the\u00a0column for which outliers will be detected on. For this example, Fresh is the chosen column.\u00a0\n \t\u00a0The number of median absolute deviations above or below the median that will be used as a\u00a0cutoff must be selected next as well as the name of the column (default is \u201coutlier\u201d) that\u00a0contains either TRUE (observation is an outlier) or FALSE (observation is not an outlier) values.\u00a0Typically 2-3 median absolute deviations is a good starting point, although a higher (stricter)\u00a0value can be used. It is recommended that different values be explored. Note that using too\u00a0small of a cutoff will label most observations as outliers.\n\t\u00a0Next, select either the Standard Deviation or Mean Absolute Deviation algorithm. In this example, we will select Standard Deviation. Last, an output DataSet must be connected and named.\n\nThe resulting output DataSet will include the original DataSet with an appended column containing the outlier indicators (circled below in the preview pane).", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-13", "text": "Building a card with this DataSet\nA Scatter Plot graph is a great way to visualize the data in this DataSet.", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-14", "text": "This Scatter Plot shows client spending on Grocery (X-axis) products against Fresh (Y-axis)\u00a0products. Recall that Fresh was the category that was chosen to detect outliers on. The clients\u00a0that are considered outliers are in red. These clients appear to spend significantly more on\u00a0Fresh products than the other clients. There were no clients that were considered outliers on\u00a0the lower side of the spending spectrum. This analysis could be replicated to explore potential\u00a0outliers in other product categories.\nPrediction\nRegression algorithms aim to build statistical models which predict a numeric column in your data. The models can then be used to predict values of that column on new data. It is recommended that multiple methods be used and compared by the user.\nThis tile allows you to choose from either a Linear Regression or Random Forest algorithm.\nLinear Regression\nLinear regression prediction uses a linear regression model to predict a numeric column in your data.\u00a0It requires a training DataSet that contains the column you want to predict as well as other columns (also known as \"predictors\") that you believe can aid in the prediction process.\u00a0The algorithm uses the training DataSet to \"train\"\u00a0a prediction algorithm which can then be applied to a \"test\"\u00a0DataSet (note the test and training DataSets could be the same) where it will use the same \"predictor\"\u00a0column\u00a0to classify each row.\u00a0\nRandom Forest\nThe Random Forest regression is very powerful as it uses an ensemble of many weak decision trees to create one strong regression algorithm that predicts the mean prediction of each of the individual trees. This performs well on a variety of data types as it is good at identifying complex non-linear substructure from data.\u00a0\nExample", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-15", "text": "Example\nThe following example illustrates how the Regression prediction algorithm can be implemented and used in Magic ETL in Domo. The sample DataSets: Catastrophic_Train.xlsx\u00a0(800 rows) and\u00a0Catastrophic_Test.xlsx\u00a0(200 rows) are artificially generated DataSets\u00a0and can be downloaded if you would like to try this example.\u00a0They contain data on insurance claims where the goal is to train a prediction algorithm which can accurately predict the number of claims for each row in a DataSet based on data in other columns.\u00a0\nA snapshot of the \u201cCatastrophic\u00a0Train.xlsx\u201d DataSet is found below.", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "f6acc6b9c05d-16", "text": "The column of interest that we\u00a0want to classify is \"num.claims\"\u00a0which is observed in this DataSet.\u00a0This DataSet will be used to \"train\"\u00a0a\u00a0classification algorithm that can\u00a0be used on future DataSets\u00a0where the \"num.claims\"\u00a0status may not be known.\u00a0\nA snapshot of the \"Catastrophic\u00a0Test.xlsx\" DataSet is found below.\n\nNote that \"num.claims\"\u00a0is also in this DataSet. This would allow the user to see how well their predictions did against actual values of \"num.claims.\"\nTo configure the Prediction tile,\u00a0\nAdd the Prediction tile to your Magic ETL and connect it to the input DataSet.\u00a0  First, you must select the training and test DataSets.\u00a0 Note that\u00a0these could be the same DataSet.  \t\u00a0Next, select the column that you want to predict. Then the columns that you believe may help predict\u00a0must be selected next with the numeric columns selected first (note that this can be left blank).\nNow, the categorical predictor columns must be selected (note that this may be left blank if at least one column was selected as a numeric predictor in the previous step).\u00a0The name of the prediction column must be set next. In the example, we leave the name at the default.\n\u00a0Lastly,\u00a0select either the Linear Regression or Random Forest algorithm. In this example, we will select Linear Regression.\nThe output DataSet must then be connected and named.\n\nThe resulting output DataSet will include the original training DataSet with the appended prediction columns. The prediction columns can then be compared with the \"num.claims\" column.", "source": "../../raw_kb/article/old_magic_etl_tiles_data_science/index.html", "title": "Old Magic ETL Tiles: Data Science"}, {"objectID": "8ebf9c339e5a-0", "text": "TitleOld Magic ETL Tiles: Edit ColumnsArticle BodyIntro\n\u00a0\n\n\n\u00a0\n\nNote: This article is for the old Magic ETL. For information on the new Magic ETL, see Magic ETL.\n\n\n\nThis article describes in detail most of the\u00a0Edit Columns tiles in Magic ETL, including the following:\nAdd ConstantsCalculatorCollapse ColumnsCombine ColumnsDate OperationsGroup BySelect ColumnsSet Column TypeSplit ColumnUncollapse Columns\n\nThis topic does not discuss the Rank & Window tiles. For information about these tiles, see\u00a0Magic ETL Tiles: Rank and Window.\n\nFor information about creating a Magic ETL DataFlow, see Creating a Magic ETL DataFlow.\nFor information about the Data Center, see Data Center Layout.\nAdd Constants\nThe Add Constants tile lets you add a column with constant values.\nTo configure the Add Constants tile,\nClick the Add Constants tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Enter the name of the new column.Select the column type.Column TypeDescriptionTextContains text and numbers (which are treated as text).DecimalContains numbers in decimal notation.Decimal (Fixed)Contains decimal numbers with a fixed number of digits after the decimal point.Whole NumberContains numbers without a decimal part.DateContains date values.Date and TimeContains date and time values.Enter the constant value, date, date and time, or leave it blank.\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_columns/index.html", "title": "Old Magic ETL Tiles: Edit Columns"}, {"objectID": "8ebf9c339e5a-1", "text": "Calculator\nThe Calculator tile lets you add a column with values from a simple calculation.\nTo configure the Calculator tile,\nClick the Calculator tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Enter the name of the new column.Select the operation you want.OperationDescriptionAdditionAdds values from two columns.SubtrtileSubtracts values from two columns.MultiplicationMultiplies values from two columns.DivisionDivides values from two columns.CeilingReturns the highest value for each series in a numeric column.FloorReturns the lowest value for each series in a numeric column.Select the columns to use or specify the values you want.\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.\n\n\n\nCollapse Columns\nThe Collapse Columns\u00a0tile lets you \"unpivot\" or \"normalize\" data in tables, transforming multiple columns in a single row into a single column with multiple rows. This tile is useful only for unpivoting data in which the number of columns stays the same. If you add another column of data to the original file, this tile does not collapse or unpivot the new column.\nExample\nFor example, the Collapse Columns\u00a0tile converts data in this pivoted format...\n\n\u00a0\n... to data in this format...\n\n... using this configuration:", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_columns/index.html", "title": "Old Magic ETL Tiles: Edit Columns"}, {"objectID": "8ebf9c339e5a-2", "text": "... to data in this format...\n\n... using this configuration:\n\nTo configure the Collapse Columns\u00a0tile,\nClick the Collapse Columns\u00a0tile in the canvas.(Optional) Rename the tile by clicking the edit icon, then entering the name you want.Enter the name of the column you want to create to contain the column headings from the columns to collapse.\tFor example, \"Product\".\u00a0Enter the name of the column you want to create to contain the row values from the columns to be collapsed.\tFor example, \"Sales\".\u00a0For each column you want to collapse, do the following:Select a column to normalize.\t\tFor example, \"Product A\".\u00a0Enter a value representing the column header to be normalized.\t\tThe value appears in the row of the new column. For example, \"A\".(Conditional) If you want to collapse another column, then click Add Column.\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.\n\n\n\nCombine Columns\nThe Combine Columns tile lets you combine values from multiple columns into one column.\u00a0For example, you could combine first name and last name from two columns into a new, full name column.\u00a0\nVideo - Combining Columns in Magic ETL\n\n\u00a0\nTo configure the\u00a0Combine Columns tile,\nClick the Combine Columns\u00a0tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Enter the name of the new column.Specify the character to use to separate the combined values.(Optional) Remove the original columns after they are combined.Select the columns to combine.\u00a0\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_columns/index.html", "title": "Old Magic ETL Tiles: Edit Columns"}, {"objectID": "8ebf9c339e5a-3", "text": "Date Operations\nThe Date Operations\u00a0tile lets you add\u00a0a column with values from a date-based calculation.\nTo configure the Date Operations\u00a0tile,\nClick the\u00a0Date Operations tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Enter the name of the new column.Select the date operation you want.OperationDescriptionAdd\u00a0to dateReturns the result of adding a unit of measurement\u00a0to values in a date column. Units of measurement include\u00a0months, weeks, days, hours, minutes, seconds, or milliseconds.Subtract from dateReturns the result of subtracting a unit of measurement from values in a date column. Units of measurement include months, weeks, days, hours, minutes, seconds, or milliseconds.Difference between datesReturns the difference in a unit of measurement between two dates. Units of measurement include days, working days, hours, minutes, seconds, milliseconds.Year of dateReturns the year for values in a date column.Quarter of dateReturns the quarter for values in a date column.Month of dateReturns the month for values in a date column.Day of yearReturns the numerical day of the year for values in a date column.Day of monthReturns the numerical day of the month for values in a date column.Day of weekReturns the numerical day of the week for values in a date column.Week of yearReturns the numerical week for values in a date column.\u00a0Weeks are Sun-Sat. Week 1 is the first week with a Saturday in this year.Select the columns to use or specify the values you want.\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.\n\n\n\nGroup By\nThe Group By tile lets you aggregate values from multiple columns into one column. For example, you could\u00a0calculate the average sales per product or get the number of yellow shirts in stock.\nVideo - Using Group By in Magic ETL", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_columns/index.html", "title": "Old Magic ETL Tiles: Edit Columns"}, {"objectID": "8ebf9c339e5a-4", "text": "To configure the\u00a0Group By tile,\nClick the Group By\u00a0tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Select the columns in the grouping.For each column you want to add, do the following:Enter the name of the new column.Select the columns to aggregate and fill the new column.Select the aggregation type to use.TypeDescriptionData Types Available ForCountReturns the number of non-null values in the column.Decimal, Whole Number, Text, DateCount including nullsReturns the number of all values in the column, including nulls.Decimal, Whole Number, Text, DateCount distinctReturns the number of unique values in the column.Decimal, Whole Number, Text, DateFirst non-null valueReturns the first non-null value.Decimal, Whole Number, Text, DateLast non-null valueReturns the last non-null value.Decimal, Whole Number, Text, DateFirst valueReturns the first value (including null).Decimal, Whole Number, Text, DateLast valueReturns the last value (including null).Decimal, Whole Number, Text, DateSumSums all of the values in the column.Decimal, Whole NumberAverageReturns the average of all of the values in the column.Decimal, Whole NumberMedianReturns the median of all of the values in the column.Decimal, Whole NumberMinimumReturns the minimum value in the column.Decimal, Whole Number, DateMaximumReturns the maximum value in the column.Decimal, Whole Number, DateStandard deviationReturns the standard deviation for the values in the column.Decimal, Whole NumberCombine strings separated by ,Combines all of the text values in the column, separating them with commas.Text(Conditional) If you want to add a column, then click Add Column.\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.\n\n\n\nSelect Columns\nThe Select Columns tile lets you select columns to include, reorder columns, and rename column headings.", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_columns/index.html", "title": "Old Magic ETL Tiles: Edit Columns"}, {"objectID": "8ebf9c339e5a-5", "text": "Example\n\nFor example, the Select Columns tile transforms these columns in this data...\n\n... to this...\n\n... using this configuration:\n\nVideo - Renaming Fields in Magic ETL\n\n\u00a0\nTo configure the Select Columns tile,\nClick the Select Columns tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Select the columns you want to include (or exclude) by doing any of the following:Click Add Column, select a column you want. Repeat to add other columns.Click Add All Columns, then exclude columns by clicking the X associated with the column.\t\tFor example, remove \"Order Quarter\".Reorder columns by clicking \u00a0and\u00a0dragging a column to the order position you want.\tFor example, moving \"Order Date\" after \"Product Container\".For each column heading you want to rename, enter the new name of the column heading.\tFor example, renaming \"Product Base Margin\" to \"Base Margin\".\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.\n\n\n\nSet Column Type\nThe Set Column Type tile lets you change the data type of a column\u00a0(for example, from number to text). For more information about data types, see\u00a0Understanding Chart Data.\nExample\nFor example, the\u00a0Set Column Type tile transforms this data...\n\n\n\n\u00a0\n\nNote:\u00a0Before the transformation, the values were actually date-time values but did not display as such because they were set to a Text data type. After the transformation, the actual values display properly as date-time values.\n\n\n\n... to this...\n\n... using this configuration:", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_columns/index.html", "title": "Old Magic ETL Tiles: Edit Columns"}, {"objectID": "8ebf9c339e5a-6", "text": "... to this...\n\n... using this configuration:\n\nTo configure the Set Column Type\u00a0tile,\nClick the Set Column Type\u00a0tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.For each column where you want to set the data type, do the following:Select the column you want to set.\t\tFor example, \"Order Date String\".Select the data type you want for the column.Data TypeDescriptionTextContains string values.DecimalContains numbers in decimal notation.Decimal (Fixed)Contains decimal numbers with a fixed number of digits after the decimal point.Whole NumberContains numbers without a decimal part.DateContains date values.Date and TimeContains date and time values.(Conditional) If you want to add another column, then click Add Column.\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.\n\n\n\nSplit Column\nThe Split Column tile lets you split a single string column into multiple columns by a specific delimiter.\u00a0\nExample\nFor example, the Split Column tile converts data in this format...\n\n...to data in this format...\n\n...using this configuration:\n\nTo configure the Split Column tile,\nClick the Split Column\u00a0tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Select the column you want to split.Choose the delimiter on which the string should be separated.Next, decide whether to keep the extra splits in the last column specified in step 4.\tFor example, in row 1 in the table above, the extra split Ben\u00a0exists in the last column Watcher Split 1.Lastly, add and name as many columns as needed.\tIn the example above, you can see there are some rows that did not have 3 values to split, so those values remain blank in those columns.", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_columns/index.html", "title": "Old Magic ETL Tiles: Edit Columns"}, {"objectID": "8ebf9c339e5a-7", "text": "Note:\u00a0If you have more values to split than columns created and choose to not keep the extra splits, the values are not placed in any column.\n\n\n\nUncollapse Columns\nThe Uncollapse Columns\u00a0tile lets you \"pivot\" or de-normalize data in tables using key-value pairs, transforming a single column with multiple rows into multiple columns in a single row.\n\n\n\u00a0\n\nNote: If you create a table that reaches the 1500 column limit, you will receive an error. You must reduce the number of columns to continue running your Magic ETL DataFlow.\u00a0\n\n\n\nExample\nFor example, the Uncollapse Columns tile converts data in this format...\n\n... to data in this format...\n\n... using this configuration:\n\nTo configure the Uncollapse Columns\u00a0tile,\nClick the Uncollapse Columns\u00a0tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Enter the name of the key column you want to uncollapse into new column headers.\tFor example, \"Product\".\u00a0Select the column to use to group the row values of the new columns.\tFor example, \"Month\".For each new column you want to create from the key column, do the following:Enter the name of the new column header.\t\tFor example, \"Product A\".\u00a0Enter a value from the key column that represents the column header to be uncollapsed.\u00a0\t\tFor example, \"A\".Select the value column to use to fill the row value of the new column.For example, \"Sales\".\u00a0\n\n\n\u00a0\n\nNote:\u00a0For each column you add to be uncollapsed, select the same value column.\n\n\n(Conditional) If you want to add another column, then click Add Column.\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_columns/index.html", "title": "Old Magic ETL Tiles: Edit Columns"}, {"objectID": "0db237dd8fad-0", "text": "TitleOld Magic ETL Tiles: Edit DataArticle BodyIntro\n\u00a0\n\n\n\u00a0\n\nNote: This article is for the old Magic ETL. For information on the new Magic ETL, see Magic ETL.\n\n\n\nThis article describes in detail all of the\u00a0Edit Data tiles in Magic ETL, including the following:\nFilter RowsRemove DuplicatesReplace TextSet Column ValueString OperationsText FormattingValue Mapper\nFor information about creating a Magic ETL DataFlow, see Creating a Magic ETL DataFlow.\nFor information about the Data Center, see Data Center Layout.\nFilter Rows\nThe Filter Rows tile lets you include or exclude rows based on specified rules.\nExample\nFor example, the Filter Rows\u00a0tile transforms this data...\n\n... to this...\n\n... using this configuration:\n\nTo configure the Filter Rows tile,\nClick the Filter Rows tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Select whether to include rows that meet all or any of the rules you define.For each filter rule, do the following:Select a column to filter on.Select the operation to use.\t\t\u00a0Operation items appear in the list, depending on the type of data in the column to filter on.Select whether to compare against values in a specific column or a specific value, then do one of the following:(Conditional) If comparing against a column, select the column to use.(Conditional) If comparing against a specific value, enter the value to use.(Conditional) If you want to add another rule, click Add Filter Rule.\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.\n\n\n\nRemove Duplicates\nThe Remove Duplicates tile lets you remove\u00a0duplicate rows, based on specific columns.\nVideo - Removing Duplicates in Magic ETL\n\n\u00a0\nExample\nFor example, the Remove Duplicates tile transforms this data...\n\n... to this...", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_data/index.html", "title": "Old Magic ETL Tiles: Edit Data"}, {"objectID": "0db237dd8fad-1", "text": "Example\nFor example, the Remove Duplicates tile transforms this data...\n\n... to this...\n\n... using this configuration:\n\n\n\n\u00a0\n\nNote:\u00a0Duplicate rows with the same base margin were removed.\n\n\n\nTo configure the Remove Duplicates tile,\nEnsure that the column with values you want exists in the DataSet.Click the Remove Duplicates\u00a0tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.For each column with duplicate values you want to remove, do the following:Select the column you want.\t\tFor example, \"Product Base Margin\".\u00a0Mark whether the comparison is case sensitive.(Conditional) If you want to add another column, then click Add Column Comparison.\n\n\n\u00a0\n\nNote:\u00a0For a row to be removed, all of the columns selected in the Remove Duplicates tile\u00a0must be duplicates.\n\n\u00a0\n\n\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then click the Preview tab.\n\n\n\nReplace Text\nThe Replace Text\u00a0tile lets you replace all occurrences of a text value with another text value (aka search and replace). You can use Java regular expressions.\u00a0For more information about Java regular expressions, see https://docs.oracle.com/javase/tutorial/essential/regex/.\n\n\n\u00a0\n\nTip:\u00a0You could use the Set Column Type tile to set a date or number column as text before (and after) using the Replace Text tile to replace values.\n\n\n\nFor information about replacing text values using other tiles, see\u00a0Set Column Value and\u00a0Value Mapper.\nExample\nFor example, the Replace Text tile replaces occurrences of the text value \"Jumbo Box\" in the \"Product Container\" column...\n\n... with the text value \"Ginormous\"...\n\n... using this configuration:", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_data/index.html", "title": "Old Magic ETL Tiles: Edit Data"}, {"objectID": "0db237dd8fad-2", "text": "... with the text value \"Ginormous\"...\n\n... using this configuration:\n\nTo configure the Replace Text\u00a0tile,\nClick the Replace Text\u00a0tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Select the column to search in.Enter the text value you want to find.\tFor example, \"Jumbo Box\".\u00a0(Option) Specify the find settings to use by clicking \u00a0in the field.OptionDescriptionWhole wordsSearches for whole words.Case sensitiveSearches with case-sensitive values.Use RegExSearches and replaces using Java regular expressions.Enter the text value you want to replace with.\tFor example, \"Ginormous\".\u00a0\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.\n\n\n\nSet Column Value\nThe Set Column Value tile lets you replace the value of a column with the values in another column.\n\n\n\u00a0\n\n\nNotes:\u00a0\nYou can only replace values in one column with values from another column that have the same data type. For example, you can copy from a column with string values to another column with string values.Both columns must already exist in the DataSet.\n\n\n\n\nFor information about replacing text values using other tiles, see\u00a0Replace Text and\u00a0Value Mapper.\nExample\nFor example, the\u00a0Set Column Value tile transforms this data...\n\n... to this...\n\n... using this configuration:", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_data/index.html", "title": "Old Magic ETL Tiles: Edit Data"}, {"objectID": "0db237dd8fad-3", "text": "... to this...\n\n... using this configuration:\n\nTo configure the Set Column Value\u00a0tile,\nEnsure that the column with values you want exists in the DataSet.Click the Set Column Value\u00a0tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.For each column with values you want to replace, do the following:Select the column with values you want to replace.\t\tFor example, \"Product Base Margin\".\u00a0Select the column with the values you want.\t\tFor example, \"Net Margin\".\u00a0(Conditional) If you want to add a column, then click Add Column.\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.\n\n\n\nString Operations\nThe String Operations tile lets you substring, trim, or pad a string with spaces.\nExample\nFor example, the String Operations tile can transform\u00a0this data...\n\n... to this...\n\n... using this configuration:\n\nTo configure the String Operations tile,\nClick the String Operations tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Type the name of your new column.Then, choose the type of operation you want to perform.Select the column you want to perform this tile on.Lastly, specify the beginning and ending character position you want from your string.(Optional) If you want to add another column, click Add String Operation.\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.\n\n\n\nText Formatting\nThe Text Formatting tile lets you format text (lower case, upper case, capitalization), remove numbers, or remove everything except numbers.\nExample\nFor example, the Text Formatting tile transforms this data...\n\n... to this...\n\n... using this configuration:", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_data/index.html", "title": "Old Magic ETL Tiles: Edit Data"}, {"objectID": "0db237dd8fad-4", "text": "... to this...\n\n... using this configuration:\n\nTo configure the Text Formatting tile,\nClick the Text Formatting tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.For each column you want to format, do the following:Select the text column you want.Select the type of letter-case format you want.Select whether to remove numbers or remove everything except numbers.(Conditional) If you want to add another column, click Add Column.\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.\n\n\n\nValue Mapper\nThe Value Mapper tile lets you search and replace string values in a specific column, according to pairs of string values you enter. (You might use the Value Mapper tile for replacing abbreviations or converting language codes.)\u00a0You can either have replacement values overwrite an existing column or be in a new column.\nFor information about replacing text values using other tiles, see\u00a0Replace Text and\u00a0Set Column Value.\nExample\nFor example, the Value Mapper tile transforms this data...\n\n... to this...\n\n... using this configuration:\n\n\n\n\u00a0\n\nNote:\u00a0This example shows values written to a new column. If configured, the values could overwrite values in the original column instead.", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_data/index.html", "title": "Old Magic ETL Tiles: Edit Data"}, {"objectID": "0db237dd8fad-5", "text": "To configure the Value Mapper tile,\nClick the Value Mapper tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Select the column you want to search.Select whether the values overwrite the values in the specified column or appear in a new column.(Conditional) If writing values to a new column, enter the name of the column.Select whether to write the original value or a default value when a match is not found in a row.(Conditional) If writing a default value, enter the value.For each value mapping you want, enter the value to search for and the value to replace with.(Conditional) If you want to add a mapping, then click Add Mapping.\n\n\n\u00a0\n\nTip: You can preview the data transformed by a tile by running a preview, clicking the tile in the canvas, then clicking the Preview tab.", "source": "../../raw_kb/article/old_magic_etl_tiles_edit_data/index.html", "title": "Old Magic ETL Tiles: Edit Data"}, {"objectID": "36d6b5a95607-0", "text": "TitleOld Magic ETL Tiles: PerformanceArticle Body\n\n\u00a0\n\n\nNote:\u00a0 This feature is available\u00a0on demand and paid.\n\u00a0\nTo request this feature be enabled,\nReach out to your Domo Customer Success Manager, Technical Consultant, or AE.If you do not have contact information for your CSM, TC, or AE, contact Technical Support for information on how to contact Support, please see: Getting Help\nDepending on the feature, you may be required to complete training before you can use the feature.\n\n\n\n\nIntro\n\u00a0\n\n\n\u00a0\n\nNote: This article is for the old Magic ETL. For information on the new Magic ETL, see Magic ETL.\n\n\n\nThis article describes in detail all of the Edit Data tiles in Magic ETL, including the following:\nSelect and Store ColumnsRestore Columns\nFor information about creating a Magic ETL DataFlow, see Creating a Magic ETL DataFlow.\nFor information about the Data Center, see Data Center Layout.\nPrerequisites\nThe Performance tiles are intended for use with either the Python or R Scripting tiles. For more information on the Scripting tiles, see Magic ETL Tiles: Scripting.\n\nSelect and Store Columns Tile\nThe Select and Store Columns tile allows you to store/remove columns that are not used as part of the script inside of a Python or R Scripting tile. Storing columns not applicable to the Scripting tiles transformations prior to the Scripting tile reduces the amount of data being loaded. Following this process will generally decrease the runtime of your Scripting tile as the tile is now only loading the necessary columns for its transformation.", "source": "../../raw_kb/article/old_magic_etl_tiles_performance/index.html", "title": "Old Magic ETL Tiles: Performance"}, {"objectID": "36d6b5a95607-1", "text": "To configure the Select and Store Columns tile,\nClick the Select and Store Columns tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Select the columns you want to use in the subsequent Python or R Scripting tile.(Optional) To verify all desired columns have been selected, hide all non-selected columns in the list by clicking .Name the column that you will use to restore the columns to the DataFlow.\n\t\n\n\u00a0\n\nImportant: Do not modify the column you named in this step in any other tile in the DataFlow or the Restore Columns tile will not work as expected.\n\n\n\nRestore Columns Tile\nThe Restore Columns tile allows you to restore/add the stored columns back into your DataFlow after the script in your Python or R Scripting tile has been processed.\n\nTo configure the Restore Columns tile,\nClick the Restore Columns tile in the canvas.(Optional) Rename the tile by clicking , then entering the name you want.Select the column that you named in the Select and Store Columns tile.(Optional) Review the columns that will be restored by hovering over the text that states the number of columns that will be restored.", "source": "../../raw_kb/article/old_magic_etl_tiles_performance/index.html", "title": "Old Magic ETL Tiles: Performance"}, {"objectID": "e6741c8871a4-0", "text": "Title\n\nOld Magic ETL Tiles: Rank and Window\n\nArticle Body\n\nIntro\n\u00a0\n\n\n\n\n\nNote: This article is for the old Magic ETL. For information on the new Magic ETL, see New Magic ETL.\n\n\n\nThe Rank & Window action lets you create new columns by applying any of several rank and window functions to columns. For all of these actions, you first define your function, then specify the column the function is to be ordered by, and finally indicate whether the results in the new column should be in ascending or descending order.\nRank & Window functions are categorized into three types: Ranking, Framed, and Offset.\nFor more information about all of the functions described in this section, see http://docs.aws.amazon.com/redshift/latest/dg/c_Window_functions.html.\nVideo - Rank & Window Functions in Magic ETL", "source": "../../raw_kb/article/old_magic_etl_tiles_rank_and_window/index.html", "title": "Old Magic ETL Tiles: Rank and Window"}, {"objectID": "e6741c8871a4-1", "text": "Understanding Partitions\nAll functions also allow you to optionally specify a column to use as a partition. For example, if you had a series column called \"State,\" selecting \"State\" as the partition would cause the values in your new column to be divided by state. This is shown in the following example, wherein values in the \"Amount\" column are ranked in descending order and partitioned by state:\u00a0\n\u00a0\nNotice that the two amounts for Connecticut (\"CT\") are ranked first, followed by the five amounts for Delaware (\"DE\"), and so on.\nRanking Functions\nRanking functions derive a ranking number for each value in a selected column and display it in a new column. There are three available ranking functions: Rank, Dense Rank, and Row Number.\nRank\nThe Rank function assigns a rank number to each value in the selected column. If any cells in the column contain the same value, those cells are given the same ranking number, and a \"gap\" appears in the numbering depending on how many numbers were skipped. For example, if the first three cells in the column had a value of 100 and the next cell had a value of 200 and the values were set to be in ascending order, the first three cells would be ranked \"1\" and the fourth cell would be ranked \"4.\"\nThe following screenshot shows an example of this:\n]\nBecause the first three states have the same $ value, all are ranked as 1. Rank numbers 2 and 3 are then skipped. The next five states also have the same value, and are all ranked as 4, and so on.\nTo configure the Rank action,", "source": "../../raw_kb/article/old_magic_etl_tiles_rank_and_window/index.html", "title": "Old Magic ETL Tiles: Rank and Window"}, {"objectID": "e6741c8871a4-2", "text": "To configure the Rank action,\nClick the Rank & Window action in the canvas.(Optional) Rename the action by clicking , then entering the name you want.Click Add Function.Add a name for the new column that will contain the ranking results (such as \"Rank\").In the Select function type menu, select Rank.Click the Apply button in the top right corner of the dialog.Three new steps appear.In Step 2 of the dialog, select the column you want to rank. (A value column is recommended.)In Step 3 of the dialog, select the order you want the values in the column to be ranked in.(Optional) In Step 4 of the dialog, select the column to use as a partition, if any. (For an explanation of partitioning, see Understanding partitions\u00a0at the top of this page.)\nDense Rank\nThe Dense Rank function is the same as the Rank function, with one important difference. If any cells in the column contain the same value, those cells are given the same ranking number, as in a \"Rank\" function; however, the numbering continues as normal to the next cell (i.e. no \"gap\" appears). For example, if the first three cells in the column had a value of 100 and the next cell had a value of 200 and the values were set to be in ascending order, the first three cells would be ranked \"1\" and the fourth cell would be ranked \"2.\"\nThe following screenshot shows an example of this:", "source": "../../raw_kb/article/old_magic_etl_tiles_rank_and_window/index.html", "title": "Old Magic ETL Tiles: Rank and Window"}, {"objectID": "e6741c8871a4-3", "text": "Because the first three states have the same $ value, all are ranked as 1. The next five states also have the same $ value and are ranked as 2, and so on.\nTo configure the Dense Rank action,\nClick the Rank & Window action in the canvas.(Optional) Rename the action by clicking , then entering the name you want.Click Add Function.Add a name for the new column that will contain the ranking results (such as \"Rank\").In the Select function type menu, select Dense Rank.Click the Apply button in the top right corner of the dialog.Three new steps appear.In Step 2 of the dialog, select the column you want to rank. (A value column is recommended.)In Step 3 of the dialog, select the order you want the values in the column to be ranked in.(Optional) In Step 4 of the dialog, select the column to use as a partition, if any. (For an explanation of partitioning, see Understanding partitions\u00a0at the top of this page.)\nRow Number\nThe Row Number function returns the row numbers of all values in the selected column. Note that when partitioning is used, rows take the number of their row within the partition group, not necessarily the row number of the DataSet. This is shown in the following screenshot, in which the row numbering derived from the Row Number function restarts with each new partition. Thus, beginning with row 4, the derived row numbers are not the same as the DataSet row numbers.\u00a0\nTo configure the Row Numbers action,", "source": "../../raw_kb/article/old_magic_etl_tiles_rank_and_window/index.html", "title": "Old Magic ETL Tiles: Rank and Window"}, {"objectID": "e6741c8871a4-4", "text": "To configure the Row Numbers action,\nClick the Rank & Window action in the canvas.(Optional) Rename the action by clicking , then entering the name you want.Click Add Function.Add a name for the new column that will contain the ranking results (such as \"Row Number\").In the Select function type menu, select Row Number.Click the Apply button in the top right corner of the dialog.Three new steps appear.In Step 2 of the dialog, select the column you want to derive row numbers for.In Step 3 of the dialog, select the order you want the values in the column to be sorted in.(Optional) In Step 4 of the dialog, select the column to use as a partition, if any. (For an explanation of partitioning, see Understanding partitions\u00a0at the top of this page.)\nFramed Functions\nFramed functions take a mathematical function and apply it to a cell in a column, along with a specified number of cells before it (\"Preceding\") and after it (\"Following\"). The derived values appear in a new column.\u00a0\nThe following simple example shows how this works. For this example, the user has selected the Sum function and has indicated a Preceding value of 1 and a Following value of 2.", "source": "../../raw_kb/article/old_magic_etl_tiles_rank_and_window/index.html", "title": "Old Magic ETL Tiles: Rank and Window"}, {"objectID": "e6741c8871a4-5", "text": "In the example, each value in the \"Original Value\" column is added to the one cell above it and the two cells below it, and the result appears in the same row in the \"Derived Value\" column. So for row 5, 3 is added to 1 (in row 4), 5 (in row 6), and 1 (in row 7). The total, 10, appears in the \"Derived Value\" column in row 5. If there are not enough values above or below a given value to include in the calculation, these are simply omitted. For example, for row 7 there is only one Following value, so the equation simply becomes 5 + 1 + 2 = 8.\nWhen partitioning is applied, partitions are honored in functions. In the following example, the user has selected Sum and indicated a Preceding value of 1 and a Following value of 2, just as in the previous example. However, he also sets the \"Class\" column as a partition.\nBecause of the grouping of rows thanks to the partition, some of the values are summed differently. For example, in row 4, only one Following value is available because the partition separates all \"B\" values into another group. So the equation for this row becomes 2 + 1 + 3 = 6. Likewise, for row 6, only the two Following values are available because of the partition; therefore, 5 + 1 + 2 = 8.\nFor an explanation of partitioning, see Understanding partitions\u00a0at the top of this page.\nAverage\nThe Average function takes the average of a given cell and its indicated Preceding and Following values. In the following example, the user has applied the Average function to the \"Amount\" column, set Preceding and Following values of 2, and set the \"Cust\" column as a partition.", "source": "../../raw_kb/article/old_magic_etl_tiles_rank_and_window/index.html", "title": "Old Magic ETL Tiles: Rank and Window"}, {"objectID": "e6741c8871a4-6", "text": "To configure the Average action,\nClick the Rank & Window action in the canvas.(Optional) Rename the action by clicking , then entering the name you want.Click Add Function.Add a name for the new column that will contain the derived values.\u00a0It is suggested you pick a name indicating the number of Preceding and Following values, such as \"Average (2P and 2F).\"In the Select function type menu, select Average.Two new menus appear after you select your function type.In the Select column menu, select the column with values that will be averaged.In the Preceding and Following fields, enter the number of Preceding and Following values you want to include in your averages.Click the Apply button in the top right corner of the dialog.Three new steps appear.In Step 2 of the dialog, select the column you want your order to be based on.In Step 3 of the dialog, select the order you want the values in the new column to be sorted in.(Optional) In Step 4 of the dialog, select the column to use as a partition, if any. (For an explanation of partitioning, see Understanding partitions\u00a0at the top of this page.)\n\u00a0\nCount\nThe Count function returns a count of a given cell and its indicated Preceding and Following values. In the following example, the user has applied the Count function to the \"Amount\" column, set Preceding and Following values of 2, and set the \"Cust\" column as a partition.\nTo configure the Count action,", "source": "../../raw_kb/article/old_magic_etl_tiles_rank_and_window/index.html", "title": "Old Magic ETL Tiles: Rank and Window"}, {"objectID": "e6741c8871a4-7", "text": "To configure the Count action,\nClick the Rank & Window action in the canvas.(Optional) Rename the action by clicking , then entering the name you want.Click Add Function.Add a name for the new column that will contain the derived values.\u00a0It is suggested you pick a name indicating the number of Preceding and Following values, such as \"Count (2P and 2F).\"In the Select function type menu, select Count.Two new menus appear after you select your function type.In the Select column menu, select the column with values that will be counted.In the Preceding and Following fields, enter the number of Preceding and Following values you want to include in your counts.Click the Apply button in the top right corner of the dialog.Three new steps appear.In Step 2 of the dialog, select the column you want your order to be based on.In Step 3 of the dialog, select the order you want the values in the new column to be sorted in.(Optional) In Step 4 of the dialog, select the column to use as a partition, if any. (For an explanation of partitioning, see Understanding partitions\u00a0at the top of this page.)\nSum\nThe Sum function returns a sum of a given cell with its indicated Preceding and Following values. In the following example, the user has applied the Sum function to the \"Amount\" column, set Preceding and Following values of 2, and set the \"Cust\" column as a partition.\nTo configure the Sum action,", "source": "../../raw_kb/article/old_magic_etl_tiles_rank_and_window/index.html", "title": "Old Magic ETL Tiles: Rank and Window"}, {"objectID": "e6741c8871a4-8", "text": "To configure the Sum action,\nClick the Rank & Window action in the canvas.(Optional) Rename the action by clicking , then entering the name you want.Click Add Function.Add a name for the new column that will contain the derived values.\u00a0It is suggested you pick a name indicating the number of Preceding and Following values, such as \"Sum (2P and 2F).\"In the Select function type menu, select Sum.Two new menus appear after you select your function type.In the Select column menu, select the column with values that will be summed.In the Preceding and Following fields, enter the number of Preceding and Following values you want to include in your totals.Click the Apply button in the top right corner of the dialog.Three new steps appear.In Step 2 of the dialog, select the column you want your order to be based on.In Step 3 of the dialog, select the order you want the values in the new column to be sorted in.(Optional) In Step 4 of the dialog, select the column to use as a partition, if any. (For an explanation of partitioning, see Understanding partitions\u00a0at the top of this page.)\nOffset Functions\nOffset functions add a new column to your DataSet in which values are the same as those in a selected column but offset by a specified number of rows. Offset functions come in two types: the Lag function, in which the values in the new column are offset after the values in the original column, and the Lead function, in which the values in the new column are offset before the values in the original column. In both Lag and Lead functions, partitions are honored.\u00a0\nLag\nIn a Lag function, the values in your new column follow the values in your original column after a specified offset. In the following example, a Lag of 3 has been applied, and the \"Cust\" column has been added as a partition.", "source": "../../raw_kb/article/old_magic_etl_tiles_rank_and_window/index.html", "title": "Old Magic ETL Tiles: Rank and Window"}, {"objectID": "e6741c8871a4-9", "text": "Notice that an offset of 3 rows has been inserted between the values in the \"Amount\" column and the matching values in the \"Lag\" column. Also, because of the partition, rows 13 to 15 are the first 3 rows in the \"Leo, Inc.\" grouping, so their cells in the \"Lag\" column appear blank.\nTo configure the Lag action,\nClick the Rank & Window action in the canvas.(Optional) Rename the action by clicking , then entering the name you want.Click Add Function.Add a name for the new column that will contain the derived values.\u00a0It is suggested you pick a name indicating the offset value of the lag.In the Select function type menu, select Lag.Two new menus appear after you select your function type.In the Select column menu, select the column with values that will appear in the new column.In the What rows should be included  field, enter the desired offset value.Click the Apply button in the top right corner of the dialog.Three new steps appear.In Step 2 of the dialog, select the column you want your order to be based on.In Step 3 of the dialog, select the order you want the values in the new column to be sorted in.(Optional) In Step 4 of the dialog, select the column to use as a partition, if any. (For an explanation of partitioning, see Understanding partitions\u00a0at the top of this page.)\nLead\nIn a Lead function, the values in your new column precede the values in your original column after a specified offset. In the following example, a Lead of 3 has been applied, and the \"Cust\" column has been added as a partition.", "source": "../../raw_kb/article/old_magic_etl_tiles_rank_and_window/index.html", "title": "Old Magic ETL Tiles: Rank and Window"}, {"objectID": "e6741c8871a4-10", "text": "Notice that an offset of 3 rows has been inserted between the values in the \"Amount\" column and the matching values in the \"Lead\" column. Also, because of the partition, rows 17 to 19 are the last 3 rows in the \"Leo, Inc.\" grouping, so their cells in the \"Lead\" column appear blank.\nTo configure the Lead action,\nClick the Rank & Window action in the canvas.(Optional) Rename the action by clicking , then entering the name you want.Click Add Function.Add a name for the new column that will contain the derived values.\u00a0It is suggested you pick a name indicating the offset value of the lead.In the Select function type menu, select Lead.Two new menus appear after you select your function type.In the Select column menu, select the column with values that will appear in the new column.In the What rows should be included  field, enter the desired offset value.Click the Apply button in the top right corner of the dialog.Three new steps appear.In Step 2 of the dialog, select the column you want your order to be based on.In Step 3 of the dialog, select the order you want the values in the new column to be sorted in.(Optional) In Step 4 of the dialog, select the column to use as a partition, if any.\u00a0(For an explanation of partitioning, see Understanding partitions\u00a0at the top of this page.)", "source": "../../raw_kb/article/old_magic_etl_tiles_rank_and_window/index.html", "title": "Old Magic ETL Tiles: Rank and Window"}, {"objectID": "d73796530d85-0", "text": "Title\n\nOld Magic ETL Tiles: Scripting\n\nArticle Body\n\nNote:\u00a0 This feature is available\u00a0on demand and paid.\n\u00a0\nTo request this feature be enabled,\nReach out to your Domo Customer Success Manager, Technical Consultant, or AE.If you do not have contact information for your CSM, TC, or AE, contact Technical Support by using /Support in Buzz or by email at support@domo.com\nDepending on the feature, you may be required to complete training before you can use the feature.\n\n\n\n\nIntro\n\u00a0\n\n\n\n\n\nNote: This article is for the old Magic ETL. For information on the new Magic ETL, see Magic ETL.\n\n\n\nScripting tiles are a powerful tool within Domo's Magic ETL feature. They allow you to write custom R or Python algorithms and implement them directly into DataFlows. With this, you can create complex data science analyses that run every time your data updates.\nGeneral   for All Scripting Tiles\nThis section provides information pertinent to all scripting tiles in Magic ETL. For information on specific tiles, click on any of the following links to jump to the section for that tile:\nPython Package API ReferenceR Package API Reference\nTake A Tour\nAll scripting tiles have\u00a0the same look. The only difference between them is the supported language.\nThe main body of the tile is the code editor. This is where you\u00a0write your script. It includes\u00a0syntax highlighting for the specific language the tile supports.\n\nOn the right side of the tile is a searchable list of input tiles currently connected to the scripting tile. Click on the name of an input to inject a code snippet\u00a0into the script at the location of the cursor. This code snippet will read the data into the script and store it in a variable. Rename the variable to whatever you would like.", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "d73796530d85-1", "text": "There is a second tab on the right side of the tile called Packages.\u00a0When you click the tab, a searchable list of available packages for the supported language is displayed. Hover over the package name for a description, or click on the arrow that appears to go to the package's documentation website. As\u00a0with inputs, if you click on a package, a code snippet is\u00a0injected into the script at the location of the cursor. This code snippet imports\u00a0the selected library for use in the script.\n\nOn the right side of the tile editor panel toolbar is a template icon button . Clicking this button resets the script to the example code template that exists when you first open a scripting tile. Be careful though\u2014if you have already\u00a0written\u00a0a script, clicking this button overwrites your script (after a confirmation prompt). However, as long as you do not close the tile, you can retrieve your overwritten script by placing the cursor within the code editor and pressing Command+z or CTRL+z.\nIn the Schema tab,\u00a0you tell the tile what the results of your script looks like. To use this, click\u00a0Schema\u00a0in the tile editor panel toolbar. For a deep dive into this tab, see the Populating the Resulting Schema\u00a0section of this documentation.\n\nIn the Console tab, you can see the standard out (stdout) and standard error (stderr) that your script produces. This tab is not available until after preview is run on the tile, when it will appear as an option in the tile editor panel toolbar.\n\nIn the Preview tab, you can see the results of running your script. This tab also does not appear until after a preview is run. It will then appear as an option in the tile editor panel toolbar.", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "d73796530d85-2", "text": "Getting Data In and Out of the Scripting Action\nDomo provides a basic API for importing data (read) from the Domo ecosystem into your script and then for exporting your results out (writing) of the script and back into the Domo ecosystem. The API is different for each scripting language and tries to follow the semantics of the language.\n\n\n \n\n\nNote: Be aware of the following data type issues when using scripting tiles in Domo:\u00a0\nIn Python, LONG becomes DOUBLE in Python because NumPY does not support NULLs in integer columns.In both Python and R, DECIMAL becomes DOUBLE because there is no analogous type in NumPY or R.", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "d73796530d85-3", "text": "The easiest way to see the specific API calls for your language is to examine the initial code template that is provided in a newly created and connected Scripting tile.\nStep 1: Import\u00a0The Domo Package\nThe first line in any script should be used for importing the language-specific Domo package into the script. This follows standard package import semantics for the chosen language. It is part of the initial code template.\u00a0Alternatively,\u00a0you can search for \"domo\" in the Packages list to the right of the code editor and click on the package to inject the code snippet into the editor.\nStep 2: Read Data Into The Script\nThe next step in writing a script is getting access to the data. Each language will have its own semantic version of a Domo \"read\" method. This is included in the initial code template.\u00a0Alternatively, you can click on one of the inputs in the input list to the right of the code editor. This injects a code snippet that is reading the input data and storing it in a variable. You can rename this variable if you like.\nStep 3: Export Data Out Of The Script\nThe last step in writing a script is returning the results to the Domo ecosystem. Each language has its own semantic version of a Domo \"write\" method. This is also\u00a0included in the initial code template. There is no other way of injecting a code snippet for this, however. Provide the name of the variable that is storing the results of your script to this \"write\" method. There can only be one export per script.\nPopulating The Resulting Schema\nThere are three ways to tell the tile what schema your script produces. These methods can be mixed and matched as necessary to get the proper result. You perform all of these in the Schema\u00a0tab of the tile.\nManually Adding the Columns\nTo add the columns manually...", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "d73796530d85-4", "text": "Manually Adding the Columns\nTo add the columns manually...\nType the name of a column that your script will produce into the Column Name\u00a0field.In the list of available data types, select the data type for this column.Add another column by clicking the Add Column\u00a0button.", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "d73796530d85-5", "text": "Important:\u00a0All added columns must be filled out in order for the tile to be considered configured.", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "d73796530d85-6", "text": "Bulk Adding the Columns\nTo add the columns in bulk...\n1. Add all of the columns from a particular \"Input DataSet\" tile in bulk by clicking on the Add From DataSet\u00a0button and selecting the \"Input DataSet\" tile you want to populate from.\n2. Remove any excess columns using the \"X\" button on the far right side of the column.\nLetting Domo Run The Script\nTo have Domo run the script for you...\nClick either the \u00a0button on the right side of the tile editor panel toolbar or the Run Preview\u00a0button in the toolbar at the top of the canvas. (If there is an issue with your preview, see the Troubleshooting\u00a0section of this documentation.)After the preview has finished running, a sentence appears under the text inputs for creating new columns. This\u00a0tells you how many columns the preview returned that are not currently listed as being part of the tile's schema.Click the button at the end of the sentence.\u00a0\nAfter you populate the schema, the tile knows what the results of your script look like and will be marked as configured (as long as you have also written a script).\nThe columns listed in the Schema tab will be passed to the next tile in the DataFlow.\nConfiguration Steps\nIf you have not done so already, check out the Take a Tour\u00a0section of this article to become familiar with the different features of the scripting tile.", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "d73796530d85-7", "text": "Start a new Magic ETL DataFlow.Drag an \"Input DataSet\" tile onto the canvas and select the DataSet you want to use.You will find the Scripting tiles under the \"Data Science\" section of the left sidebar.Drag the Scripting tile for the language you want to write onto the canvas and then drag a connection from the \"Input DataSet\" to this Scripting tile.(Conditional) If the editor panel is not open at the bottom of the screen, click the Scripting tile you just added to the canvas so that it is selected; the editor panel will then open.The code editor will be auto-populated with an initial code template. For more information on what is included in the template, see the Getting Data In and Out of the Scripting Action\u00a0section of this documentation. A yellow banner will also be displayed. Ignore this for now; it will be addressed later on in the configuration steps.You will see that the template is pulling the data from the \"Input DataSet\" tile that is connected to the Scripting tile and storing it in a variable. This is", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "d73796530d85-8", "text": "tile and storing it in a variable. This is the variable that your script should manipulate.(Conditional) If you have multiple data sources, simply drag out another \"Input DataSet,\"\u00a0select the next DataSet you need, connect this tile to the Scripting Action, and add another import statement to the script.Underneath the line that is creating the variable to hold your data, you will see a space for you to write your script.Write your script in the line provided,\u00a0making\u00a0sure that the export statement at the very bottom of the template is exporting the variable that represents the final product of your script.You will notice that your tile is still not marked as configured and there is still a yellow banner at the top of the tile telling you this. This is because the tile does not yet know what the result of your script looks like.To provide the tile with this information...Click the Schema\u00a0tab in the toolbar of the tile editor panel.\u00a0Choose one of the methods listed in the Populating The Resulting Schema\u00a0section of this article and follow the steps there.", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "d73796530d85-9", "text": "Schema\u00a0section of this article and follow the steps there. Afterwards, continue the rest of the steps listed below.Drag an \"Output DataSet\" tile from the sidebar and drop it onto the canvas.Drag a connection from the Scripting tile to this new \"Output DataSet\" tile.Open the \"Output DataSet\" tile and give it a name and description.The tiles within the DataFlow are now fully configured.Next, enter a name for\u00a0the DataFlow\u00a0in the field\u00a0in the top left corner.Configure the settings in the panel using the Settings\u00a0button in the canvas toolbar.Save the DataFlow.", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "d73796530d85-10", "text": "Congratulations! You have created a DataFlow that utilizes a Scripting tile. This has been a very basic configuration that only uses a single Input DataSet tile, a single Scripting tile, and a single Output DataSet tile. Don't forget that you can still use all of the classic DataFlow tiles to manipulate the data before and after your Scripting tile.\nAPI Reference\u00a0\ndomomagic is the simple API provided to both the Magic ETL \"Python Action\" and \"R Action\" authors, allowing them to load and unload data to and from the Python and R contexts.\nPython Module\u00a0API Reference\nMethod SignatureParametersReturnsread_dataframe(input_name=None)input_name:\u00a0Name of the Magic ETL input tile. Not required if only one input is available.A Pandas DataFrame representing the tiles input.\u00a0write_dataframe(dataframe)dataframe: Pandas DataFrame that will be used as the output for the Magic ETL tile.\u00a0N/Aread_array(column_name,input_name=None)column_name: Name of the\u00a0column.input_name:\u00a0Name of the Magic ETL input tile. Not required if only one input is available.A single column from the input as a NumPy array.read_array_dict(input_name=None)input_name:\u00a0Name of the Magic ETL input tile. Not required if only one input is available.The input as an OrderedDict of column names mapping to NumPy arrays.write_array_dict(array_dict)array_dict: The dictionary of column names mapping to NumPy arrays as output to the Magic ETL context. The arrays must be of equal length.N/A\nR Package API Reference\nMethod SignatureParametersReturnsread.dataframe(input.name=NULL, see below)input.name:\u00a0Name of the Magic ETL input tile. Optional if only one input is available.The tiles input data.frame.write.dataframe(table)table: Exports a data.frame or matrix as the output for a Magic ETL tile.\u00a0N/A", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "d73796530d85-11", "text": "The R Package\u00a0read.dataframe\u00a0function also supports the following parameters that allow you to customize its behavior:\nParameterDescriptioncolClassesA named character vector of classes to be assigned to the named columns.stringsAsFactorsLogical value determining whether or not string columns will be read as factors. Defaults to false, and is overridden by colClasses.integersAsNumericsLogical value determining whether integers should be read as numerics (floating point numbers). Defaults to true, and is overridden by colClasses.allVerbatimExceptCharacter vector of column names which should be read according to default behavior. All other columns will be read in verbatim as strings and written out with their original types. Useful when translation to and from the R context is causing loss of precision or errors and the column is not necessary for the calculation being performed.allIgnoredExceptCharacter vector of column names which will be read. All other columns will be ignored.\nTroubleshooting", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "d73796530d85-12", "text": "Troubleshooting\nIf your tile is not marked as configured after writing the script, make sure you have provided a resulting schema. See the Populating The Resulting Schema\u00a0section of this article\u00a0for more info.Running a preview is the easiest way to get feedback on the behavior of your script. You can run a preview by clicking the preview button on the right side of the tile editor panel toolbar or the preview button in the toolbar at the top of the canvas.After running a preview, a Console\u00a0tab appears in the tile editor panel toolbar. This displays the standard out (stdout) and standard error (stderr) that your script produces. If the preview fails, check this console for errors.If a script is failing, check that you have properly finished all three of the steps listed in the Getting Data In and Out of the Scripting Action\u00a0section of this article. Double-check the variable name that you are writing back to Domo to make sure it is correct.Previews run on just a sample of your dataset. If your script requires a certain variability in data to function properly, the sample grabbed by the preview might not meet this variability requirement. You can control the size of the preview sample by changing the Row Limit\u00a0in the canvas toolbar.", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "d73796530d85-13", "text": "Note:\u00a0Note that larger sample sizes will result in longer preview run times.\n\n\nHave you explicitly imported the packages/libraries that you need for your script to run? A list of available packages is in the Package\u00a0tab of the section to the right of the code editor.If a column is resulting in all null values, it could mean that the column is not actually produced by your script. If a column is provided in the list in the Schema\u00a0tab, that column is\u00a0added to the results regardless of whether the script actually produces it or not. If the script does not produce that column, then all of the values for that column are set to null. You can see which of your columns are and are not created by the script by running a preview and then looking at the Schema\u00a0tab. The status of each column will be displayed to the right of the column data type.If your script is failing during runtime with an out of memory error, your input DataSet could be too large or your script could be doing some sort of join that is causing the data to explode. Try filtering the data before it gets injected into the scripting\u00a0tile and/or refactoring your script to prevent data explosion.", "source": "../../raw_kb/article/old_magic_etl_tiles_scripting/index.html", "title": "Old Magic ETL Tiles: Scripting"}, {"objectID": "9e5fb780f9c7-0", "text": "Title\n\nOlo Connector\n\nArticle Body", "source": "../../raw_kb/article/olo_connector/index.html", "title": "Olo Connector"}, {"objectID": "9e5fb780f9c7-1", "text": "Intro\nOlo is a mobile and online food ordering platform that allows customers to order food from online menus and prepay in advance from their mobile or desktop device.  To learn more about the Olo API, visit their page (https://www.olo.com/developers.html).\nYou connect to your Olo account in the Data Center. This topic discusses the fields and menus that are specific to the Olo connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0 a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Olo account and create a DataSet, you must have an Olo API key. To obtain an API key, reach out to your Olo account representative.\u00a0\nConnecting to Your Olo Account\nThis section enumerates the options in the Credentials and Details panes in the Olo Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Olo account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter your Olo API key.EnvironmentSelect the environment you want to pull into Domo.\nOnce you have entered valid Olo credentials, you can use the same account any time you go to create a new Olo DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/olo_connector/index.html", "title": "Olo Connector"}, {"objectID": "9e5fb780f9c7-2", "text": "MenuDescriptionReportSelect the Olo report you want to run.\u00a0The following reports are available:MenuReturns data about Olo menus.RestaurantsReturns data about Olo restaurants.Product ModifiersReturns data about Olo product modifiers.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/olo_connector/index.html", "title": "Olo Connector"}, {"objectID": "520383177b47-0", "text": "Title\n\nOmegaFi Connector\n\nArticle Body\n\nIntro\nOmegaFi is a management tool for fraternal organizations including billing, due collection, fund raising, and record management. To learn more about the OmegaFi API, visit their page (https://www.omegafi.com/apps/home/ab...y/integration/).  \nYou connect to your OmegaFi account in the Data Center. This topic discusses the fields and menus that are specific to the OmegaFi connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your OmegaFi account and create a DataSet, you must have an OmegaFi username and password.\nConnecting to Your OmegaFi Account\nThis section enumerates the options in the Credentials and Details panes in the OmegaFi Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your OmegaFi account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionUsernameEnter your OmegaFi username.PasswordEnter your OmegaFi password.\nOnce you have entered valid OmegaFi credentials, you can use the same account any time you go to create a new OmegaFi DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a single menu from which you select an OmegaFi saved search to pull into Domo.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/omegafi_connector/index.html", "title": "OmegaFi Connector"}, {"objectID": "5da7bb4da559-0", "text": "TitleOnBrand360 ConnectorArticle BodyIntro\nOnBrand360 is a unique proprietary software. It enables specialists to utilize a software interface in the field that supports complex forms, conditional questions, scoring, validation, and more. OnBrand360\u00ae helps clients consistently and confidently deliver on their brand promises with its secure, intelligible, and scalable features. Use Domo's OnBrand360 connector to get all your assessments data.\nYou connect to your OnBrand360 account in the Data Center. This topic discusses the fields and menus that are specific to the OnBrand360 connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your OnBrand360 account and create a DataSet, you must have the following:\nYour OnBrand360 API Client ID and\u00a0Client SecretYour OnBrand360 Username and PasswordYour OnBrand360 API URL\nConnecting to Your OnBrand360 Account\nThis section enumerates the options in the Credentials and Details panes in the OnBrand360 Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your OnBrand360 account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionClient IDEnter the API Client ID associated with your\u00a0OnBrand360 account.Client SecretEnter the API Client Secret associated with your\u00a0OnBrand360 account.UsernameEnter the username associated with your OnBrand360 account.PasswordEnter the password associated with your\u00a0OnBrand360 account.API URLEnter the API URL associated with your\u00a0OnBrand360 account.", "source": "../../raw_kb/article/onbrand360_connector/index.html", "title": "OnBrand360 Connector"}, {"objectID": "5da7bb4da559-1", "text": "Once you have entered valid OnBrand360 credentials, you can use the same account any time you go to create a new OnBrand360 DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.\nMenuDescriptionReportSelect the OnBrand360 report you want to run.\u00a0The following reports are available:AssessmentsReturns the assessment data.Line Item AnswersReturns the line item answers data.ObservationsReturns the observations data.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/onbrand360_connector/index.html", "title": "OnBrand360 Connector"}, {"objectID": "2dfce90d6126-0", "text": "TitleOne by AOL:Video - Adap.tv ConnectorArticle BodyIntro\nAdap.tv, a part of ONE by AOL, transforms the way programmatic video advertising is bought and sold. To learn more about the Adap.tv API, visit their page (https://learn.onevideo.aol.com/APIs/Reporting_API#/). You will need to sign in to view this content.\u00a0\nYou connect to your Adap.tv account in the Data Center. This topic discusses the fields and menus that are specific to the Adap.tv connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Adap.tv account and create a DataSet, you must have an Adap.tv username and password.\u00a0\nConnecting to Your Adap.tv Account\nThis section enumerates the options in the Credentials and Details panes in the Adap.tv Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Adap.tv account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionUsernameEnter your Adap.tv username.PasswordEnter your Adap.tv password.\u00a0\nOnce you have entered valid Adap.tv credentials, you can use the same account any time you go to create a new Adap.tv DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a number of menus in which you can select and configure your Adap.tv report.", "source": "../../raw_kb/article/one_by_aolvideo__adaptv_connector/index.html", "title": "One by AOL:Video - Adap.tv Connector"}, {"objectID": "2dfce90d6126-1", "text": "This pane contains a number of menus in which you can select and configure your Adap.tv report.\nMenuDescriptionOrganization IDIf you want to enter your own organization ID, select\u00a0Override. Otherwise, leave this set to\u00a0Default.Enter Your Organization IDEnter the ID of the organization you want to retrieve data for.ReportSelect the Adap.tv report you want to run.\u00a0The following reports are available:Ad Hoc ReportAllows you to build out your own customized report by selecting keys and metrics and indicating a date range.\u00a0\u00a0Generated ReportLets you import a report that already exists in your Adap.tv account.List ReportsReturns a list of all reports in your Adap.tv account.Report NameSelect the existing report you want to pull into Domo.\u00a0KeysSelect all of the keys you want to import into your report.MetricsSelect all of the metrics you want to appear in your report.Duration\u00a0Select whether you want to pull data for a specific date or a date range.\u00a0Report Date\u00a0Select whether the report data is for a specific date or for a relative number of days back from today.\u00a0Select Specific Date\u00a0Select the date for the report.\u00a0Days BackEnter the number of past days that should appear in the report.\u00a0\u00a0Start DateSpecify whether the\u00a0first date in your date range is a specific or relative date.\u00a0You select the last date in your range in\u00a0End Date.\u00a0End DateSpecify whether the second date in your date range is a specific or relative date. You select the first date in your range in\u00a0Start Date.\u00a0\u00a0Select Specific Start DateSelect\u00a0the first date in your date range.\u00a0Select Specific End DateSelect the second date in your date range.\u00a0Days Back to Start FromEnter the number of the farthest day back that should be represented in the report. Combine with\u00a0Days Back to End At\u00a0to create a range of represented days.", "source": "../../raw_kb/article/one_by_aolvideo__adaptv_connector/index.html", "title": "One by AOL:Video - Adap.tv Connector"}, {"objectID": "2dfce90d6126-2", "text": "For example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Days Back to End AtEnter the number of the most recent day back that should be represented in the report. Combine with\u00a0Days Back to Start From\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/one_by_aolvideo__adaptv_connector/index.html", "title": "One by AOL:Video - Adap.tv Connector"}, {"objectID": "884800533419-0", "text": "TitleOne Click Retail ConnectorArticle BodyIntro\nOne Click Retail provides ecommerce data measurement, sales analytics and search optimization for brand manufacturers. Use Domo's One Click Retail connector to retrieve your data from One Click Retail. To learn more about One Click Retail, visit their website (http://www.oneclickretail.com).\nYou connect to your One Click Retail account in the Data Center. This topic discusses the fields and menus that are specific to the One Click Retail connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your One Click Retail account and create a DataSet, you must have the following:\nA One Click Retail API key.A One Click Retail UUID.\nFor more information, reach out to your One Click Retail account representative.\nConnecting to Your One Click Retail Account\nThis section enumerates the options in the Credentials and Details panes in the One Click Retail Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your One Click Retail account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter your One Click Retail API key.Client UUIDEnter your One Click Retail UUID.\nOnce you have entered valid One Click Retail credentials, you can use the same account any time you go to create a new One Click Retail DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains various menus in which you configure the data you want to retrieve from One Click Retail.", "source": "../../raw_kb/article/one_click_retail_connector/index.html", "title": "One Click Retail Connector"}, {"objectID": "884800533419-1", "text": "This pane contains various menus in which you configure the data you want to retrieve from One Click Retail.\nMenuDescriptionFilter ID (Optional)If you want your report to include specific data from your One Click Retail account, enter the filter ID here.Weeks Back or Select DatesSelect whether you want to pull data for a specific number of weeks back or input a data range.Weeks BackEnter the number of weeks back you want to pull data for.Duration\u00a0Select whether you want to pull data for a specific date or a date range.\u00a0Report Date\u00a0Select whether the report data is for a specific date or for a relative number of days back from today.\u00a0Select Specific Date\u00a0Select the date for the report.\u00a0Days BackEnter the number of past days that should appear in the report.\u00a0\u00a0Start DateSpecify whether the\u00a0first date in your date range is a specific or relative date.\u00a0You select the last date in your range in\u00a0End Date.\u00a0End DateSpecify whether the second date in your date range is a specific or relative date. You select the first date in your range in\u00a0Start Date.\u00a0\u00a0Select Specific Start DateSelect\u00a0the first date in your date range.\u00a0Select Specific End DateSelect the second date in your date range.\u00a0Days Back to Start FromEnter the number of the farthest day back that should be represented in the report. Combine with\u00a0Days Back to End At\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Days Back to End AtEnter the number of the most recent day back that should be represented in the report. Combine with\u00a0Days Back to Start From\u00a0to create a range of represented days.", "source": "../../raw_kb/article/one_click_retail_connector/index.html", "title": "One Click Retail Connector"}, {"objectID": "884800533419-2", "text": "For example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nFAQs\nHow often can the data be updated?\nAs often as needed.\nAre there any API limits I should be aware of?\nNo.", "source": "../../raw_kb/article/one_click_retail_connector/index.html", "title": "One Click Retail Connector"}, {"objectID": "abbd0861c8e0-0", "text": "TitleOn-Premise SharePoint Data Provider Plugin (Beta)Article BodyIntro\nThe Domo SharePoint Plugin allows you to create jobs in Workbench 5 to get the data from SharePoint into Domo.\u00a0Domo Workbench provides a secure, client-side solution for uploading your on-premise data to Domo. The Domo SharePoint Data Provider links Domo Workbench to operational SharePoint data. You can build datasets from SharePoint data in Workbench and then create real-time visualizations of SharePoint data in the Domo service. This tutorial teaches you how to use the Domo SharePoint Plugin to connect to your SharePoint data.\nWhat you need to get started\nWindows 10 64-bit operating systemDomo WorkbenchSharePoint Plugin\nInstalling the SharePoint Plugin in Domo Workbench\nAll Workbench plugins are contained within Dynamic Link Libraries (DLLs). You can add plugins to Workbench by selecting the desired DLL on your machine or network.\nAdding SharePoint Plugin to Workbench:\n\u00a0\n\n\n\u00a0\n\nNote:\u00a0Your SharePoint Plugin must be located in a subdirectory of the chosen directory.", "source": "../../raw_kb/article/onpremise_sharepoint_data_provider_plugin_beta/index.html", "title": "On-Premise SharePoint Data Provider Plugin (Beta)"}, {"objectID": "abbd0861c8e0-1", "text": "Note:\u00a0Your SharePoint Plugin must be located in a subdirectory of the chosen directory.\n\n\n\nIn Domo Workbench, click \u00a0in the left-hand icon bar.Click Plugins in the More pane. (If you do not see this pane, click \u00a0to expand it.)\tThe Plugin Manager opens.Under Register new plugins click the ellipsis (...) next to the Search path field.  \t\u00a0On your machine or network, locate and open the folder that contains a folder with all DLLs of SharePoint Plugin.Click Add after you have chosen your DLL.\nConnecting to the SharePoint Data\nCreating a SharePoint DataSet job in Workbench 5\nClick the \u00a0icon in the left-hand icon bar.Click the + button in the top right corner of the jobs listing pane.An Overview tab for a new job will appear.Enter the following details in Job Details section.FieldDescriptionDomo DomainSelect the desired account (Domo instance) in the Domo Domain dropdown menu.\nIf you have only one account set up, that account is already chosen for you and the menu is unavailable.Job NameEnter a name for the DataSet Job.\nThis is the job name that appears in Workbench, not the name of the uploaded DataSet in Domo.Transport TypeSelect Domo SharePoint Data Provider.Reader TypeSelect the file type that you want to read from SharePoint in Workbench. \t\u00a0In the Domo Details section, provide the information for your DataSet.FieldDescriptionDataSet NameEnter the name of the DataSet. This is the name of the uploaded DataSet in Domo.DataSet TypeSelect the type of DataSet from the dropdown. The DataSet type you select or enter here is reflected as the Connector type in Domo after you execute the job.DataSet DescriptionEnter a description for the DataSet, if desired.\nThis is the description of the DataSet as it appears in Domo.\u00a0Click Create.\tA new SharePoint DataSet Job is created and added to the list of jobs for the currently authenticated account.", "source": "../../raw_kb/article/onpremise_sharepoint_data_provider_plugin_beta/index.html", "title": "On-Premise SharePoint Data Provider Plugin (Beta)"}, {"objectID": "abbd0861c8e0-2", "text": "Note:\u00a0After creating a job, you cannot edit any of the settings you just configured except for the DataSet name. If you want to change any of the other settings, you must create another new job.", "source": "../../raw_kb/article/onpremise_sharepoint_data_provider_plugin_beta/index.html", "title": "On-Premise SharePoint Data Provider Plugin (Beta)"}, {"objectID": "abbd0861c8e0-3", "text": "Configuring Your Job\nOnce a job is created, you need to provide the configuration details for the job.\nConfigure the Source\nProvide the details for the SharePoint data in the Source menu.Click Edit.A Domo SharePoint Data Provider Editor window will appear. Here, you need to provide the Credentials and Report details required to connect to your SharePoint data.FieldDescriptionConnection TypeSelect the connection type as SharePoint On-Premise.SharePoint URLEnter URL for the SharePoint site.UsernameEnter your SharePoint username.PasswordEnter your SharePoint password.DomainEnter your SharePoint Windows domain name.\nExample: If your SharePoint site was located at https://sample.sharepoint.com, your domain name would be \u201csample\u201d.ReportSelect the report from the dropdown.Server Relative URLEnter the name of the data file you want to connect with this DataSet in SharePoint.\u00a0Click Apply.  \nConfigure Data Processing\nProvide the details about data processing for the SharePoint data in the Processing menu.Click Edit.An Editor window will appear for the selected Reader type. Here, you can provide the properties and details for your data to define how your data will be handled in the DataSet.Click Apply.\nConfiguring Data Update Method\nSelect Replace if you want newly uploaded data to replace the existing data in the DataSet.Select Append if you want the newly added data to be appended (added) to the existing dataSelect Partition if you want to apply partitioning on your data. Partitioning uses a grain (like day or week) to create groups in your data. Data can then be processed as a group, and added or replaced as it changes.Select the Partition column and Date grain in the respective drop downs for your data.\nApplying Transforms to Your Data\nTransforms modify your data locally before uploading it to Domo. They are faster, and process on your computer or server without a queue. Choose from a variety of options to transform your data so it\u2019s ready when it hits Domo.", "source": "../../raw_kb/article/onpremise_sharepoint_data_provider_plugin_beta/index.html", "title": "On-Premise SharePoint Data Provider Plugin (Beta)"}, {"objectID": "abbd0861c8e0-4", "text": "Select the desired transform from the drop down and click the +\u00a0button next to it.Mention the transform properties for the selected transform and click Apply.You can add multiple transforms to your data.Click \u00a0to update the transform properties for a specific transform.Click \u00a0to remove a specific transform.Click the \u00a0(up and down arrows) to interchange the positions of the transforms.\nImpersonating Your Job\nUse of impersonation allows the Domo Workbench to run your job as a specific Active Directory user.", "source": "../../raw_kb/article/onpremise_sharepoint_data_provider_plugin_beta/index.html", "title": "On-Premise SharePoint Data Provider Plugin (Beta)"}, {"objectID": "abbd0861c8e0-5", "text": "Note: The user profile in job impersonation needs to be a role that has access to the source data needed to run the job.", "source": "../../raw_kb/article/onpremise_sharepoint_data_provider_plugin_beta/index.html", "title": "On-Premise SharePoint Data Provider Plugin (Beta)"}, {"objectID": "abbd0861c8e0-6", "text": "Select the Requires impersonations check box.Your Active Directory domain name and username will appear.Enter your Active Directory password and click Validate.\nAdditional Settings for Your Job\nSet the advanced options for how your job uploads data in Domo in the Additional Settings. You can specify the Error handling method, and the job run duration and conditions here.\nScheduling Your Job\nYou can schedule a DataSet job to routinely upload data from external DataSets to Domo. You mention this frequency in the Schedule tab.\nBasic Schedule\nThe Basic Schedule section allows you to update the data manually, update when file is changed, or update on a schedule.\nIf you chose to update on a schedule, you can select the time interval and a specific time window to run the job.\nAdvanced Schedule\nIn the Advanced Scheduling section, you can opt to run the job once a day, more than once a day, every day, specific days of the week/month, every month, or specific months.\nClick the \u00a0(Save) button to save your changes.\nSchema Protection for Your Job\nDomo Workbench 5 offers three different schema protection types. You can control the schema changes by allowing the schema changes safely or permitting the unprotected schema changes, or completely blocking all schema changes. Domo Workbench supports a Protect feature that enables you to control these schema changes in a way. It is available for the \u201cAllow safe schema changes\u201d and \u201cAllow unprotected schema changes\u201d views.\nProtect Column\nThe Protect column indicates whether your column (data field) is protected while you apply the schema changes to your job.", "source": "../../raw_kb/article/onpremise_sharepoint_data_provider_plugin_beta/index.html", "title": "On-Premise SharePoint Data Provider Plugin (Beta)"}, {"objectID": "abbd0861c8e0-7", "text": "If the Protect checkbox is selected for a column, it means that column is protected, and no schema changes can be made. If you try to remove the protection for any column (by unchecking it) while allowing either the safe schema changes or unprotected schema changes, the Domo Workbench will give you the following\u00a0warning: Warning: Unprotected columns can be changed and deleted, which may break content in Domo.  \t\u00a0The Protect column provides you a control to protect or unprotect all columns with a single click. Select the checkbox next to the column header (Protect) to protect all your columns at once. Similarly, you can unprotect your columns at the same time by deselecting this checkbox.   \t\u00a0The column header also provides the control to get a filtered view of protected, unprotected, or both type of entries with a single click.When you click to select the regular select view , the Protect column will display all protected entries.When you click to select the unchecked view , the Protect column will display the unprotected entries.When you click to select the mixed view , the Protect column displays both protected and unprotected entries together.You cannot change the name of a protected source column. Domo Workbench does not allow the edit operation on a protected source column name. However, you can change the names or properties for other columns.  \t\u00a0Similarly, you cannot delete a protected column.If you want to allow the schema change, uncheck the column and re-run the job.\nAllow Safe Schema Changes\nIf you select this option, the unprotected columns will accept the changes during the next execution, and will automatically be protected after. New columns will be added, and will automatically be protected in future runs. The Allow safe schema changes\u00a0option is the default setting for new jobs.\nAllow Unprotected Schema Changes\nIf you choose to allow unprotected schema changes, you will be able to change and delete the unprotected columns, and they will remain unprotected.\nBlock All Schema Changes", "source": "../../raw_kb/article/onpremise_sharepoint_data_provider_plugin_beta/index.html", "title": "On-Premise SharePoint Data Provider Plugin (Beta)"}, {"objectID": "abbd0861c8e0-8", "text": "Block All Schema Changes\nIf you choose to block all schema changes, you will not see the Protect option for your columns. If you attempt to make changes to any column and run the job, you will receive an error stating about your forceful change.\nSetting Notifications for Your Job\nYou can set notify other users upon your job success or failure by simply selecting the respective checkbox in front of their names under the respective columns.\nOnce you are done with the job specifications, click the \u00a0(Save) button to save your changes.Click the \u00a0(Execute) button to run your job.", "source": "../../raw_kb/article/onpremise_sharepoint_data_provider_plugin_beta/index.html", "title": "On-Premise SharePoint Data Provider Plugin (Beta)"}, {"objectID": "c82916e86169-0", "text": "TitleOoyala Advanced ConnectorArticle BodyIntro\nOoyala provides\u00a0online video analytics and monetization solutions that boost revenues from video.\u00a0\u00a0For more information about the Ooyala\u00a0API, visit\u00a0their website.\u00a0(http://support.ooyala.com/developers...ics_v3_metrics)\nThe Ooyala connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking Cloud App in the toolbar at the top of the window.\nThere is also a simplified\u00a0version of the Ooyala connector. This connector is almost identical but does not include the \"Ooyala IQ Analytics v.3\" report. For more information about this version, see Ooyala Connector.\u00a0\u00a0\nYou connect to your\u00a0Ooyala account in the\u00a0Data Center. This topic discusses the fields and menus that are specific to the\u00a0Ooyala\u00a0connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrimary Use CasesUse this connector to monitor viewer habits by device type, platform, screen size, and playthrough rate.Primary MetricsMost viewed videosTotal video viewsTotal vs. unique viewsVideo displays/loads/startsVideo playthrough rate percentagePrimary Company RolesMarketing directorMarketing managerTraining video producerAverage Implementation Time1 hourEase of Use (on a 1-to-10 scale with 1 being easiest)3 (higher when using the \"Ooyala IQ Analytics v.3\" report)\nBest Practices\nRetrieve account/brand performance data for account over time.View trends to determine viewer behaviors.Determine analytics regarding device types and platforms to optimize viewing experience.\nPrerequisites", "source": "../../raw_kb/article/ooyala_advanced_connector/index.html", "title": "Ooyala Advanced Connector"}, {"objectID": "c82916e86169-1", "text": "Prerequisites\nTo connect to your\u00a0Ooyala account and create a DataSet, you must have an Ooyala\u00a0API Key and API Secret. You can obtain these credentials by doing the following:\nLog into your account at https://backlot.ooyala.com.\u00a0Click the\u00a0Account\u00a0button in the toolbar at the top of the screen.Click\u00a0Developers\u00a0in the subtab\u00a0row\u00a0under the main toolbar.\nThe API Key is immediately visible in this tab. To show the API Secret, click\u00a0Display API Secret.\u00a0\u00a0\nConnecting to Your\u00a0Ooyala Account\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the\u00a0Ooyala\u00a0Connector page.\u00a0The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your\u00a0Ooyala\u00a0account. For information about obtaining these credentials, see \"Prerequisites,\" above.\u00a0\nFieldDescriptionAPI KeyEnter the API Key for your Ooyala account.API SecretEnter the API Secret for your Ooyala account.\nOnce you have entered valid\u00a0Ooyala credentials, you can use the same account any time you go to create a new\u00a0Ooyala DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see\u00a0Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Report\u00a0menu in which you select a report type. Depending on the report type you select, other parameters may be required.", "source": "../../raw_kb/article/ooyala_advanced_connector/index.html", "title": "Ooyala Advanced Connector"}, {"objectID": "c82916e86169-2", "text": "MenuDescriptionReportSelect an Ooyala report. The following reports are available:Account PerformanceReturns perfromance metrics for the authenticated user's account.Brand PerformanceReturns performance metrics based on brands for the authenticated user's account.Performance Analytics for Device TypesReturns performance metrics for device types.\u00a0Performance Analytics for PlatformsReturns performance metrics per platform.Get Total Bytes DeliveredReturns total bytes delivered within a fixed period of time.List All AssetsReturns a list of videos and other assets for the authenticated user's account.List All Asset AnalysisReturns performance metrics for each asset.\u00a0List Most Popular VideosReturns a list of the most popular videos in descending order.List Plays By CountryReturns performance metrics by specified country.List Videos with Most MomentumReturns a list of videos with the most momentum in descending order.Ooyala IQ Analytics v.3Returns customized data based on selected dimensions and metrics as well as applied filters.LabelSelect the label you want to retrieve data for.Duration\u00a0Specify whether the data in this report is for a single date or a range of dates.Report Date\u00a0Specify whether the\u00a0data is for a specific\u00a0or relative date.\u00a0Choose\u00a0Relative if you always want", "source": "../../raw_kb/article/ooyala_advanced_connector/index.html", "title": "Ooyala Advanced Connector"}, {"objectID": "c82916e86169-3", "text": "specific\u00a0or relative date.\u00a0Choose\u00a0Relative if you always want the report to\u00a0retrieve data for a\u00a0given number of days back (which you specify in Days Back) from the current date. For example, if you enter\u00a05 for Days Back\u00a0and set the\u00a0DataSet to update\u00a0daily, each\u00a0new day the report will update to show information for the date 5 days in the past.\u00a0\u00a0\u00a0Select Specific Date\u00a0Select the date you want to retrieve\u00a0data for.\u00a0\u00a0Days Back\u00a0Enter the number of days back from the current date that will be presented in the report.\u00a0Start Date\u00a0Specify whether the\u00a0first date in your date range is a specific or relative date. Choose\u00a0Relative if you always want the report to retrieve data for a given number of days back (which you specify in\u00a0Days Back to Start From) from the current date.\u00a0If you choose Relative here, you should also choose Relative for\u00a0End Date\u00a0and specify\u00a0a value for\u00a0Days Back to End At.", "source": "../../raw_kb/article/ooyala_advanced_connector/index.html", "title": "Ooyala Advanced Connector"}, {"objectID": "c82916e86169-4", "text": "For example, if you enter\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05 for\u00a0Days Back to End At\u00a0and you set the\u00a0DataSet to update\u00a0daily, each new day the report will update to show information for 5 to 10 days in the past.\u00a0\u00a0\u00a0\u00a0End Date\u00a0Specify whether the\u00a0last date in your date range is a specific or relative date. Choose\u00a0Relative if you always want the report to retrieve data for a given number of days back (which you specify in\u00a0Days Back to\u00a0End At) from the current date.\u00a0If you choose Relative here, you should also choose Relative for\u00a0Start Date\u00a0and specify\u00a0a value for\u00a0Days\u00a0Back to\u00a0Start From.\u00a0\nFor example, if you enter\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05 for\u00a0Days Back to End At\u00a0and you set the\u00a0DataSet to update\u00a0daily, each new day the report will update to show information for 5 to 10 days in the past.\u00a0\u00a0\u00a0\u00a0\u00a0Select Specific Start Date\u00a0Select the first date in your date range.\u00a0\u00a0Select Specific End Date\u00a0Select the\u00a0last date in your date range.\u00a0\u00a0Days Back to Start From\u00a0Enter the number of days before the current date to use as the start date. \u00a0\nFor example, if you enter 10 for Days Back to Start From and 5 for\u00a0Days Back to End At\u00a0and you set the DataSet to update daily, each day the report updates to show information for a 5-day range, starting 10 days ago and ending 5 days ago.\u00a0Days Back to End At\u00a0Enter the number of days before the current date to use as the\u00a0end date.", "source": "../../raw_kb/article/ooyala_advanced_connector/index.html", "title": "Ooyala Advanced Connector"}, {"objectID": "c82916e86169-5", "text": "For example, if you enter 10 for Days Back to Start From and 5 for\u00a0Days Back to End At\u00a0and you set the DataSet to update daily, each day the report updates to show information for a 5-day range, starting 10 days ago and ending 5 days ago.\u00a0\u00a0Report Period TypeSelect the period type for the report data. For example, if you entered 30 for Start Day and selected Month for Report Period Type, and today's date was September 15, data would be returned for the month of August.BreakdownSelect the time unit the report data will be broken down by. For example, if you selected Week, there will be a row in the report for each individual week.Include Sub AccountSpecify whether sub accounts are to be included.Device TypeSelect the device type you want to retrieve data for.Filters (Optional)Enter filters using the following syntax:\nfilter_type1=='filter_value1',filter_type2=='filter_value2'...\nFor example:\ncountry=='CA',device_type=='mobile'\nFor more information, visit\u00a0http://help.ooyala.com/video-platform/api/analytics_v3_api_reporting_filters.html#analytics_v3_filters\n\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nTroubleshooting\nCheck that date ranges are valid for the accounts/videos.", "source": "../../raw_kb/article/ooyala_advanced_connector/index.html", "title": "Ooyala Advanced Connector"}, {"objectID": "eb6b121503d5-0", "text": "TitleOoyala ConnectorArticle Body\nIntro\nOoyala provides\u00a0online video analytics and monetization solutions that boost revenues from video.\u00a0You can use Domo's Ooyala connector to retrieve performance analytics, lists of your most popular videos, total bytes delivered, and so on.\u00a0For more information about the Ooyala\u00a0API, visit\u00a0their website.\u00a0(http://support.ooyala.com/developers...ics_v3_metrics)\nThe Ooyala connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking Cloud App in the toolbar at the top of the window.\nThere is also an advanced version of the Ooyala connector. This connector is almost identical but includes an additional report, \"Ooyala IQ Analytics v.3,\" a customizable report that lets you select dimensions and metrics as well as apply filters. For more information about the advanced report, see\u00a0Ooyala Advanced Connector.\u00a0\u00a0\nYou connect to your\u00a0Ooyala account in the\u00a0Data Center. This topic discusses the fields and menus that are specific to the\u00a0Ooyala\u00a0connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrimary Use CasesUse this connector to monitor viewer habits by device type, platform, screen size, and playthrough rate.Primary MetricsMost viewed videosTotal video viewsTotal vs. unique viewsVideo displays/loads/startsVideo playthrough rate percentagePrimary Company RolesMarketing directorMarketing managerTraining video producerAverage Implementation Time1 hourEase of Use (on a 1-to-10 scale with 1 being easiest)3\nBest Practices\nRetrieve account/brand performance data for account over time.View trends to determine viewer behaviors.Determine analytics regarding device types and platforms to optimize viewing experience.\nPrerequisites", "source": "../../raw_kb/article/ooyala_connector/index.html", "title": "Ooyala Connector"}, {"objectID": "eb6b121503d5-1", "text": "Prerequisites\nTo connect to your\u00a0Ooyala account and create a DataSet, you must have an Ooyala\u00a0API Key and API Secret. You can obtain these credentials by doing the following:\nLog into your account at https://backlot.ooyala.com.\u00a0Click the\u00a0Account\u00a0button in the toolbar at the top of the screen.Click\u00a0Developers\u00a0in the subtab\u00a0row\u00a0under the main toolbar.\nThe API Key is immediately visible in this tab. To show the API Secret, click\u00a0Display API Secret.\u00a0\u00a0\nConnecting to Your\u00a0Ooyala Account\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the\u00a0Ooyala\u00a0Connector page.\u00a0The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your\u00a0Ooyala\u00a0account. For information about obtaining these credentials, see \"Prerequisites,\" above.\u00a0\nFieldDescriptionAPI KeyEnter the API Key for your Ooyala account.API SecretEnter the API Secret for your Ooyala account.\nOnce you have entered valid\u00a0Ooyala credentials, you can use the same account any time you go to create a new\u00a0Ooyala DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see\u00a0Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Report\u00a0menu in which you select a report type. Depending on the report type you select, other parameters may be required.", "source": "../../raw_kb/article/ooyala_connector/index.html", "title": "Ooyala Connector"}, {"objectID": "eb6b121503d5-2", "text": "MenuDescriptionReportSelect an Ooyala report. The following reports are available:Account PerformanceReturns perfromance metrics for the authenticated user's account.Brand PerformanceReturns performance metrics based on brands for the authenticated user's account.Performance Analytics for Device TypesReturns performance metrics for device types.\u00a0Performance Analytics for PlatformsReturns performance metrics per platform.Get Total Bytes DeliveredReturns total bytes delivered within a fixed period of time.List All AssetsReturns a list of videos and other assets for the authenticated user's account.List All Asset AnalysisReturns performance metrics for each asset.\u00a0List Most Popular VideosReturns a list of the most popular videos in descending order.List Plays By CountryReturns performance metrics by specified country.List Videos with Most MomentumReturns a list of videos with the most momentum in descending order.\u00a0LabelSelect the label you want to retrieve data for.Duration\u00a0Specify whether the data in this report is for a single date or a range of dates.Report Date\u00a0Specify whether the\u00a0data is for a specific\u00a0or relative date.\u00a0Choose\u00a0Relative if you always want the report to\u00a0retrieve data for a\u00a0given number of days back (which you specify in Days Back)", "source": "../../raw_kb/article/ooyala_connector/index.html", "title": "Ooyala Connector"}, {"objectID": "eb6b121503d5-3", "text": "of days back (which you specify in Days Back) from the current date. For example, if you enter\u00a05 for Days Back\u00a0and set the\u00a0DataSet to update\u00a0daily, each\u00a0new day the report will update to show information for the date 5 days in the past.\u00a0\u00a0\u00a0Select Specific Date\u00a0Select the date you want to retrieve\u00a0data for.\u00a0\u00a0Days Back\u00a0Enter the number of days back from the current date that will be presented in the report.\u00a0Start Date\u00a0Specify whether the\u00a0first date in your date range is a specific or relative date. Choose\u00a0Relative if you always want the report to retrieve data for a given number of days back (which you specify in\u00a0Days Back to Start From) from the current date.\u00a0If you choose Relative here, you should also choose Relative for\u00a0End Date\u00a0and specify\u00a0a value for\u00a0Days Back to End At.", "source": "../../raw_kb/article/ooyala_connector/index.html", "title": "Ooyala Connector"}, {"objectID": "eb6b121503d5-4", "text": "For example, if you enter\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05 for\u00a0Days Back to End At\u00a0and you set the\u00a0DataSet to update\u00a0daily, each new day the report will update to show information for 5 to 10 days in the past.\u00a0\u00a0\u00a0\u00a0End Date\u00a0Specify whether the\u00a0last date in your date range is a specific or relative date. Choose\u00a0Relative if you always want the report to retrieve data for a given number of days back (which you specify in\u00a0Days Back to\u00a0End At) from the current date.\u00a0If you choose Relative here, you should also choose Relative for\u00a0Start Date\u00a0and specify\u00a0a value for\u00a0Days\u00a0Back to\u00a0Start From.\u00a0\nFor example, if you enter\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05 for\u00a0Days Back to End At\u00a0and you set the\u00a0DataSet to update\u00a0daily, each new day the report will update to show information for 5 to 10 days in the past.\u00a0\u00a0\u00a0\u00a0\u00a0Select Specific Start Date\u00a0Select the first date in your date range.\u00a0\u00a0Select Specific End Date\u00a0Select the\u00a0last date in your date range.\u00a0\u00a0Days Back to Start From\u00a0Enter the number of days before the current date to use as the start date. \u00a0\nFor example, if you enter 10 for Days Back to Start From and 5 for\u00a0Days Back to End At\u00a0and you set the DataSet to update daily, each day the report updates to show information for a 5-day range, starting 10 days ago and ending 5 days ago.\u00a0Days Back to End At\u00a0Enter the number of days before the current date to use as the\u00a0end date.", "source": "../../raw_kb/article/ooyala_connector/index.html", "title": "Ooyala Connector"}, {"objectID": "eb6b121503d5-5", "text": "For example, if you enter 10 for Days Back to Start From and 5 for\u00a0Days Back to End At\u00a0and you set the DataSet to update daily, each day the report updates to show information for a 5-day range, starting 10 days ago and ending 5 days ago.\u00a0\u00a0Report Period TypeSelect the period type for the report data. For example, if you entered 30 for Start Day and selected Month for Report Period Type, and today's date was September 15, data would be returned for the month of August.BreakdownSelect the time unit the report data will be broken down by. For example, if you selected Week, there will be a row in the report for each individual week.Include Sub AccountSpecify whether sub accounts are to be included.\n\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nTroubleshooting\nCheck that date ranges are valid for the accounts/videos.", "source": "../../raw_kb/article/ooyala_connector/index.html", "title": "Ooyala Connector"}, {"objectID": "0e8cb126bb3c-0", "text": "TitleOpenfire ConnectorArticle BodyIntro\nOpenfire\u00a0(previously known as\u00a0Wildfire\u00a0and\u00a0Jive Messenger) is an\u00a0instant messaging\u00a0(IM) and\u00a0groupchat\u00a0server\u00a0that uses\u00a0XMPP\u00a0server written in\u00a0Java. To learn more about the Openfire API, visit their page (https://www.igniterealtime.org/proje...pi/readme.html).\nYou connect to your Openfire account in the Data Center. This topic discusses the fields and menus that are specific to the Openfire connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Openfire account and create a DataSet, you must have the following:\nThe hostname or IP address where the Openfire database is stored.The port number used to communicate with the database.The database name.The credentials (username and password) for the account.The certificate key for the Openfire database.\nYou must also whitelist\u00a0a number of IP address as described in\u00a0Whitelisting IP Addresses.\nConnecting to Your Openfire Account\nThis section enumerates the options in the Credentials and Details panes in the Openfire Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Openfire account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionHostnameEnter the hostname or IP address of the Openfire server.PortEnter the port number used to communicate with the database.DatabaseEnter the name of the Openfire database.UsernameEnter your Openfire username.PasswordEnter your Openfire password.Certificate KeyEnter your certificate key for the database.", "source": "../../raw_kb/article/openfire_connector/index.html", "title": "Openfire Connector"}, {"objectID": "0e8cb126bb3c-1", "text": "Once you have entered valid Openfire credentials, you can use the same account any time you go to create a new Openfire DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors. \u00a0\nDetails Pane\nThis pane contains only a single field where you enter your SQL query.\nMenuDescriptionSQL StatementEnter the Openfire SQL query you want to retrieve data for.\nFor example: SELECT * FROM ofPresence\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/openfire_connector/index.html", "title": "Openfire Connector"}, {"objectID": "f9229980a91c-0", "text": "Title\n\nOpening Analyzer\n\nArticle Body\n\nIn the Analyzer for a Visualization card, you can change the visual characteristics of the chart.\nThe Analyzer is only available for users with a default security role of Editor or higher (or a custom role with the Edit Cards grant enabled). Also, if the \"Only the owner and administrators\" checkbox in the bottom left corner of the Details view has been selected, you can only display Analyzer\u00a0if you have an Admin security role (or a custom role with the Manage All Cards and Pages grant enabled) or you have been assigned as the card owner. For more information, see\u00a0Managing Roles.\nFor more information about the Analyzer, see\u00a0Analyzer Overview.\nTo display Analyzer\u00a0for a Visualization Card,\nDo one of the following:From the card page, mouse over the card in the page view, click , then select Edit in Analyzer.From the Details page, click\u00a0 in the icon bar in the top right corner of the page.From the\u00a0Details\u00a0page, click\u00a0 then select Edit in Analyzer.", "source": "../../raw_kb/article/opening_analyzer/index.html", "title": "Opening Analyzer"}, {"objectID": "1472063d318b-0", "text": "Title\n\nOpening a Sumo Card for Editing\n\nArticle Body\n\nAfter you have created a Sumo card as described in Adding a Sumo Card, you can open it for editing. The options available in the Edit view are the same as those in the Build view.\nTo open an existing table for editing,\nNavigate to the card page where the Sumo card is found.Mouse over the card that you want to edit.Click \u00a0> Edit Card.The Edit view opens.", "source": "../../raw_kb/article/opening_a_sumo_card_for_editing/index.html", "title": "Opening a Sumo Card for Editing"}, {"objectID": "9d9c27db6e16-0", "text": "Title\n\nOpenWeatherMap Connector\n\nArticle Body", "source": "../../raw_kb/article/openweathermap_connector/index.html", "title": "OpenWeatherMap Connector"}, {"objectID": "9d9c27db6e16-1", "text": "Intro\nOpenWeatherMap is an online service that provides weather data, including current weather data, forecasts, and historical data to the developers of web services and mobile applications. To learn more about the OpenWeatherMap API, visit their page (https://openweathermap.org/api).\nYou connect to your OpenWeatherMap account in the Data Center. This topic discusses the fields and menus that are specific to the OpenWeatherMap connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrimary Use CasesCommon use cases are for...Retailers that need to see how weather impacts sales, andLogistics companies that need to understand forecasts and historical weather.Basically this connector is great for any organization that relies on weather trends for attendance, product delivery, or outdoor work.Primary MetricsTemperature and precipitation forecastsHistorical weather patternsLikelihood of weather events occurringPossibility of extreme events.Primary Company RolesFacilitiesEvent planningOperations managerProgram managerSales teamsAverage Implementation TimeLess than 1 hourEase of Use (on a 1-to-10 scale with 1 being easiest)3\nPrerequisites\nTo connect to your OpenWeatherMap account and create a DataSet, you must have an OpenWeatherMap API key. You can obtain an API key by doing the following:\nLog into your OpenWeatherMap account.Click the API Keys tab.Copy and paste the default API key into Domo OR use the Create Key option to generate a new key.\nConnecting to Your OpenWeatherMap Account\nThis section enumerates the options in the Credentials and Details panes in the OpenWeatherMap Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane", "source": "../../raw_kb/article/openweathermap_connector/index.html", "title": "OpenWeatherMap Connector"}, {"objectID": "9d9c27db6e16-2", "text": "Credentials Pane\nThis pane contains fields for entering credentials to connect to your OpenWeatherMap account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter your OpenWeatherMap API key. For information about obtaining a key, see \"Prerequisites,\" above.\nOnce you have entered valid OpenWeatherMap credentials, you can use the same account any time you go to create a new OpenWeatherMap DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/openweathermap_connector/index.html", "title": "OpenWeatherMap Connector"}, {"objectID": "9d9c27db6e16-3", "text": "MenuDescriptionReportSelect the OpenWeatherMap report you want to run.\u00a0The following reports are available:Current Weather DataReturns current weather data for one location, based on city ID, city name, geographic coordinates (latitude and longitude), or ZIP code.Current Weather Data for Multiple CitiesReturns current weather data for several city IDs.Five-Day Three-Hour ForecastReturns a weather forecast for the next five days, at three hour intervals, for one location identified by city ID, city name, or geographic coordinates (latitude and longitude).Historical DataReturns historical weather data for one location identified by city ID, city name, or geographic coordinates (latitude and longitude). Requires a separate paid plan; for more information see OpenWeatherMap Subscription Pricing.Sixteen Day Daily ForecastReturns a 16-day weather forecast with daily average parameters for one location identified by city ID, city name, or geographic coordinates (latitude and longitude).Current Weather by Weather StationReturns current weather from one or several weather stations.Choose Location BySelect whether you want the location for your report to be based on city ID, city name, latitude and longitude, or zip code.", "source": "../../raw_kb/article/openweathermap_connector/index.html", "title": "OpenWeatherMap Connector"}, {"objectID": "9d9c27db6e16-4", "text": "city name, latitude and longitude, or zip code. For the most accurate results, choose City ID.City IDEnter the City ID. A list of City IDs can be downloaded from OpenWeatherMap.City NameEnter the name of the city you want to retrieve data for.LatitudeEnter the latitude of the region you want to retrieve data for. This can be a positive or negative number with up to 6 decimal places. Degree-minutes-seconds form is not accepted.LongitudeEnter the longitude of the region you want to retrieve data for. This can be a positive or negative number with up to 6 decimal places. Degree-minutes-seconds form is not accepted.Zip CodeEnter the ZIP code of the area you want to retrieve data for.UnitsSelect whether to return temperature data in Kelvin, Celsius, or Fahrenheit units.Search AccuracySelect whether to return the one closest match (Accuracy) or all similar values (Like).", "source": "../../raw_kb/article/openweathermap_connector/index.html", "title": "OpenWeatherMap Connector"}, {"objectID": "9d9c27db6e16-5", "text": "For example, if this was set to Accurate and you searched for a city named \"Cedar,\" your report would return data for \"Cedar Rapids\" (since this is the city determined by the server to be the best match). But if this parameter was set to Like, you would get results for \"Cedar City,\" \"Cedar Hills,\" as well as cities named \"Cedar.\"Multiple City IDsEnter a comma-separated list of City IDs. For example:\u00a0524901,703448,2643743\nA list of City IDs can be downloaded from\u00a0OpenWeatherMap.Start DateSelect the start date for the range of data you want to pull.End DateSelect the end date for the range of data you want to pull.Choose Station BySelect whether to pull station data for a station ID, a geographic point (based on latitude and longitude), or a rectangular zone.Station IDEnter the ID of the station you want to retrieve data for. You can find station IDs by searching for weather stations using geographic coordinates and noting the IDs in the returned data.CountEnter the expected number of weather stations.Bounding BoxEnter the coordinates for the rectangular zone you want to retrieve data for. The format for this is: [longitude of top left point],[latitude of top left point],[longitude of bottom right point],[latitude of bottom right point],[map zoom level].\nFor example: 8.87,49.07,65.21,61.26,6ClusterSelect whether to use server clustering of points.\n\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nTroubleshooting", "source": "../../raw_kb/article/openweathermap_connector/index.html", "title": "OpenWeatherMap Connector"}, {"objectID": "9d9c27db6e16-6", "text": "Troubleshooting\nDouble-check the spelling on the city name.If using city IDs, make sure\u00a0the IDs\u00a0are\u00a0correct.Ensure the free API key is valid.If data limits or speed becomes an issue, consider upgrading to a paid plan.", "source": "../../raw_kb/article/openweathermap_connector/index.html", "title": "OpenWeatherMap Connector"}, {"objectID": "fa3ecd26e8de-0", "text": "TitleOpenX ConnectorArticle BodyIntro\nOpenX\u00a0is an open-source advertising platform which features an integrated banner management interface and tracking system for gathering statistics. To learn more about the OpenX API, visit their page (https://docs.openx.com/Content/developers/about_topics_dev.html).\nYou connect to your OpenX account in the Data Center. This topic discusses the fields and menus that are specific to the OpenX connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your OpenX account and create a DataSet, you must have the following:\nThe hostname or IP address of your OpenX Ad server. The hostname must include the API package directory name. For example: http:///openx/www/api/v1/xmlrpc/The username for your OpenX account. The user with\u00a0this username must be an administrative user.The password for your OpenX account.\nConnecting to Your OpenX Account\nThis section enumerates the options in the Credentials and Details panes in the OpenX Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your OpenX account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionHostEnter the hostname or IP address of your OpenX Ad server. The hostname must include the API package directory name. For example: http:///openx/www/api/v1/xmlrpc/UsernameEnter your OpenX username.\u00a0The user with\u00a0this username must be an administrative user.PasswordEnter your OpenX password.", "source": "../../raw_kb/article/openx_connector/index.html", "title": "OpenX Connector"}, {"objectID": "fa3ecd26e8de-1", "text": "Once you have entered valid OpenX credentials, you can use the same account any time you go to create a new OpenX DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.\nMenuDescriptionReportSelect the OpenX report you want to run.\u00a0The following reports are available:Advertisers ListReturns a list of advertisers.Advertiser StatsReturns statistics for a selected advertiser.Agencies ListReturns a list of agencies.Agency StatsReturns statistics for a selected agency.Banners ListReturns a list of banners.Banner StatsReturns statistics for a selected banner.Campaigns ListReturns a list of campaigns.Campaign StatsReturns statistics for a selected campaigns.Publishers ListReturns a list of publishers.Publisher StatsReturns statistics for a selected publisher.Zones ListReturns a list of zones.Zone StatsReturns statistics for a selected zone.Agency NameSelect the agency you want to retrieve data for.Advertiser\u00a0Select the advertiser you want to retrieve data for.CampaignSelect the campaign you want to retrieve data for.PublisherSelect the publisher you want to retrieve data for.Group BySelected how you want your report data to be aggregated.Past DaysEnter the number of past days you want to pull data for.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/openx_connector/index.html", "title": "OpenX Connector"}, {"objectID": "aa6a0d901515-0", "text": "Title\n\nOpen Exchange Rates Advanced Connector\n\nArticle Body\n\nIntro", "source": "../../raw_kb/article/open_exchange_rates_advanced_connector/index.html", "title": "Open Exchange Rates Advanced Connector"}, {"objectID": "aa6a0d901515-1", "text": "Open Exchange Rates provides real-time exchange rates and currency conversion data. Use Domo\u2019s\u00a0Open Exchange Rates Advanced connector to retrieve the\u00a0latest exchange rates, historical data for a given day or date range, or a list of world currencies.\u00a0To learn more about the Open Exchange Rates\u00a0API, visit their\u00a0website (https://docs.openexchangerates.org/).\nThere is also a simplified version of this connector that allows you to see exchange rates for a base world currency. To learn more about this connector, see Open Exchange Rates Connector.\nPrimary Use CasesThis connector returns exchange rate information and lists of world currencies.Primary MetricsWorld currenciesHistorical exchange ratesLatest exchange ratesPrimary Company RolesSalesFinanceAverage Implementation TimeLess than 1 hourEase of Use (in a 1-to-10 scale with 1 being easiest)2\nThe Open Exchange Rates Advanced connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking Cloud App in the toolbar at the top of the window.\u00a0\nYou connect to\u00a0Open Exchange Rates in the\u00a0Data Center. This topic discusses the fields and menus that are specific to the Open Exchange Rates Advanced connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nBest Practices\nThe \"Currencies\" report only returns countries and their associated currency symbols. To pull the conversation rate, you'll need to use the \"Latest\" or \"Time Series Queries\" report then join it back to the \"Currencies\" report using the\u00a0Currency Symbol\u00a0field.\u00a0\nPrerequisites\nNone.\nConnecting to\u00a0Open Exchange Rates", "source": "../../raw_kb/article/open_exchange_rates_advanced_connector/index.html", "title": "Open Exchange Rates Advanced Connector"}, {"objectID": "aa6a0d901515-2", "text": "Prerequisites\nNone.\nConnecting to\u00a0Open Exchange Rates\nThis section enumerates the options in the Details\u00a0pane in the Open Exchange Rates Advanced Connector page.\u00a0The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nDetails Pane\nThis pane contains a primary\u00a0Report\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/open_exchange_rates_advanced_connector/index.html", "title": "Open Exchange Rates Advanced Connector"}, {"objectID": "aa6a0d901515-3", "text": "MenuDescriptionReportSelect\u00a0an Open Exchange Rates Advanced report. The following reports are available:CurrenciesReturns a list of world currencies.Historical DataReturns exchange rates for a specific date.LatestReturns a list of the latest exchange rates.Time Series QueriesReturns exchange rates for a range of dates. \u00a0Base CurrencyEnter the three-letter abbreviation for the desired base currency. If you do not enter a base currency, USD will be used by default.Specific CurrenciesEnter a comma-separated list of three-letter currency abbreviations\u00a0to request the exchange rates for those currencies. For example: EGP,CNY,GEL to return the exchange rates for\u00a0Egyptian pounds, Chinese yuan, and Georgian lari. \u00a0\u00a0DateEnter a date in\u00a0yyyy-mm-dd format to retrieve exchange rates for that date. For example:\u00a02014-08-28\u00a0Start DaysEnter the number of the farthest day back that should be represented in the report. Combine with End Days to create a range of represented days. For example, if you entered 10\u00a0for Start Days and 5 for End Days, the report would contain data for\u00a010 days ago up until\u00a05 days ago.\u00a0Enter 0 for today.End DaysEnter the number of the most recent day back that should be represented in the report. Combine with Start Days to create a range of represented days. For example, if you entered 10\u00a0for Start Days and 5 for End Days, the report would contain data for 10 days ago up until 5 days ago. Enter 0 for today.\n\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nTroubleshooting\nBe aware of the API limits for your specific account. Free accounts only allow for 1000 API requests per month.Error Code Reference: https://docs.openexchangerates.org/docs/errors", "source": "../../raw_kb/article/open_exchange_rates_advanced_connector/index.html", "title": "Open Exchange Rates Advanced Connector"}, {"objectID": "7d3e67f6b2bc-0", "text": "TitleOpen Exchange Rates ConnectorArticle BodyIntro", "source": "../../raw_kb/article/open_exchange_rates_connector/index.html", "title": "Open Exchange Rates Connector"}, {"objectID": "7d3e67f6b2bc-1", "text": "Open Exchange Rates provides real-time exchange rates and currency conversion data. Use Domo\u2019s\u00a0Open Exchange Rates\u00a0connector to find the exchange rate for a selected base currency type.\u00a0To learn more about\u00a0Open Exchange Rates\u00a0API, visit their\u00a0website (https://docs.openexchangerates.org/). Domo also includes an advanced version of this connector that lets you retrieve lists of world currencies as well as historical data. For more information, see Open Exchange Rates Advanced Connector.\nPrimary Use CasesThis connector returns exchange rate information.Primary MetricsExchange rates for a selected world currency.Primary Company RolesSalesFinanceAverage Implementation TimeA matter of secondsEase of Use (in a 1-to-10 scale with 1 being easiest)1\nThe Open Exchange Rates connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking Cloud App in the toolbar at the top of the window.\u00a0\nYou connect to\u00a0Open Exchange Rates\u00a0in the\u00a0Data Center. This topic discusses the fields and menus that are specific to the Open Exchange Rates connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nNone.\u00a0\nConnecting to\u00a0Open Exchange Rates\nThis section enumerates the options in the Details\u00a0pane in the Open Exchange Rates Connector page.\u00a0The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nDetails Pane\nThis pane contains a single menu from which you select a world currency.\nMenuDescriptionCurrency to Use as Base ValueSelect the currency you want to see exchange rates for.\nOther Panes", "source": "../../raw_kb/article/open_exchange_rates_connector/index.html", "title": "Open Exchange Rates Connector"}, {"objectID": "7d3e67f6b2bc-2", "text": "Other Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/open_exchange_rates_connector/index.html", "title": "Open Exchange Rates Connector"}, {"objectID": "63fbf2ac94a2-0", "text": "TitleOpen FEC ConnectorArticle BodyIntro\nThe Open FEC Connector allows you to retrieve data about United States Elections. Use Domo's Open FEC connector to retrieve data about calendar events, candidates, committees, and more. Use Domo's\u00a0Open FEC connector to instantly connect, visualize, and get insights from elections data. To learn more about the Open FEC API, visit their page (https://api.open.fec.gov/developers/).\nYou connect to your Open FEC account in the Data Center. This topic discusses the fields and menus that are specific to the Open FEC connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Open FEC account and create a DataSet, you must have your API\u00a0key generated at https://api.data.gov/signup/.\nConnecting to Your Open FEC Account\nThis section enumerates the options in the Credentials and Details panes in the Open FEC Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Open FEC account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter your API\u00a0key. Visit https://api.data.gov/signup/ to generate your API key.\nOnce you have entered valid\u00a0credentials, you can use the same account any time you go to create a new Open FEC DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/open_fec_connector/index.html", "title": "Open FEC Connector"}, {"objectID": "63fbf2ac94a2-1", "text": "MenuDescriptionReportSelect the Open FEC report you want to run.\u00a0The following reports are available:Calendar EventsReturns a list of calendar events with start dates that fall between the selected dates.CandidatesReturns a list of candidates that can be filtered by office and political party.CommitteesReturns information about committees and filers. Date range selection is based on the committee's first filing date.FinancialsReturns top-level financial information about candidates running for the same office.PartyEnter the three-letter code for the party of interest. For example, use 'REP' for Republican, 'DEM' for Democrat or 'LIB' for Libertarian. Use 'all' to return all parties.OfficeSelect to filter the returned results to include candidates by the office sought.Election YearFilter the returned results to include only candidates running for office in a specific year. You must use a 4 digit year format.Committee TypeSelect the committee type.Election YearEnter the Election Cycle year. The cycle begins with an odd year and is named for its ending, even year. To see data for the entire four years of a presidential term or six", "source": "../../raw_kb/article/open_fec_connector/index.html", "title": "Open FEC Connector"}, {"objectID": "63fbf2ac94a2-2", "text": "entire four years of a presidential term or six years of a senatorial term, you will need the 'Aggregate Full Cycle' option set to true. Must use 4 digit year format.Aggregate Full CycleSelect to aggregate data for a full election cycle. By default it's False.Single DateSelect whether the report data is for a specific date or for a relative number of days back from today.Specific DateSelect the specific date using the date selector.Relative DateEnter the number of days back that you would like to get data for in the\u00a0Days Back\u00a0field. Specify either today or 0, yesterday or 1, or today-7 or 7 to get data for 7 days into the past.Date RangeSelect the specific or relative date range.Start Date - SpecificSelect\u00a0the first date in your date range using the date selector.End Date - SpecificSelect the last date in your date range\u00a0using the date selector.Start Date - RelativeEnter the number of days back that you would like to get data from (start day). Combine with\u00a0End Date\u00a0to create a range of represented days.", "source": "../../raw_kb/article/open_fec_connector/index.html", "title": "Open FEC Connector"}, {"objectID": "63fbf2ac94a2-3", "text": "For example, if you entered\u00a010\u00a0for\u00a0Start Date\u00a0and\u00a05\u00a0for\u00a0End Date, the report would contain data for\u00a010 days ago up until\u00a05 days ago.End Date - RelativeEnter the number of days back that you would like to get data to (end day). Combine with\u00a0Start Date\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Start Date\u00a0and\u00a05\u00a0for\u00a0End Date, the report would contain data for\u00a010 days ago up until\u00a05 days ago.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding a DataSet Using a Data Connector.", "source": "../../raw_kb/article/open_fec_connector/index.html", "title": "Open FEC Connector"}, {"objectID": "a801fb322a0e-0", "text": "TitleOpsgenie ConnectorArticle BodyIntro\nOpsgenie is a cloud-based incident management platform. To learn more about the Opsgenie API, visit their page (https://docs.opsgenie.com/docs).\nYou connect to your Opsgenie account in the Data Center. This topic discusses the fields and menus that are specific to the Opsgenie connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Opsgenie account and create a DataSet, you must have your Opsgenie API key. For information about obtaining an API key, see\u00a0https://docs.opsgenie.com/docs/api-key-management.\nConnecting to Your Opsgenie Account\nThis section enumerates the options in the Credentials and Details panes in the Opsgenie Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Opsgenie account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter your Opsgenie API key.DomainSelect your Opsgenie domain. If you are using the\u00a0EU instance of Opsgenie, you must use api.eu.opsgenie.com\nOnce you have entered valid Opsgenie credentials, you can use the same account any time you go to create a new Opsgenie DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a single menu from which you select a report.", "source": "../../raw_kb/article/opsgenie_connector/index.html", "title": "Opsgenie Connector"}, {"objectID": "a801fb322a0e-1", "text": "Details Pane\nThis pane contains a single menu from which you select a report.\nMenuDescriptionReportSelect the Opsgenie report you want to run.\u00a0The following reports are available:AlertsReturns a list of alerts. You must select\u00a0Merge\u00a0as your\u00a0Update Mode\u00a0(in the\u00a0Scheduling\u00a0tab) for this report to run properly.\u00a0IncidentsReturns a list of incidents. You must select\u00a0Merge\u00a0as your\u00a0Update Mode\u00a0(in the\u00a0Scheduling\u00a0tab) for this report to run properly.\u00a0SchedulesReturns a list of schedules.\u00a0You must select Replace\u00a0as your\u00a0Update Mode\u00a0(in the\u00a0Scheduling\u00a0tab) for this report to run properly.TeamsReturns a list of teams.\u00a0You must select Replace\u00a0as your\u00a0Update Mode\u00a0(in the\u00a0Scheduling\u00a0tab) for this report to run properly.UsersReturns a list of users.\u00a0You must select Replace\u00a0as your\u00a0Update Mode\u00a0(in the\u00a0Scheduling\u00a0tab) for this report to run properly.Who Is on CallReturns a list of users on a call.\u00a0You must select Replace\u00a0as your\u00a0Update Mode\u00a0(in the\u00a0Scheduling\u00a0tab) for this report to run properly.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/opsgenie_connector/index.html", "title": "Opsgenie Connector"}, {"objectID": "e94bd54735de-0", "text": "Title\n\nOptimizing a SQL DataFlow\n\nArticle Body", "source": "../../raw_kb/article/optimizing_a_sql_dataflow/index.html", "title": "Optimizing a SQL DataFlow"}, {"objectID": "e94bd54735de-1", "text": "Intro\nYou can optimize your\u00a0DataFlows by creating indices in the DataFlows and limiting your data. Doing so will help eliminate \"Timed Out\" errors by allowing your DataFlows to run more efficiently.\nOptimizing Using Indexes\nIndexes are used to find rows with specific column values quickly. Without an index, MySQL begins with the first row and reads sequentially to find the relevant data. See How MySQL Uses Indexes for more detailed information on the best use cases to optimize using indexes.\nJoining data and using a WHERE statement in MySQL are the most common reasons for using indexes. When\u00a0you are performing a join or using a WHERE clause, you should index the columns on which you are joining or filtering.\nFor example, here is a SELECT statement where we are joining two tables together:\nSelect \na.`column1`, \na.`column2`, \nb.`column3`, \nb.`column4`\u00a0\nFROM input_dataset_1 a\nLEFT JOIN input_dataset_2 b\nON a.`column1` = b.`column3`\nYou should index the two columns in the\u00a0ON\u00a0statement. There are two ways you can accomplish this.\nAdding a new SQL type transform BEFORE the transform where the join is happening.Using Easy\u00a0Indexing\u00a0you can quickly add an index on one or more columns right in your\u00a0Table Transform\u00a0without the use of SQL.\nSee Understanding Transforms for more information on the different transform types.\nCreate an Easy Index\u00a0by,\nAdding a new transform.Select Table as the transform type.Then, select\u00a0the\u00a0Indexing\u00a0tab.\u00a0Choose your\u00a0Index Type.\u00a0Select which column to apply the index.Click\u00a0Done.\nSee Understanding Transforms for more information on the different transform types.\u00a0\nOther Optimizations", "source": "../../raw_kb/article/optimizing_a_sql_dataflow/index.html", "title": "Optimizing a SQL DataFlow"}, {"objectID": "e94bd54735de-2", "text": "See Understanding Transforms for more information on the different transform types.\u00a0\nOther Optimizations\nIndexing\u00a0in MySQL does not always optimize the DataFlow to the full extent needed.\u00a0Here are additional things you\u00a0can do to optimize your DataFlow:", "source": "../../raw_kb/article/optimizing_a_sql_dataflow/index.html", "title": "Optimizing a SQL DataFlow"}, {"objectID": "e94bd54735de-3", "text": "Filter the columns being brought into the DataFlow.\u00a0Some larger DataSets have a large number of columns, not all of which\u00a0are needed.\u00a0You can click on the Dataset in the Input Datasets\u00a0section to limit what columns are being brought into the DataFlow.Filter your data. The most common way to do this is by using a data filter. For example:  SELECT `date`, `value`, `series`    FROM input_dataset_1 WHERE YEAR(`date`) = YEAR(CURRENT_DATE()) \u00a0Take advantage of the GROUP BY function. When filtering data, you sometimes end up with duplicate rows because they were broken out by another column in the original data. If you aggregate value columns then apply a\u00a0GROUP BY\u00a0to the remaining columns, you can condense the number of rows. The most common aggregation is\u00a0SUM.\u00a0Here is an example:  SELECT `Date`, `Series`, SUM(`value`) AS \u2018value\u2019    FROM input_dataset_1    GROUP BY `Date`, `Series` \u00a0If you have a transform with multiple JOINs, you can break them up into multiple transforms. For example:  SELECT", "source": "../../raw_kb/article/optimizing_a_sql_dataflow/index.html", "title": "Optimizing a SQL DataFlow"}, {"objectID": "e94bd54735de-4", "text": "break them up into multiple transforms. For example:  SELECT a.`column`,a.`column4`, b.`column2`,b.`column5`,c.`column6`, c.`column3`    FROM input_dataset_1    LEFT JOIN input_dataset_2 b    ON a.`column4` = b.`column2`    LEFT JOIN input_dataset_3 c    ON b.`column5` = c.`column3`You can also split a transform into two transforms. For example:  Transform 1  SELECT a.`column`,a.`column4`, b.`column2`,b.`column5`    FROM input_dataset_1    LEFT JOIN input_dataset_2 b    ON a.`column4` = b.`column2`  Transform 2  SELECT a.`column`,a.`column4`, a.`column2`,a.`column5`,c.`column6`, c.`column3`    FROM transform_data_1 a    LEFT JOIN input_dataset_3 c    ON a.`column5` = c.`column3`", "source": "../../raw_kb/article/optimizing_a_sql_dataflow/index.html", "title": "Optimizing a SQL DataFlow"}, {"objectID": "e94bd54735de-5", "text": "Make sure that if you are using MySQL, you index the columns from transform_data_1 before doing the join, as well as any additional indexing you didn't create.\u00a0\nIf none of these methods helps optimize your data, please reach out to Domo Support.", "source": "../../raw_kb/article/optimizing_a_sql_dataflow/index.html", "title": "Optimizing a SQL DataFlow"}, {"objectID": "647d98e04120-0", "text": "TitleOptimizing Data PerformanceArticle BodyIntro\nThis article provides general guidelines to optimize data performance in Cards, DataFlows and Beast Modes.\nThese should be used as general guidelines and may not apply to all use cases. Please test any changes prior to implementing them in a production scenario.\nCaching\nTo take advantage of caching in Domo, try to keep your DataSet updates to the minimum required.\nBeast Modes\nComplex Beast Modes are calculated against every row of a DataSet and as such can contribute to poor query performance. Beast Modes calculated against text fields are often the most query intensive. Large or nested CASE statements can also significantly impact your performance.\nRecommendations:\nBuild your Beast Modes on numeric or date fields instead of text/string fields.Consider converting Beast Modes to calculations in a DataFlow. This will avoid the need to compute the formula when querying to display a Card, for example.Avoid large CASE statements calculated on string fields.Avoid using LIKE for text matching on lengthy text fields.\nTargeted DataSets\nFor each DataSet, ask these questions:\nAre all rows necessary for the Cards built from it?How much historical data is truly necessary for your most common use?\nIn general, reducing rows in a DataSet can help improve performance. Consider running larger DataSets through a DataFlow to reduce row counts and provide DataSets for your most common use cases. Alternatively, consider aggregating data when possible.\nDistinct\nCOUNT DISTINCT can be an expensive operation. Instead, try these alternatives:\nConsider approximating the value with APPROXIMATE_COUNT_DISTINCT.Use fewer DISTINCT keywords in your formula.Consider reducing your row counts prior to performing a COUNT DISTINCT.\nSummary Numbers\nCards include Summary Numbers by default. If you don't need a summary number on your Card, consider removing it as it can impact performance.\nDashboard Size", "source": "../../raw_kb/article/optimizing_data_performance/index.html", "title": "Optimizing Data Performance"}, {"objectID": "647d98e04120-1", "text": "Dashboard Size\nEvaluate the number of Cards on each Dashboard to determine if any can be moved to separate Dashboards. Dashboards with many Cards can take longer to load than those with fewer Cards.", "source": "../../raw_kb/article/optimizing_data_performance/index.html", "title": "Optimizing Data Performance"}, {"objectID": "02b89fc4e831-0", "text": "TitleOracle Autonomous Data Warehouse Cloud ConnectorArticle BodyIntro\nOracle Autonomous Data Warehouse Cloud (Oracle ADWC) is a fully-managed, high-performance, and elastic data warehouse service. You can use Domo's Oracle ADWC connector to pull data from your Oracle data warehouse and compile custom reports. To learn more about the Oracle ADWC, visit their website (https://cloud.oracle.com/en_US/datawarehouse).\nYou connect to your Oracle ADWC account in the Data Center. This topic discusses the fields and menus that are specific to the Oracle ADWC connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Oracle ADWC account and create a DataSet, you must have the following:\nThe name of the service you want to connect to.\u00a0Your service names are found in the tnsnames.ora file inside your connection wallet. Each service name is the text on the left of the '=' in each entry in tnsnames.ora.\n\n\n \n\n\nNote: The entries may contain a field named\u00a0service_name.\u00a0This is not the Oracle service that needs to be provided.", "source": "../../raw_kb/article/oracle_autonomous_data_warehouse_cloud_connector/index.html", "title": "Oracle Autonomous Data Warehouse Cloud Connector"}, {"objectID": "02b89fc4e831-1", "text": "For example,\u00a0the Oracle service of the following entry is adw_high.adw_high = (description= (address=(protocol=tcps)(port=1522)(host=adb.us-phoenix-1.oraclecloud.com))(connect_data=(service_name=qfd8c2d8u4sdf_adw_high.adwc.oraclecloud.com)))Your Oracle database username and passwordA Base64-encoded wallet file. You can download this file from the Oracle ADWC\u00a0console. To encode the wallet file, use the command line\u00a0to navigate to the directory of your zipped wallet file. Run the command corresponding to your operating system, replacing wallet.zip\u00a0with the name of your wallet file:Windows: certutil -encode wallet.zip encoded_wallet.txtMac/Linux: base64 -i wallet.zip -o encoded_wallet.txtThis will generate a text file named encoded_wallet.txt. Open this file\u00a0and copy ALL of the text. Paste the text into the\u00a0Base64 Encoded Wallet\u00a0field.\u00a0\nWhitelisting\u00a0\nBefore you can connect to an Oracle database, you must also whitelist a number of IP addresses on your database server on the\u00a0port\u00a0you want to connect to. For the full list of IP addresses, see\u00a0Whitelisting IP Addresses for Connectors.\nConnecting to Your Oracle ADWC Database\nThis section enumerates the options in the Credentials and Details panes in the Oracle ADWC Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Oracle ADWC database. The following table describes what is needed for each field:", "source": "../../raw_kb/article/oracle_autonomous_data_warehouse_cloud_connector/index.html", "title": "Oracle Autonomous Data Warehouse Cloud Connector"}, {"objectID": "02b89fc4e831-2", "text": "FieldDescriptionOracle ServiceEnter the name of the Oracle service you want to connect to. For more information about locating your service, see \"Prerequisites,\" above.Database UsernameEnter your Oracle database username.Database PasswordEnter your Oracle database password.Base64 Encoded WalletEnter the copied text from the encoded_wallet.txt file. For more information about generating this file, see \"Prerequisites,\" above.\nOnce you have entered valid credentials, you can use the same account any time you go to create a new Oracle ADWC DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nIn this pane you input the SQL query you want to use to pull data from your Oracle database. Optionally, you can also indicate the specific table and columns from that table to bring into Domo.\nMenuDescriptionQueryEnter the SQL query to use to retrieve your data. You can use the\u00a0Query Helper\u00a0parameter to help you write a usable SQL query. To use the\u00a0Query Helper, do the following:Select your database table\u00a0and table columns in the appropriate menus.Copy the SQL statement that appears in the\u00a0Query Helper\u00a0field.Paste the copied SQL statement into the\u00a0Query\u00a0field.Database Tables\u00a0Select the database tables you want to pull into Domo, if desired.Table Columns\u00a0Select the table columns you want to pull into Domo.Query Helper\u00a0(Optional) Copy and paste the SQL statement in this field into the\u00a0Query\u00a0field. For more information, see\u00a0Query, above.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nFAQ\nHow do I find and upload the wallet file?\nSee \"Prerequisites\" near the top of this page.\nHow do I find services to connect to?", "source": "../../raw_kb/article/oracle_autonomous_data_warehouse_cloud_connector/index.html", "title": "Oracle Autonomous Data Warehouse Cloud Connector"}, {"objectID": "02b89fc4e831-3", "text": "How do I find services to connect to?\nSee \"Prerequisites\" near the top of this page.", "source": "../../raw_kb/article/oracle_autonomous_data_warehouse_cloud_connector/index.html", "title": "Oracle Autonomous Data Warehouse Cloud Connector"}, {"objectID": "208a729357a8-0", "text": "Title\n\nOracle CRM on Demand Connector\n\nArticle Body", "source": "../../raw_kb/article/oracle_crm_on_demand_connector/index.html", "title": "Oracle CRM on Demand Connector"}, {"objectID": "208a729357a8-1", "text": "Intro\nOracle's CRM On Demand solutions help organizations drive sales, marketing, loyalty, and service effectiveness through a CRM that integrates with other Oracle products and services.\nYou connect to your Oracle CRM On Demand account in the Data Center. This topic discusses the fields and menus that are specific to the Oracle CRM On Demand connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0 a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Oracle CRM On Demand account and create a DataSet, you must have the following:\nThe user host where your Oracle CRM On Demand account is locatedYour Oracle CRM On Demand username and password\nConnecting to Your Oracle CRM On Demand Account\nThis section enumerates the options in the Credentials and Details panes in the Oracle CRM On Demand Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Oracle CRM On Demand account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionHostEnter the host name where the Oracle CRM On Demand account is found.UsernameEnter the username for the Oracle CRM On Demand account.PasswordEnter the username for the Oracle CRM On Demand account.\nOnce you have entered valid Oracle CRM On Demand credentials, you can use the same account any time you go to create a new Oracle CRM On Demand DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains two primary menus from which you select your resource and the attributes (columns) for the resource you want to appear in the DataSet. You can also add an optional query expression to filter resources.", "source": "../../raw_kb/article/oracle_crm_on_demand_connector/index.html", "title": "Oracle CRM on Demand Connector"}, {"objectID": "208a729357a8-2", "text": "MenuDescriptionResourcesSelect the Oracle CRM On Demand resource (record) you want to pull into Domo as a DataSet.\n\u00a0AttributesSelect all the attributes (columns) of the selected resource you want to appear in your DataSet.Advanced OptionsCheck this box to reveal the optional Query Expression field.Query Expression (Optional)Enter a query expression to filter resources in a collection. A query expression is comprised of one or more \"field expressions.\" The maximum supported query expression length is 4096 characters.\nThe following is the query expression syntax:  QUERY EXPRESSION = FIELD EXPRESSION [; FIELD EXPRESSION] \t\t\t[FIELD EXPRESSION] = <Field> <OPERATOR> <VALUE> [ANDOR CLAUSE] \t\t\t[ANDOR CLAUSE] = <AND/OR> <OPERATOR> <VALUE> [ ANDOR CLAUSE] \t\t\tThe following example shows a query expression with two field expressions separated by a semicolon:  AccountName='PSKDemo02' OR = 'A. C. Networks'; Reference = false", "source": "../../raw_kb/article/oracle_crm_on_demand_connector/index.html", "title": "Oracle CRM on Demand Connector"}, {"objectID": "208a729357a8-3", "text": "Tips: \nUse single quotes around values.Use the same date format as exists in the field you are writing the expression for.\n\n\n\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/oracle_crm_on_demand_connector/index.html", "title": "Oracle CRM on Demand Connector"}, {"objectID": "9d68e181d6d7-0", "text": "Title\n\nOracle Database Connector\n\nArticle Body", "source": "../../raw_kb/article/oracle_database_connector/index.html", "title": "Oracle Database Connector"}, {"objectID": "9d68e181d6d7-1", "text": "Intro\nOracle Database is an object-relational database management system produced and marketed by Oracle Corporation. You indicate the data you want by inputting an SQL query.\nYou connect to Oracle Database\u00a0in the Data Center. This topic discusses the fields and menus that are specific to the Oracle Database connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to Oracle Database\u00a0and create a DataSet, you must have the following:\nYour Oracle username and password.The hostname or IP address of your Oracle server.Your Oracle port number.Your Oracle SID.\u00a0\nBefore you can connect to\u00a0Oracle Database, you must also whitelist a number of IP addresses on your database server on the\u00a0port\u00a0you want to connect to. For the full list of IP addresses, see\u00a0Whitelisting IP Addresses for Connectors.\nConnecting to Oracle Database\nThis section enumerates the options in the Credentials and Details panes in the Oracle Database Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Oracle Database account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionUsernameEnter the username for your Oracle account.PasswordEnter the password for your Oracle account.HostEnter the hostname or IP address of your Oracle server.PortEnter your Oracle port number.SIDEnter your Oracle SID.\nOnce you have entered valid Oracle Database credentials, you can use the same account any time you go to create a new Oracle Database DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane", "source": "../../raw_kb/article/oracle_database_connector/index.html", "title": "Oracle Database Connector"}, {"objectID": "9d68e181d6d7-2", "text": "Details Pane\nIn this pane you create an SQL query to pull data from your database. The\u00a0Query\u00a0parameter is required. The other three parameters are here to help you construct this query if you choose.\nMenuDescriptionQueryEnter the Structured Query Language (SQL) query to use in selecting the data you want. For example:\nselect * from Employee\nIf you want help in constructing your query,\u00a0Database Table (Optional)Select the table containing the data you want to pull into Domo. The selected table will be added to the automatically generated query in the\u00a0Query Helper\u00a0field.\u00a0Table Columns (Optional)Select the table columns with data you want to pull into Domo.\u00a0The selected columns\u00a0will be added to the automatically generated query in the\u00a0Query Helper\u00a0field.\u00a0Query Helper (Optional)Copy and paste this query into the\u00a0Query\u00a0field if you need help building a query. This query is automatically generated when you select a table and columns in the\u00a0Database Table\u00a0and Table Columns\u00a0fields, respectively.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/oracle_database_connector/index.html", "title": "Oracle Database Connector"}, {"objectID": "cc54a79aed13-0", "text": "TitleOracle Database Partition ConnectorArticle BodyIntro\nOracle Database is an object-relational database management system produced and marketed by Oracle Corporation. Oracle provides the most complete, open, and integrated business software and hardware systems. With Domo's Oracle database integration, you can easily connect your Oracle data and make faster decisions. Partitioning enables the table data to be divided across multiple storage objects (data partitions), according to the values in one or more table columns based on a set of user-defined rules.\u00a0Use Domo's Oracle Database Partition connector to pull data from your Oracle database and compile custom reports. You indicate the data you want by inputting an SQL query. Once your data is in Domo, you have access to the real-time data, so it's easy to move and pivot.\u00a0\nDomo\u2019s Oracle Database Partition connector assists you to get a comprehensive view of your business and to optimize the way the database engine physically stores data.\u00a0You indicate the data you want by inputting an SQL query.\nYou connect to Oracle Database\u00a0in the Data Center. This topic discusses the fields and menus that are specific to the Oracle Database Partition connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Oracle Database\u00a0and create a DataSet, you must have the following:\nYour Oracle database username and password.The hostname or IP address of your Oracle server.Your Oracle port number.Your Oracle SID.\u00a0\nBefore you can connect to\u00a0Oracle Database, you must also white list a number of IP addresses on your database server on the\u00a0port\u00a0you want to connect to. For the full list of IP addresses, see\u00a0Whitelisting IP Addresses for Connectors.\nConnecting to Your Oracle\u00a0Database", "source": "../../raw_kb/article/oracle_database_partition_connector/index.html", "title": "Oracle Database Partition Connector"}, {"objectID": "cc54a79aed13-1", "text": "Connecting to Your Oracle\u00a0Database\nThis section enumerates the options in the Credentials and Details panes in the Oracle Database Partition Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Oracle Database. The following table describes what is needed for each field: \u00a0\nFieldDescriptionUsernameEnter the username for your Oracle databasePasswordEnter the password for your Oracle databaseHostEnter the hostname or IP address of your Oracle serverPortEnter your Oracle port numberSIDEnter your Oracle SID\nOnce you have entered valid Oracle Database credentials, you can use the same account any time you go to create a new Oracle Database Partition DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nIn this pane you create an SQL query to pull data from your database.\u00a0\nMenuDescriptionQueryEnter the SQL query to use in selecting the data you want.\nExample:\u00a0select Date from Employee\u00a0Table NameSelect the table containing the data you want to pull into Domo.Partition Column NameSelect partition column name.Past DaysEnter the number of past days you want to get data for. Value can be a positive integer. For example: 30.Date FormatSelect the required date format. By default\u00a0yyyy-MM-dd\u00a0will be used.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding a DataSet Using a Data Connector.", "source": "../../raw_kb/article/oracle_database_partition_connector/index.html", "title": "Oracle Database Partition Connector"}, {"objectID": "b4d5629a7bf6-0", "text": "TitleOracle Database Service Name ConnectorArticle BodyIntro\nOracle Database is an object-relational database management system produced and marketed by Oracle Corporation. You can use Domo's Oracle Database Connector to pull data from your Oracle database and compile custom reports. You indicate the data you want by inputting an SQL query.\nYou connect to Oracle Database\u00a0in the Data Center. This topic discusses the fields and menus that are specific to the Oracle Database connector user interface.\u00a0General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to Oracle Database\u00a0and create a DataSet, you must have the following:\nYour Oracle database server username and passwordThe hostname or IP address of your Oracle database serverYour Oracle port numberYour Oracle database service name\nBefore you can connect to\u00a0Oracle Database, you must also whitelist a number of IP addresses on your database server on the\u00a0port\u00a0you want to connect to. For the full list of IP addresses, see\u00a0Whitelisting IP Addresses for Connectors.\nConnecting to Your\u00a0Oracle\u00a0Account\nThis section enumerates the options in the Credentials and Details panes in the Oracle Database Connector page. The components of the other panes in this page, Scheduling and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Oracle Database\u00a0account. The following table describes what is needed for each field:\nFieldDescriptionUsernameEnter the username for your Oracle database.PasswordEnter the password for your Oracle database.HostEnter the hostname or IP address of your Oracle server. Example db.company.comPortEnter your Oracle database port number.Service NameEnter your Oracle database service name.", "source": "../../raw_kb/article/oracle_database_service_name_connector/index.html", "title": "Oracle Database Service Name Connector"}, {"objectID": "b4d5629a7bf6-1", "text": "Once you have entered valid Oracle database credentials, you can use the same account any time you go to create a new Oracle Database DataSet. You can manage Connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary Reports menu, along with various other menus which may or may not appear depending on the report type you select.\nMenuDescriptionQuery TypeSelect a query type.Query TypeDescriptionQueryRegular SQL query without parameter.Query ParameterSQL query with parameter.QueryEnter the SQL query to execute.Query ParameterEnter the query parameter value. It is the initial value for query parameter. The last run date is optional. By default, it is '02/01/1700' if is not provided. Example: \u00a0!{lastvalue:_id}!=1,!{lastrundate:start_date}!=02/01/1944Database TablesSelect the database table.Table ColumnsSelect the table columns.Query HelperThis query is automatically generated when you select a table and columns in the Database Table and Table Columns fields, respectively. Copy and paste this query into the Query field if you need help building a query.\nOther Panes\nFor information about the remaining sections of the Connector interface, including how to configure scheduling, retry, and update options, see Adding a DataSet Using a Data Connector.", "source": "../../raw_kb/article/oracle_database_service_name_connector/index.html", "title": "Oracle Database Service Name Connector"}, {"objectID": "61cb7f8703de-0", "text": "Title\n\nOracle Database SSH Connector\n\nArticle Body\n\nIntro\nOracle Database is an object-relational database management system produced and marketed by Oracle Corporation. You can use Domo's Oracle Database SSH Connector to pull data from your Oracle database via an SSH tunnel and compile custom reports. You indicate the data you want by inputting an SQL query.\nYou connect to Oracle Database\u00a0in the Data Center. This topic discusses the fields and menus that are specific to the Oracle Database SSH connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to Oracle Database with SSH and create a DataSet, you must have the following:\nThe username and password you use to log into your Oracle databaseThe SID of the Oracle databaseThe port number for the Oracle databaseThe Oracle database hostname or IP addressThe SSH hostname or URLThe SSH username and passwordThe SSH port numberThe SSH private key\u00a0\nBefore you can connect to\u00a0Oracle Database, you must also whitelist a number of IP addresses on your database server on the\u00a0port\u00a0you want to connect to. For the full list of IP addresses, see\u00a0Whitelisting IP Addresses for Connectors.\n\n\n\u00a0\n\nNote: Domo does not support the SSH keys generated using ssh-keygen. The SSH keys need to be the DES or RSA keys (in PEM format) generated by OpenSSL.", "source": "../../raw_kb/article/oracle_database_ssh_connector/index.html", "title": "Oracle Database SSH Connector"}, {"objectID": "61cb7f8703de-1", "text": "Connecting to Oracle Database\nThis section enumerates the options in the Credentials and Details panes in the Oracle Database SSH Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your database and SSH server. The following table describes what is needed for each field: \u00a0\nFieldDescriptionSSH Server HostnameEnter the SSH server hostname.\u00a0SSH UsernameEnter the SSH username.SSH PasswordEnter the SSH password.SSH PortEnter the SSH port number.Database HostnameEnter the host name for the Oracle database.\u00a0SSH Private KeyEnter the SSH private key.Database NameEnter the Oracle database name.Database UsernameEnter your Oracle username.Database PasswordEnter your Oracle password.Database PortEnter your Oracle port number.\nOnce you have entered valid Oracle Database credentials, you can use the same account any time you go to create a new Oracle Database SSH DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nIn this pane you create an SQL query to pull data from your database. The\u00a0Query\u00a0parameter is required. The other three parameters are here to help you construct this query if you choose.\nMenuDescriptionQueryEnter the Structured Query Language (SQL) query to use in selecting the data you want. For example:\nselect * from Employee", "source": "../../raw_kb/article/oracle_database_ssh_connector/index.html", "title": "Oracle Database SSH Connector"}, {"objectID": "61cb7f8703de-2", "text": "select * from Employee\nIf you want help in constructing your query,\u00a0Database Table (Optional)Select the table containing the data you want to pull into Domo. The selected table will be added to the automatically generated query in the\u00a0Query Helper\u00a0field.\u00a0Table Columns (Optional)Select the table columns with data you want to pull into Domo.\u00a0The selected columns\u00a0will be added to the automatically generated query in the\u00a0Query Helper\u00a0field.\u00a0Query Helper (Optional)Copy and paste this query into the\u00a0Query\u00a0field if you need help building a query. This query is automatically generated when you select a table and columns in the\u00a0Database Table\u00a0and Table Columns\u00a0fields, respectively.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/oracle_database_ssh_connector/index.html", "title": "Oracle Database SSH Connector"}, {"objectID": "397c1d5d2e71-0", "text": "TitleOracle Database Writeback ConnectorArticle BodyIntro\nTo learn more about Oracle, visit their website at\u00a0https://www.oracle.com/index.html.\nYou export data to an Oracle database\u00a0in the Data Center. This topic discusses the fields and menus that are specific to the Oracle Database Writeback\u00a0connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0 a DataSet Using a Data Connector.\n\n\n\u00a0\n\nNote: The owner of a writeback dataset must also be an owner or co-owner of the input dataset.", "source": "../../raw_kb/article/oracle_database_writeback_connector/index.html", "title": "Oracle Database Writeback Connector"}, {"objectID": "397c1d5d2e71-1", "text": "Prerequisites\nTo configure this connector, you will need the following:\nA Domo Client ID and Client Secret. To obtain these credentials, do the following:Log into your Domo developer account at https://developer.domo.com/login.\u00a0Create a new client.\u00a0Select the desired data and user application scope.Click\u00a0Create.Your Oracle Databaseserver hostname.Your Oracle Databaseserver port number.Your Oracle Databaseserver username and password.\u00a0An Oracle SID. This is a unique identifier for a specific Oracle database. For more information about finding the SID for your database, see\u00a0https://asktom.oracle.com/pls/asktom...D:318216852435.\u00a0\nConfiguring the Connection\nThis section enumerates the options in the Credentials and Details panes in the Oracle Database\u00a0Writeback Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Domo\u00a0developer\u00a0account as well as the table in your Oracle database where you want your data to be copied to. The following table describes what is needed for each field: \u00a0\nFieldDescriptionDomo Client IDEnter your Domo client ID.Domo Client SecretEnter your Domo client secret.HostEnter your Oracle database\u00a0hostname.PortEnter your Oracle database\u00a0port number.UsernameEnter your Oracle database\u00a0username.PasswordEnter your Oracle database\u00a0password.\u00a0SIDEnter your Oracle SID.\nFor more information about obtaining these credentials, see \"Prerequisites,\" above.", "source": "../../raw_kb/article/oracle_database_writeback_connector/index.html", "title": "Oracle Database Writeback Connector"}, {"objectID": "397c1d5d2e71-2", "text": "For more information about obtaining these credentials, see \"Prerequisites,\" above.\u00a0\nOnce you have entered valid credentials, you can use the same account any time you go to set up a new Domo-Oracle connection. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a number of fields for specifying your data and indicating where it's going.", "source": "../../raw_kb/article/oracle_database_writeback_connector/index.html", "title": "Oracle Database Writeback Connector"}, {"objectID": "397c1d5d2e71-3", "text": "This pane contains a number of fields for specifying your data and indicating where it's going.\nMenuDescriptionInput DataSet IDEnter the DataSet\u00a0ID (GUID) for the DataSet you want to copy to S3. You can find the ID by opening the details view for the DataSet in the Data Center and looking at the portion of the URL following datasources/.\u00a0For example, in the URL\u00a0https://mycompany.domo.com/datasources/845305d8-da3d-4107-a9d6-13ef3f86d4a4/details/overview, the DataSet ID is\u00a0845305d8-da3d-4107-a9d6-13ef3f86d4a4.\u00a0Select Table NameSelect how you want to name the table where data will be copied.\u00a0Use Input DataSet\u00a0Name as Table Name. The table name will be the same as that of the input DataSet.Enter Table Name. You will give the table a custom name in the\u00a0Table Name\u00a0field.Table NameEnter the name of the table in your Oracle database where you want your DataSet data to be copied.Update TypeSelect how you like to update the database table.Truncate Table if Input Dataset is empty?Select this checkbox to truncate the table, if the input datset is empty.\u00a0 Note:\u00a0It will remove all the rows from the table, only if the provided dataset is empty.\u00a0Please do not select the checkbox if table does not exist in oracle database. Only select the checkbox when truncating the exisiting database tables.Alter SchemaSelect if you want to alter the database table schema.\u00a0 Note: It may change/alter the table schema completely.\u00a0If selected with Truncate Table if Input Dataset is empty?\u00a0checkbox, then it will only alter schema if input dataset has some schema/columns.\nOther Panes", "source": "../../raw_kb/article/oracle_database_writeback_connector/index.html", "title": "Oracle Database Writeback Connector"}, {"objectID": "397c1d5d2e71-4", "text": "Other Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/oracle_database_writeback_connector/index.html", "title": "Oracle Database Writeback Connector"}, {"objectID": "d8330fe1ffbf-0", "text": "TitleOracle Sales Cloud ConnectorArticle BodyIntro\nOracle Sales Cloud is a customer relationship management solution that offers capabilities and features enabling companies to significantly grow through accelerated sales, improved customer engagement, and more. It enables modern selling with tools that are easy to deploy and use, completely mobile, packed with powerful analytics, and built for collaborative selling and revenue generation.Use this connector to get data about your opportunities like- your\u00a0team's opportunities, territories\u00a0opportunities, subordinate opportunities, and so on.\u00a0\nYou connect to your Oracle Sales Cloud account in the Data Center. This topic discusses the fields and menus that are specific to the Oracle Sales Cloud connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Oracle Sales Cloud account and create a DataSet, you must have the following:\nYour Oracle Sales Cloud username and passwordYour Oracle Sales Cloud REST Server URL. It's the URL of your Oracle Cloud service. Example:\u00a0https://servername.fa.us2.oraclecloud.com\nConnecting to Your\u00a0Oracle Sales Cloud\u00a0Account\nThis section enumerates the options in the Credentials and Details panes in the Oracle Sales Cloud Connector page. The components of the other panes in this page, Scheduling and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Oracle Sales Cloud account. The following table describes what is needed for each field:\nFieldDescriptionUsernameEnter your Oracle Sales Cloud username.PasswordEnter your Oracle Sales Cloud password.API URLEnter your Oracle Sales Cloud REST Server URL. It's the URL of your Oracle Cloud service. Example:\u00a0https://servername.fa.us2.oraclecloud.com", "source": "../../raw_kb/article/oracle_sales_cloud_connector/index.html", "title": "Oracle Sales Cloud Connector"}, {"objectID": "d8330fe1ffbf-1", "text": "Once you have entered valid Oracle Sales Cloud credentials, you can use the same account any time you go to create a new Oracle Sales Cloud DataSet. You can manage Connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary Reports menu, along with various other menus which may or may not appear depending on the report type you select.\nMenuDescriptionReportSelect the Oracle Sales Cloud report you want to run. The following reports are available:OpportunitiesReturns all the opportunities like sales, revenue for all the products.Record SetSelect the record set you want to retrieve the opportunities data for.Status CodeEnter the status code.Date SelectionSelect the date format for your data.Single DateSelect whether the report data is for a specific date or for a relative number of days back from today.Specific DateSelect the specific date using the date selector.Relative DateEnter the number of days back that you would like to get data for in the\u00a0Days Back\u00a0field. Specify either today or 0, yesterday or 1, or today-7 or 7 to get data for 7 days into the past.Date RangeSelect the specific or relative date range.Start Date - SpecificSelect\u00a0the first date in your date range using the date selector.End Date - SpecificSelect the last date in your date range\u00a0using the date selector.Start Date - RelativeEnter the number of days back that you would like to get data from (start day). Combine with\u00a0End Date\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Start Date\u00a0and\u00a05\u00a0for\u00a0End Date, the report would contain data for\u00a010 days ago up until\u00a05 days ago.End Date - RelativeEnter the number of days back that you would like to get data to (end day). Combine with\u00a0Start Date\u00a0to create a range of represented days.", "source": "../../raw_kb/article/oracle_sales_cloud_connector/index.html", "title": "Oracle Sales Cloud Connector"}, {"objectID": "d8330fe1ffbf-2", "text": "For example, if you entered\u00a010\u00a0for\u00a0Start Date\u00a0and\u00a05\u00a0for\u00a0End Date, the report would contain data for\u00a010 days ago up until\u00a05 days ago.\nOther Panes\nFor information about the remaining sections of the Connector interface, including how to configure scheduling, retry, and update options, see Adding a DataSet Using a Data Connector.\nFAQs\nWhich endpoint(s) does each report call in this Connector?\nReport NameEndpoint URL(s)Opportunities/crmRestApi/resources/11.13.18.05/opportunities\nWhat kind of credentials do I need to power up this Connector?", "source": "../../raw_kb/article/oracle_sales_cloud_connector/index.html", "title": "Oracle Sales Cloud Connector"}, {"objectID": "d8330fe1ffbf-3", "text": "You need the username and password associated with your Oracle Sales Cloud account, and the URL of your Oracle Cloud service (Example: https://{servername}.fa.us2.oraclecloud.com.)\n\n\n\nCan I use the same Oracle Sales Cloud account to create multiple datasets?\nYes\n\n\n\nAre there any API limits that I need to be aware of?\nNo\n\n\n\nHow often can the data be updated?\nAs often as needed.\n\nTroubleshooting\nMake sure your authentication remains valid.Review the configuration to make sure that all required items have been selected.Review the Connector history for error messages.In rare cases, you may be requesting too much information and reaching API limitations or timeouts. If this is the case, you can review the history of the Connector run to see the error message and duration. If this is the case, you can reduce the number of accounts that are being pulled, choose a smaller number of metrics for the report that you are pulling, or reduce the timeframe that you are trying to pull.", "source": "../../raw_kb/article/oracle_sales_cloud_connector/index.html", "title": "Oracle Sales Cloud Connector"}, {"objectID": "7e0c3e77135f-0", "text": "TitleOrthoFi ConnectorArticle BodyIntro\nWith the perspective of improvising their patients\u2019 lives and dental health, OrthoFi combines technology with the medical expertise to revolutionize the way patients and their families pay for treatments, making it affordable for everyone. OrthoFi is dedicated to ensuring that the oral and overall health benefits is available to everyone in the hopes of better health outcomes.\nThe Domo OrthoFi Connector provides data on a wide range of factors such as, business health, medical charges, patients details, practice staff details, practice location data, patient\u2019s insurance details, and more. It helps you to gather the health information datasets for various categories.\u00a0Once you have set up this connector, you can easily combine the latest business and health data with information from across your organization.\nThe OrthoFi Connector is a \"Cloud App\" Connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the Connector page for this and other Cloud App Connectors by clicking Cloud App in the toolbar at the top of the window.\nYou connect to your OrthoFi account in the Data Center. This topic discusses the fields and menus that are specific to theOrthoFi Connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your OrthoFi account and create a DataSet, you must have the client ID and client secret associated with your OrthoFi account.\nConnecting to YourOrthoFi Account\nThis section enumerates the options in the Credentials and Details panes in the OrthoFi Connector page. The components of the other panes in this page, Scheduling and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in Adding a DataSet Using a Data Connector.\nCredentials Pane", "source": "../../raw_kb/article/orthofi_connector/index.html", "title": "OrthoFi Connector"}, {"objectID": "7e0c3e77135f-1", "text": "Credentials Pane\nThis pane contains fields for entering credentials to connect to your OrthoFi account. The following table describes what is needed for each field:\nFieldDescriptionClient IDEnter the client ID associated with your OrthoFi account.Client SecretEnter the client secret associated with your OrthoFi account.\nOnce you have entered valid OrthoFi credentials, you can use the same account any time you go to create a new OrthoFi DataSet. You can manage Connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary Reports menu, along with various other menus which may or may not appear depending on the report type you select.\nMenuDescriptionReportSelect the OrthoFi report you want to run. The following reports are available:Business HealthRetrieves business health details.Business Health MetricsRetrieves Median OrthoFi metrics of all practice locations as well as mean metrics of the top 20 (production dollar) practice locations.ChargesRetrieves the charges details.Collection DetailsRetrieves collections details.Configuration DataRetrieves practice location configuration data.ContractsRetrieves contracts details.Insurance Accounts ReceivableRetrieves insurance accounts receivable details.Insurance SubmissionsRetrieves insurance submissions details.PatientsRetrieves the patient details.Practice LocationsRetrieves practice locations details.Practice StaffRetrieves practice staff records.Reference DataRetrieves reference data.ReferralsRetrieves the referral details.Practice Location IDsSelect the practice location IDs.As of DateSelect the exact date that you want to fetch the Insurance Accounts Receivable report for.\nOther Panes\nFor information about the remaining sections of the Connector interface, including how to configure scheduling, retry, and update options, see Adding a DataSet Using a Data Connector.", "source": "../../raw_kb/article/orthofi_connector/index.html", "title": "OrthoFi Connector"}, {"objectID": "1ca905c7b77c-0", "text": "TitleOutbrain ConnectorArticle Body\nIntro\nOutbrain is an advertising platform whose content marketing module offers to help Internet publishers increase web traffic by presenting them with links to related and interesting articles and other trusted content.\u00a0The Domo Outbrain connector integrates Domo with Outbrain to extract data from the Outbrain Amplify API. Use Domo's\u00a0Outbrain connector to retrieve data on marketers, budgets, campaigns, promoted links, and performance reporting.\u00a0For more information about the\u00a0Outbrain Amplify API, visit\u00a0their website.\u00a0(http://docs.amplifyv01.apiary.io/#)\nThe Outbrain connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking Cloud App in the toolbar at the top of the window. \u00a0\u00a0\nYou connect to your\u00a0Outbrain account in the\u00a0Data Center. This topic discusses the fields and menus that are specific to the\u00a0Outbrain\u00a0connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrimary Use CasesWeb marketingCampaign performancePrimary MetricsCampaign clicksPromoted links\nPrerequisites\nTo connect to your\u00a0Outbrain account and create a DataSet, you must have an Outbrain username and password. You must also be a registered beta user of Outbrain's Amplify API. For more information, see\u00a0http://developer.outbrain.com/home-page/amplify-api/apply/.\nConnecting to Your\u00a0Outbrain Account", "source": "../../raw_kb/article/outbrain_connector/index.html", "title": "Outbrain Connector"}, {"objectID": "1ca905c7b77c-1", "text": "Connecting to Your\u00a0Outbrain Account\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the\u00a0Outbrain\u00a0Connector page.\u00a0The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your\u00a0Outbrain\u00a0account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionUsernameEnter your Outbrain username.\u00a0Password\u00a0Enter your Outbrain password.\u00a0\nOnce you have entered valid\u00a0Outbrain credentials, you can use the same account any time you go to create a new\u00a0Outbrain DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see\u00a0Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Report\u00a0menu in which you select a report type. Depending on the report type you select, you may also have the option to specify the date range for the report.", "source": "../../raw_kb/article/outbrain_connector/index.html", "title": "Outbrain Connector"}, {"objectID": "1ca905c7b77c-2", "text": "MenuDescriptionReportSelect an Outbrain report. The following reports are available:Budget Collection via MarketerReturns a collection of all budgets for a given marketer.\u00a0Campaigns Collection via BudgetReturns a collection of all campaigns for a given budget.Campaign Collections via MarketerReturns a collection of all campaigns for a given marketer.Marketers\u00a0Returns information about all marketers associated with the authenticated user.\u00a0Performance for a Campaign per DayReturns performance statistics for a given campaign per day.Performance for a Campaign per Month\u00a0Returns performance statistics for a given campaign per\u00a0month.\u00a0Performance for a Campaign per PromotedLink\u00a0Returns performance statistics for a given campaign per PromotedLink.\u00a0Performance for a Marketer per Campaign\u00a0Returns performance statistics for a given marketer per campaign.\u00a0Performance for a Marketer per Day\u00a0Returns performance statistics for a given marketer per day.\u00a0Performance for a Marketer per Month\u00a0Returns performance statistics for a given marketer per month.\u00a0Performance for a Marketer per PromotedLink\u00a0Returns\u00a0performance statistics for a given marketer per PromotedLink.\u00a0Performance for a PromotedLink per Day\u00a0Returns performance statistics for a given PromotedLink per", "source": "../../raw_kb/article/outbrain_connector/index.html", "title": "Outbrain Connector"}, {"objectID": "1ca905c7b77c-3", "text": "Day\u00a0Returns performance statistics for a given PromotedLink per day.\u00a0Performance for a PromotedLink per Month\u00a0Returns performance statistics for a given PromotedLink per month.\u00a0PromotedLinks Collection via Campaign\u00a0Returns a collection of all PromotedLinks for a given campaign.\u00a0\u00a0Start\u00a0 DaysEnter the number of the farthest day back that should be represented in the report. Combine with End Days to create a range of represented days. For example, if you entered 10 for Start Days and 5 for End Days, the report would contain data for\u00a010 days ago up until\u00a05 days ago.\u00a0Enter 0 to get today's data.\u00a0\u00a0End DaysEnter the number of the\u00a0most recent day\u00a0that should be represented in the report. Combine with\u00a0Start Days to create a range of represented days. For example, if you entered 10 for Start Days and 5 for End Days, the report would contain data for\u00a010 days ago up until\u00a05 days ago.\u00a0Enter 0 to get today's data.", "source": "../../raw_kb/article/outbrain_connector/index.html", "title": "Outbrain Connector"}, {"objectID": "1ca905c7b77c-4", "text": "Other Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nTroubleshooting\nEnsure you are a member of Outbrain's Amplify API beta program (see Prerequisites for more information).", "source": "../../raw_kb/article/outbrain_connector/index.html", "title": "Outbrain Connector"}, {"objectID": "152212accf80-0", "text": "Title\n\nOutliers Chart\n\nArticle Body\n\nIntro\nAn outliers chart is nearly identical to a basic line chart but allows you to call out any points you deem to be outliers. Be aware that the line in an outliers chart is built from X and Y coordinate pairs, not from date-time values as in a typical line chart. However, you can use numbers to represent time periods. For example, in the graphic further down in this topic, the numbers in the \"X-axis\" column represent months in a time scale.\nThis chart type does not currently include algorithms to identify outlier points. You must identify these points yourself in the DataSet you use to power the chart. However, you can use tools such as R and Python to help you identify these outliers.\nPowering outliers charts\nOutliers charts require three columns or rows of data from your DataSet. Two of these contain the X and Y coordinate values for each point, as in a scatter plot chart. The third column contains a value of TRUE or FALSE for each coordinate pair. If the point is considered an outlier, the value should be TRUE; if it is not an outlier, the value should be FALSE. For an example, see the graphic below.\u00a0\nFor information about value, category, and series data, see Understanding Chart Data.\nIn the Analyzer,\u00a0you choose the columns containing the data for your outliers chart. For more information about choosing data columns, see\u00a0Applying DataSet Columns to Your Chart.\nFor more information about formatting charts in the Analyzer, see KPI Card Building Part 2: The Analyzer.\nThe following graphic shows you how the data from a typical column-based spreadsheet is converted into an outliers chart. (For clarification purposes, the values in the \"X-Axis\" column represent months.)\n\nCustomizing outliers charts\nYou can customize the appearance of an outliers chart by editing its Chart Properties. For information about all chart properties, see Chart Properties.", "source": "../../raw_kb/article/outliers_chart/index.html", "title": "Outliers Chart"}, {"objectID": "f4779bed3f90-0", "text": "Title\n\nOutreach Connector\n\nArticle Body\n\nIntro\nOutreach is a sales communication platform that makes your team's communication workflows faster and reveals the performance insights that make them more effective at selling. To learn more about the Outreach API, visit their page (https://www.outreach.io/product/platform#api).\nYou connect to your Outreach account in the Data Center. This topic discusses the fields and menus that are specific to the Outreach connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Outreach account and create a DataSet, you must have the username and password associated with your Outreach account.\nConnecting to Your Outreach Account\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the Outreach Connector page.\u00a0The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThe Domo\u00a0Outreach\u00a0connector uses OAuth to connect, so there is no need to enter credentials within Domo. Click\u00a0Connect\u00a0(or select\u00a0Add Account\u00a0if\u00a0you have\u00a0existing Outreach accounts in Domo) to open the Outreach OAuth screen where you can enter your Outreach\u00a0username and password. Once you have entered valid Outreach\u00a0credentials, you can use the same account any time you go to create a new Outreach DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see\u00a0Managing User Accounts for Connectors.", "source": "../../raw_kb/article/outreach_connector/index.html", "title": "Outreach Connector"}, {"objectID": "f4779bed3f90-1", "text": "Note:\u00a0If you are already logged into Outreach when you connect in Domo, you are authenticated automatically when you click Add account. If you want to connect to an account that is different from the one you are logged into, you must first log out of Outreach.\n\n\n\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.\nMenuDescriptionReportSelect the Outreach report you want to run.\u00a0The following reports are available:AccountsRetrieves details about accounts used to categorize prospects.AuditsRetrieves details about audit events that happen during the day. Things like login, plugin mapping changes, etc.Call DispositionsDetails about call dispositions used to categorize calls.Call PurposesDetails about call purposes used to categorize calls.CallsRetrieves details about inbound and outbound calls.Content Category MembershipRetrieves details about content category membership. Use this report to map content to a content category.Content Category OwnershipRetrieves details about content category ownership. use this report to map content to content owners.Content CategoryRetrieves details about content categories.Custom DutiesRetrieves details about custom duties, which are freeform user-specified roles or job duties played by a user in their organization.DutyRetrieves details about dutiesEmail Address\nRetrieves details about prospect's email addresses.\n\nEvent\nRetrieves details about application events.\n\nFavorite\nRetrieves details about favorites.\n\nMail Alias\nRetrieves details about mail aliases.\n\nMailboxRetrieves details about mailboxes.Mailings\nRetrieves details about emails.\n\nMessenger Conversation\nRetrieves details about messenger conversations.\n\nMessenger Message\nRetrieves details about messenger messages.", "source": "../../raw_kb/article/outreach_connector/index.html", "title": "Outreach Connector"}, {"objectID": "f4779bed3f90-2", "text": "Messenger Message\nRetrieves details about messenger messages.\n\nOpportunitiesRetrieves details about opportunities.Opportunity Prospect RoleRetrieves details about opportunity prospect roles.Opportunity StageRetrieves details about opportunity stages.PersonasRetrieves details about personas used to categorize prospects.Phone NumberRetrieves details about prospect's phone numbers.ProfileRetrieves details about profiles.ProspectsRetrieves details about prospects associated with a logged in user.Recipient\nRetrieves details about recipients.\n\nRole\nRetrieves details about roles, which are where an individual falls within the organizational structure.\n\nRulesets\nRetrieves details about rulesets applied to sequences.\n\nSequence States\nRetrieves details about sequence states for a prospect\n\nsequence Steps\nRetrieves details about steps in sequences\n\nSequence Template\nRetrieves details about sequence templates.\n\nSequencesRetrieves details about sequences.SnippetRetrieves details about snippets, a piece of email to be reused in multiple messages.StagesRetrieves details about stages used to categorize prospects.Task Priority\nRetrieves details about priorities used to categorize tasks.\n\nTasks\nRetrieves details about tasks.\n\nTeam\nRetrieves details about teams.\n\nTemplate\nRetrieves details about email templates.\n\nUsers\n\n\n\n\n\n\nRetrieves details about users.", "source": "../../raw_kb/article/outreach_connector/index.html", "title": "Outreach Connector"}, {"objectID": "f4779bed3f90-3", "text": "OutcomeSelect whether you want to retrieve all outcomes, only answered outcomes or only non-answered outcomes.Mailing TypeSelect whether to retrieve data for all mailing types or only a specific type (campaign, sequence, or single).ActionSelect whether to retrieve data for all task action types or only a specific type (action items, calls, emails, or in-person).StateSelect the task state you want to retrieve data for.TypeSelect whether to retrieve data for all task types or only a specific type (follow-up, manual, no-reply, open sequence, call sequence, email sequence, task sequence, or touch).Include Email Body?Select\u00a0True\u00a0to include the email body in your report data.Date FilterSelect whether to filter dates based on the creation date or the date when updates were last made.Duration\u00a0Select whether you want to pull data for a single date (e.g. January 23) or a date range (e.g. January 23-31).\u00a0\u00a0Report Date\u00a0Select whether the report data is for a specific date or for a relative number of days back from today. If you choose\u00a0Specific, the report will always pull data for the", "source": "../../raw_kb/article/outreach_connector/index.html", "title": "Outreach Connector"}, {"objectID": "f4779bed3f90-4", "text": "choose\u00a0Specific, the report will always pull data for the selected date whenever it runs. If you choose Relative, the report will pull data for the entered number of back days whenever it runs. For example, if you selected\u00a0Relative\u00a0and entered 7 for the number of days back, each time the report ran it would pull data for the last 7 days.\u00a0Specific Date\u00a0Select the specific date you want to pull data for.\u00a0Days BackEnter the number of past days that should appear in the report. The report will pull data for this\u00a0number of past\u00a0days whenever it runs. For example, if you entered 7\u00a0here, each time the report ran it would pull data for the last 7 days.\u00a0Start DateSpecify whether the\u00a0first date in your date range is a specific or relative date.\u00a0You select the last date in your range in\u00a0End Date.\u00a0End DateSpecify whether the second date in your date range is a specific or relative date. You select the first date in your range in\u00a0Start Date.\u00a0\u00a0Specific Start DateSelect\u00a0the first date in your date", "source": "../../raw_kb/article/outreach_connector/index.html", "title": "Outreach Connector"}, {"objectID": "f4779bed3f90-5", "text": "Start DateSelect\u00a0the first date in your date range.\u00a0Specific End DateSelect the second date in your date range.\u00a0Days Back to Start FromEnter the number of the farthest day back that should be represented in the report. Combine with\u00a0Days Back to End At\u00a0to create a range of represented days.", "source": "../../raw_kb/article/outreach_connector/index.html", "title": "Outreach Connector"}, {"objectID": "f4779bed3f90-6", "text": "For example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Days Back to End AtEnter the number of the most recent day back that should be represented in the report. Combine with\u00a0Days Back to Start From\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nFAQ\n\u00a0\nWhat version of the Outreach API does this connector use?\nThis connector uses version 2 of the Outreach API (https://api.outreach.io/api/v2).\nWhich endpoint(s) does each report call in this connector?", "source": "../../raw_kb/article/outreach_connector/index.html", "title": "Outreach Connector"}, {"objectID": "f4779bed3f90-7", "text": "Which endpoint(s) does each report call in this connector?\nReport NameEndpoint URL(s)Accounts/accountsAudits/auditsCall Dispositions/callDispositionsCall Purposes/callPurposesCalls/callsContent Category Membership/contentCategoryMembershipsContent Category Ownership/contentCategoryOwnershipsContent Category/contentCategoriesCustom Duties/customDutiesDuty/dutiesEmail Address/emailAddressesEvent/eventsFavorite/favoritesMail Alias/mailAliasesMailbox/mailboxesMailings/mailingsMessenger Conversation/messengerConversationsMessenger Message/messengerMessagesOpportunities/opportunitiesOpportunity Prospect Role/opportunityProspectRolesOpportunity Stage/opportunityStagesPersonas/personasPhone Number/phoneNumbersProfile/profilesProspects/prospectsRecipient/recipientsRole/rolesRulesets/rulesetsSequence States/sequenceStatesSequence Steps/sequenceStepsSequence Template/sequenceTemplatesSequences/sequencesSnippet/snippetsStages/stagesTask Priority/taskPrioritiesTasks/tasksTeam/teamsTemplate/templatesUsers/users\nWhat kind of credentials do I need to power up this connector?\nYou need the email address and password of your Outreach account.\nWhy am I getting an error after entering the correct credentials in the OAuth login window?\nOutreach has previously had a known issue with their OAuth popup window. This requires you to login into Outreach in a separate tab, then create a Domo Outreach account. For the step-by-step instructions for obtaining a client id, see Outreach  OAuth Documentation.\nRedirect URL: https://oauth.domo.com/api/data/v1/oauth/providers/outreach.\nHow do I know my Outreach account credentials are secure?\nDomo's Outreach connector uses OAuth, which authenticates the account without Domo ever having access to your Outreach account credentials.\nHow often can the data be updated?\nAs often as needed.\nAre there any API limits that I need to be aware of?", "source": "../../raw_kb/article/outreach_connector/index.html", "title": "Outreach Connector"}, {"objectID": "f4779bed3f90-8", "text": "As often as needed.\nAre there any API limits that I need to be aware of?\nThe Outreach API is rate limited on a per-user basis, with a fixed limit of 5,000 requests per one hour period.\nWhen I click 'Add Account', why am I getting automatically validated without needing to enter credentials?\nIf you are already logged into Outreach when you connect to Domo, you are authenticated automatically as you click Add Account. If you want to connect to an account that is different from the one you are logged into, you must first log out of Outreach.", "source": "../../raw_kb/article/outreach_connector/index.html", "title": "Outreach Connector"}, {"objectID": "f14680b89a06-0", "text": "TitleOutreach Writeback ConnectorArticle BodyIntro\nOutreach is a sales communication platform that makes your team's communication workflows faster and reveals the performance insights that make them more effective at selling. Use Domo's Outreach Writeback connector to create and update prospects, accounts and opportunities in Outreach.\u00a0To learn more about the Outreach API, visit their page (https://www.outreach.io/platform/).\nYou connect to your Outreach Writeback account in the Data Center. This topic discusses the fields and menus that are specific to the Outreach Writeback connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\n\n\n\n\n\nNote: The owner of a writeback dataset must also be an owner or co-owner of the input dataset.\n\n\n\n\nPrerequisites\nTo connect to your Outreach account and create a DataSet, you must have the following:\nYour Domo Client ID and Client Secret.Your Outreach Client ID and Client Secret, created when registering an OAuth app with Outreach.\u00a0Use the following redirect URI while registering the app -https://oauth.domo.com/api/data/v1/oauth/providers/outreachwriteback/exchangeYour Outreach username and password.\nTo obtain the Domo Client ID and Client Secret, do the following:\nLog into your Domo developer account.\u00a0In the top right corner, click My Accounts >> New Client.Enter the name and description for your application.Provide the application scope by selecting the checkboxes for Data and User.", "source": "../../raw_kb/article/outreach_writeback_connector/index.html", "title": "Outreach Writeback Connector"}, {"objectID": "f14680b89a06-1", "text": "5. Click Create.\nOnce you have created a client, you can manage the client by clicking on Manage Client. Your Client Secret will appear in the Manage Client section.\nConfiguring the connection\nThis section enumerates the options in the Credentials and Details panes in the Outreach\u00a0Writeback Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials for your Domo developer account as well as your Outreach account. The following table describes what is needed for each field:\nFieldDescriptionDomo Client IDEnter your Domo Client ID. For more information, see Prerequisites.Domo Client SecretEnter your Domo Client secret.\u00a0For more information, see Prerequisites.Outreach Client IDEnter your Outreach Client ID. You will need to register an app within Outreach.\u00a0Outreach Client SecretEnter your Outreach Client Secret. You will need to register an app within Outreach.\u00a0\nOnce you have entered valid\u00a0credentials, you can use the same account any time you go to create a new Outreach Writeback DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/outreach_writeback_connector/index.html", "title": "Outreach Writeback Connector"}, {"objectID": "f14680b89a06-2", "text": "MenuDescriptionReportSelect the Outreach Writeback report you want to run.\u00a0The following reports are available:AccountThis report is used to update the details about accounts that are associated with logged in user.ProspectsThis report is used to create a new prospect resource or to update an existing prospect that is associated with logged in user.OpportunityThis report is used to create a new opportunity resource or to update an existing opportunity for a sale or pending deal.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/outreach_writeback_connector/index.html", "title": "Outreach Writeback Connector"}, {"objectID": "a2656d85d834-0", "text": "Title\n\nOverlay Bar Chart\n\nArticle Body\n\nIntro\nAn Overlay Bar chart is similar to a standard Stacked Bar chart\u00a0except that instead of being stacked, all series items begin from the baseline, so overlapping of series items occurs in a category when multiple series are present. In its initial non-rollover state, an Overlay chart is rather meaningless, as shown in the following example: \u00a0\n\nHowever, by mousing over a series item in the legend, you can see just that series in the chart, as shown in the following example:  \nIn many applications this may be more useful than a Stacked Bar because you can more quickly compare series items in different categories. (In a Stacked Bar this is difficult because series in different categories do not usually begin from the same baseline.)\nOverlay Bar charts include both vertical and horizontal sub-types.\nPowering Overlay Bar charts\nAn Overlay Bar chart requires three data columns or rows from your DataSet\u2014one for categories, one for the series in each category, and one for values. For information about value, category, and series data, see Understanding Chart Data.\nIn the Analyzer,\u00a0you choose the columns containing the data for your Overlay Bar chart. For more information about choosing data columns, see\u00a0Applying DataSet Columns to Your Chart.\nFor more information about formatting charts in the Analyzer, see\u00a0KPI Card Building Part 2: The Analyzer.\nThe following graphic shows you how the data from a typical column-based spreadsheet is converted into a vertical Overlay Bar chart:\n\nThe following graphic shows you how the data from a typical column-based spreadsheet is converted into a horizontal Overlay Bar chart:\n\nCustomizing Overlay Bar charts\nYou can customize the appearance of an Overlay Bar chart in a number of ways. Many customizations are possible by setting Chart Properties. For information about all chart properties, see Chart Properties.", "source": "../../raw_kb/article/overlay_bar_chart/index.html", "title": "Overlay Bar Chart"}, {"objectID": "7e9bff27c6a6-0", "text": "Title\n\nOwler Connector\n\nArticle Body\n\nImportant:\u00a0The Owler\u00a0Fortune 500 public DataSet will no longer be available for use after September 2, 2019. Customers using this data will need to create their own DataSets using the Owler Connector and their personal Owler account.", "source": "../../raw_kb/article/owler_connector/index.html", "title": "Owler Connector"}, {"objectID": "7e9bff27c6a6-1", "text": "Intro\nOwler\u00a0crowdsources\u00a0business insights\u00a0by providing news alerts, company profiles, and polls and allows members to follow, track, and research companies in real time. Use Domo's\u00a0Owler\u00a0connector to retrieve company and competitor data as well as feeds for selected companies. To learn more about the Owler\u00a0API, visit their page (https://developers.owler.com/).  \nYou connect to your Owler account in the Data Center. This topic discusses the fields and menus that are specific to the Owler connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Owler account and create a DataSet, you must have an Owler API key. For information about obtaining an API key, reach out to your Owler\u00a0representative.\nConnecting to Your Owler Account\nThis section enumerates the options in the Credentials and Details panes in the Owler Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Owler account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter your Owler API key.\nOnce you have entered valid Owler credentials, you can use the same account any time you go to create a new Owler DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/owler_connector/index.html", "title": "Owler Connector"}, {"objectID": "7e9bff27c6a6-2", "text": "MenuDescriptionReportSelect the Owler report you want to run.\u00a0The following reports are available:Company SearchReturns the top 30 companies most likely to match your search criteria.Company DetailReturns detailed information for the selected companies.CompetitorsReturns competitor information for the selected companies.FeedsReturns the top 10 feeds for the selected companies.Search FilterSelect the type of filter you want to apply to your report. You then enter the actual search term in the\u00a0Search\u00a0field. For example, if you wanted to filter on the company name \"Kablinko,\" you would select\u00a0Name\u00a0as your search filter type then enter Kablinko in the\u00a0Search\u00a0field.SearchEnter the term you want to retrieve information for in your report. Make sure you select the matching filter type in the\u00a0Search Filter\u00a0menu.\u00a0For example, if you wanted to filter on the company name \"Kablinko,\" you would select\u00a0Name\u00a0in the\u00a0Search Filter\u00a0menu\u00a0then enter Kablinko in the\u00a0Search\u00a0field.Input TypeSelect how you would like to input company data to search for. If you select\u00a0Manual Entry, you are\u00a0prompted to enter the IDs for all companies you want to retrieve information for. If you select\u00a0Search, you are prompted to enter a search term to filter by. If you select\u00a0Fortune 500, data is returned for Fortune 500 companies.\u00a0\u00a0Company IDsEnter a comma-separated list of IDs for companies you want to retrieve information for.Sub ReportSelect a sub report, either\u00a0Industries,\u00a0Funding, or\u00a0Acquisition. If you do not want a sub report, select\u00a0None.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/owler_connector/index.html", "title": "Owler Connector"}, {"objectID": "6bab2b202395-0", "text": "TitlePagerDuty Advanced ConnectorArticle Body\nIntro\nPagerDuty is an operations performance platform designed to make businesses more reliable by eliminating the chaos across the entire operations lifecycle.\u00a0Use Domo's\u00a0PagerDuty connector to\u00a0get reports about schedule management, alerting, and incident tracking. To learn more about\u00a0the\u00a0PagerDuty API, visit their\u00a0website (https://developer.pagerduty.com/documentation/rest).\n\n\nBen Green\nSep 29, 2016, 12:59 PM\n\n\nThe PagerDuty connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking Cloud App in the toolbar at the top of the window.", "source": "../../raw_kb/article/pagerduty_advanced_connector/index.html", "title": "PagerDuty Advanced Connector"}, {"objectID": "6bab2b202395-1", "text": "This is the advanced version of the PagerDuty connector, which allows you to set up a date range for your report data. There is also a simplified version, which instead gives you the simpler option of pulling data for a previous month. For more information about this version, see\u00a0PagerDuty Connector.\nYou connect to your\u00a0PagerDuty account in the\u00a0Data Center. This topic discusses the fields and menus that are specific to the\u00a0PagerDuty\u00a0Advanced connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your\u00a0PagerDuty account and create a PagerDuty Advanced DataSet, you must have the following:\nThe API key for your\u00a0PagerDuty account. For information about generating a PagerDuty API key, see\u00a0https://support.pagerduty.com/hc/en-us/articles/202829310-Generating-an-API-Key.The domain for your PagerDuty URL. For example, if your PagerDuty URL was\u00a0domo.pagerduty.com, you would enter\u00a0domo\u00a0as the domain.\nConnecting to Your\u00a0PagerDuty Account\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the\u00a0PagerDuty\u00a0Advanced Connector page.\u00a0The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your\u00a0PagerDuty account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter\u00a0the\u00a0API Key\u00a0for your\u00a0PagerDuty account.DomainEnter\u00a0the domain for your PagerDuty URL.", "source": "../../raw_kb/article/pagerduty_advanced_connector/index.html", "title": "PagerDuty Advanced Connector"}, {"objectID": "6bab2b202395-2", "text": "For information about obtaining these credentials, see \"Prerequisites,\" above.\nOnce you have entered valid\u00a0PagerDuty credentials, you can use the same account any time you go to create a new\u00a0PagerDuty\u00a0Advanced DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains\u00a0a primary\u00a0menu from which you can select a report, along with various other fields and menus that may or may not appear depending on your selected report.", "source": "../../raw_kb/article/pagerduty_advanced_connector/index.html", "title": "PagerDuty Advanced Connector"}, {"objectID": "6bab2b202395-3", "text": "MenuDescriptionReportSelect a\u00a0PagerDuty report. The following reports are available:AlertsRetrieves existing alerts for a given time range. \u00a0Alerts RollupRetrieves existing alerts by day, week, or month for a given period of time.Escalation PoliciesRetrieves all existing escalation policies.\u00a0\u00a0Escalation Policies On CallRetrieves all existing escalation policies with currently on-call users.Escalation Rules\u00a0Retrieves\u00a0rules for a specified\u00a0escalation policy. \u00a0Incident Notes\u00a0Retrieves\u00a0existing notes for a specified incident.\u00a0\u00a0Incidents\u00a0Retrieves existing incidents. \u00a0Incidents Count\u00a0Retrieves the count of the number of incidents matching the specified criteria.\u00a0Incidents Rollup\u00a0Retrieves existing incidents\u00a0by day, week, or month for a given period of time.\u00a0Log Entries\u00a0Retrieves all incident log entries across the entire account.\u00a0Maintenance Windows\u00a0Retrieves existing maintenance windows.\u00a0Schedule Overrides\u00a0Retrieves overrides for a given time range.\u00a0Schedules\u00a0Retrieves existing on-call schedules.\u00a0Services\u00a0Retrieves existing services. \u00a0Users\u00a0Retrieves existing users. \u00a0Users on Call\u00a0Retrieves existing on-call users.\u00a0Duration\u00a0Select whether you", "source": "../../raw_kb/article/pagerduty_advanced_connector/index.html", "title": "PagerDuty Advanced Connector"}, {"objectID": "6bab2b202395-4", "text": "existing on-call users.\u00a0Duration\u00a0Select whether you want to pull data for a specific date or a date range.\u00a0Report Date\u00a0Select whether the report data is for a specific date or for a relative number of days back from today.\u00a0Select Specific Date\u00a0Select the date for the report.\u00a0Days BackEnter the number of past days that should appear in the report.\u00a0\u00a0Start DateSpecify whether the\u00a0first date in your date range is a specific or relative date.\u00a0You select the last date in your range in\u00a0End Date.\u00a0End DateSpecify whether the second date in your date range is a specific or relative date. You select the first date in your range in\u00a0Start Date.\u00a0\u00a0Select Specific Start DateSelect\u00a0the first date in your date range.\u00a0Select Specific End DateSelect the second date in your date range.\u00a0Days Back to Start FromEnter the number of the farthest day back that should be represented in the report. Combine with\u00a0Days Back to End At\u00a0to create a range of represented days.", "source": "../../raw_kb/article/pagerduty_advanced_connector/index.html", "title": "PagerDuty Advanced Connector"}, {"objectID": "6bab2b202395-5", "text": "For example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Days Back to End AtEnter the number of the most recent day back that should be represented in the report. Combine with\u00a0Days Back to Start From\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Date Granularity\u00a0Select whether you want report data to be shown by day, week, or month.\u00a0Policy Name\u00a0Enter the name of the policy you want to retrieve information for.Policy ID\u00a0Enter ID of the policy you want to retrieve information for.Incident ID\u00a0Enter the ID of the incident you want to retrieve information for.User ID(s)\u00a0Enter the ID(s) of the user(s) you want to retrieve information for. Separate multiple IDs with commas. \u00a0Description\u00a0Enter description text to filter the data in your report. \u00a0Schedule ID\u00a0Enter the ID of the schedule you want to retrieve information for.\u00a0Schedule Name\u00a0Enter the name of the schedule you want to retrieve information for.\u00a0Username/Email Address\u00a0Enter a username or email address to filter\u00a0the data in your report. \u00a0RollupSelect the desired grain for your report data--either daily, weekly, or monthly.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/pagerduty_advanced_connector/index.html", "title": "PagerDuty Advanced Connector"}, {"objectID": "9e63267195df-0", "text": "TitlePagerDuty ConnectorArticle Body\nIntro\nPagerDuty is an operations performance platform designed to make businesses more reliable by eliminating the chaos across the entire operations lifecycle.\u00a0Use Domo's\u00a0PagerDuty connector to\u00a0get reports about schedule management, alerting, and incident tracking. To learn more about\u00a0the\u00a0PagerDuty API, visit their\u00a0website (https://developer.pagerduty.com/documentation/rest).\n\n\n\nThe PagerDuty connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking Cloud App in the toolbar at the top of the window.", "source": "../../raw_kb/article/pagerduty_connector/index.html", "title": "PagerDuty Connector"}, {"objectID": "9e63267195df-1", "text": "This is the simplified version of this connector, which allows you to simply pull data for a previous month instead of specifying a date range. There is also an advanced version of the connector, which provides options for setting up a date range. For more information, see\u00a0PagerDuty Advanced Connector.\nYou connect to your\u00a0PagerDuty account in the\u00a0Data Center. This topic discusses the fields and menus that are specific to the\u00a0PagerDuty connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your\u00a0PagerDuty account and create a DataSet, you must have the following:\nThe API key for your\u00a0PagerDuty account. For information about generating a PagerDuty API key, see\u00a0https://support.pagerduty.com/hc/en-us/articles/202829310-Generating-an-API-Key.The domain for your PagerDuty URL. For example, if your PagerDuty URL was\u00a0domo.pagerduty.com, you would enter\u00a0domo\u00a0as the domain.\nConnecting to Your\u00a0PagerDuty Account\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the\u00a0PagerDuty\u00a0Connector page.\u00a0The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your\u00a0PagerDuty account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter\u00a0the\u00a0API Key\u00a0for your\u00a0PagerDuty account.DomainEnter\u00a0the domain for your PagerDuty URL.\u00a0\nFor information about obtaining these credentials, see \"Prerequisites,\" above.", "source": "../../raw_kb/article/pagerduty_connector/index.html", "title": "PagerDuty Connector"}, {"objectID": "9e63267195df-2", "text": "For information about obtaining these credentials, see \"Prerequisites,\" above.\nOnce you have entered valid\u00a0PagerDuty credentials, you can use the same account any time you go to create a new\u00a0PagerDuty DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains\u00a0a primary\u00a0menu from which you can select a report, along with various other fields and menus that may or may not appear depending on your selected report.", "source": "../../raw_kb/article/pagerduty_connector/index.html", "title": "PagerDuty Connector"}, {"objectID": "9e63267195df-3", "text": "MenuDescriptionReportSelect a\u00a0PagerDuty report. The following reports are available:AlertsRetrieves existing alerts for a given time range. \u00a0Alerts RollupRetrieves existing alerts by day, week, or month for a given period of time.Escalation PoliciesRetrieves all existing escalation policies.\u00a0\u00a0Escalation Policies On CallRetrieves all existing escalation policies with currently on-call users.Escalation Rules\u00a0Retrieves\u00a0rules for a specified\u00a0escalation policy. \u00a0Incident Notes\u00a0Retrieves\u00a0existing notes for a specified incident.\u00a0\u00a0Incidents\u00a0Retrieves existing incidents. \u00a0Incidents Count\u00a0Retrieves the count of the number of incidents matching the specified criteria.\u00a0Incidents Rollup\u00a0Retrieves existing incidents\u00a0by day, week, or month for a given period of time.\u00a0Log Entries\u00a0Retrieves all incident log entries across the entire account.\u00a0Maintenance Windows\u00a0Retrieves existing maintenance windows.\u00a0Schedule Overrides\u00a0Retrieves overrides for a given time range.\u00a0Schedules\u00a0Retrieves existing on-call schedules.\u00a0Services\u00a0Retrieves existing services. \u00a0Users\u00a0Retrieves existing users. \u00a0Users on Call\u00a0Retrieves existing on-call users.\u00a0Duration\u00a0Select whether the", "source": "../../raw_kb/article/pagerduty_connector/index.html", "title": "PagerDuty Connector"}, {"objectID": "9e63267195df-4", "text": "existing on-call users.\u00a0Duration\u00a0Select whether the data in this report is for a single specified date or for the past month.Report Date\u00a0Specify whether the\u00a0data is for a specific\u00a0or relative date.\u00a0Choose\u00a0Relative if you always want the report to\u00a0retrieve data for a\u00a0given number of days back (which you specify in Date Offset) from the current date. For example, if you enter\u00a05 for Date Offset and set the\u00a0DataSet to update\u00a0daily, each\u00a0new day the report will update to show information for the date 5 days in the past.\u00a0\u00a0\u00a0\u00a0Select Specific Date\u00a0Select the date you want to retrieve information for.\u00a0Date Offset\u00a0Enter the number of days back from the current date that will be presented in the report.\u00a0\u00a0Date Granularity\u00a0Select whether you want report data to be shown by day, week, or month.\u00a0Policy Name\u00a0Enter the name of the policy you want to retrieve information for.Policy ID\u00a0Enter ID of the policy you want to retrieve information for.Incident ID\u00a0Enter the ID of the incident you want to retrieve information for.User ID(s)\u00a0Enter the ID(s)", "source": "../../raw_kb/article/pagerduty_connector/index.html", "title": "PagerDuty Connector"}, {"objectID": "9e63267195df-5", "text": "to retrieve information for.User ID(s)\u00a0Enter the ID(s) of the user(s) you want to retrieve information for. Separate multiple IDs with commas. \u00a0Description\u00a0Enter description text to filter the data in your report. \u00a0Schedule ID\u00a0Enter the ID of the schedule you want to retrieve information for.\u00a0Schedule Name\u00a0Enter the name of the schedule you want to retrieve information for.\u00a0Username/Email Address\u00a0Enter a username or email address to filter\u00a0the data in your report. \u00a0RollupSelect the desired grain for your report data--either daily, weekly, or monthly.", "source": "../../raw_kb/article/pagerduty_connector/index.html", "title": "PagerDuty Connector"}, {"objectID": "9e63267195df-6", "text": "Other Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/pagerduty_connector/index.html", "title": "PagerDuty Connector"}, {"objectID": "ea23aa89bc64-0", "text": "TitlePagerDuty V2 ConnectorArticle Body\nIntro\nPagerDuty is an operations performance platform designed to make businesses more reliable by eliminating the chaos across the entire operations lifecycle.\u00a0Use Domo's\u00a0PagerDuty\u00a0V2 connector to\u00a0get reports about schedule management, notifications, incident tracking, and more. To learn more about\u00a0the\u00a0PagerDuty API, visit their\u00a0website (https://developer.pagerduty.com/documentation/rest).\nThe PagerDuty\u00a0V2 connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking Cloud App in the toolbar at the top of the window.\nYou connect to your\u00a0PagerDuty account in the\u00a0Data Center. This topic discusses the fields and menus that are specific to the\u00a0PagerDuty\u00a0V2 connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your\u00a0PagerDuty account and create a DataSet, you must have the API key for your\u00a0PagerDuty account. For information about generating a PagerDuty API key, see\u00a0https://support.pagerduty.com/hc/en-us/articles/202829310-Generating-an-API-Key.\nConnecting to Your\u00a0PagerDuty Account\nThis section enumerates the options in the\u00a0Credentials\u00a0and\u00a0Details\u00a0panes in the\u00a0PagerDuty\u00a0V2 Connector page.\u00a0The components of the other panes in this page,\u00a0Scheduling\u00a0and\u00a0Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane", "source": "../../raw_kb/article/pagerduty_v2_connector/index.html", "title": "PagerDuty V2 Connector"}, {"objectID": "ea23aa89bc64-1", "text": "Credentials Pane\nThis pane contains fields for entering credentials to connect to your\u00a0PagerDuty account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter\u00a0the\u00a0API Key\u00a0for your\u00a0PagerDuty account.\u00a0For information about generating a PagerDuty API key, see\u00a0https://support.pagerduty.com/hc/en-us/articles/202829310-Generating-an-API-Key.\nOnce you have entered valid\u00a0PagerDuty credentials, you can use the same account any time you go to create a new\u00a0PagerDuty\u00a0V2 DataSet. You can manage connector accounts in the\u00a0Accounts\u00a0tab in the\u00a0Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains\u00a0a primary\u00a0menu from which you can select a report, along with various other fields and menus that may or may not appear depending on your selected report.", "source": "../../raw_kb/article/pagerduty_v2_connector/index.html", "title": "PagerDuty V2 Connector"}, {"objectID": "ea23aa89bc64-2", "text": "MenuDescriptionReportSelect a\u00a0PagerDuty report. The following reports are available:AbilitiesRetrieves all abilities for your account.AddonsRetrieves all of the add-ons installed in your account.Escalation PoliciesRetrieves all existing escalation policies.\u00a0\u00a0ExtensionsRetrieves all existing extensions.\u00a0Incident AlertsRetrieves alerts for the specified incident.\u00a0Incident Log EntriesReturns log entries for a specified incident.\u00a0Incident Notes\u00a0Retrieves\u00a0existing notes for a specified incident.\u00a0\u00a0Incidents\u00a0Retrieves existing incidents. \u00a0Log Entries\u00a0Retrieves all incident log entries across the entire account.\u00a0Maintenance Windows\u00a0Retrieves existing maintenance windows.\u00a0NotificationsReturns all existing notifications across the entire account.\u00a0On-CallsReturns all on-call entries for the account.\u00a0Schedule Overrides\u00a0Retrieves overrides for a given time range.\u00a0Schedules\u00a0Retrieves existing on-call schedules.\u00a0Schedules UsersReturns a list of all users on call in a given schedule.\u00a0Services\u00a0Retrieves existing services. \u00a0TeamsReturns all teams on your account.Users\u00a0Retrieves existing users. \u00a0Vendors\u00a0Retrieves all vendors on the account.\u00a0Query (Optional)Enter a term to filter the results of your\u00a0report.\u00a0User", "source": "../../raw_kb/article/pagerduty_v2_connector/index.html", "title": "PagerDuty V2 Connector"}, {"objectID": "ea23aa89bc64-3", "text": "a term to filter the results of your\u00a0report.\u00a0User ID(s) (Optional)Enter the ID(s) of the user(s) you want to retrieve information for. Separate multiple IDs with commas. \u00a0Team IDs (Optional)Enter the ID(s) of the team(s) you want to retrieve information for. Separate multiple IDs with commas. The account must have the \"Teams\" ability enabled for this option to work.\u00a0\u00a0Sort ByChoose how you want to sort the data in your report, either by name, ascending name, or descending name.\u00a0Duration\u00a0Select whether the data in this report is for a single specified date or for the past month.Report Date\u00a0Specify whether the\u00a0data is for a specific\u00a0or relative date.\u00a0Choose\u00a0Relative if you always want the report to\u00a0retrieve data for a\u00a0given number of days back (which you specify in Date Offset) from the current date. For example, if you enter\u00a05 for Date Offset and set the\u00a0DataSet to update\u00a0daily, each\u00a0new day the report will update to show information for the date 5 days in the past.\u00a0\u00a0\u00a0\u00a0Select Specific Date\u00a0Select the date", "source": "../../raw_kb/article/pagerduty_v2_connector/index.html", "title": "PagerDuty V2 Connector"}, {"objectID": "ea23aa89bc64-4", "text": "in the past.\u00a0\u00a0\u00a0\u00a0Select Specific Date\u00a0Select the date you want to retrieve information for.\u00a0Date Offset\u00a0Enter the number of days back from the current date that will be presented in the report.\u00a0\u00a0Date Granularity\u00a0Select whether you want report data to be shown by day, week, or month.\u00a0Policy Name\u00a0Enter the name of the policy you want to retrieve information for.Policy ID\u00a0Enter ID of the policy you want to retrieve information for.Incident ID\u00a0Enter the ID of the incident you want to retrieve information for.Date RangeSelect whether you want to pull data for all time or for a selected date range. When you select\u00a0All, the\u00a0SINCE\u00a0and\u00a0UNTIL\u00a0parameters and defaults are ignored.\u00a0Start DateSpecify whether the\u00a0first date in your date range is a specific or relative date.\u00a0You select the last date in your range in\u00a0End Date.\u00a0End DateSpecify whether the second date in your date range is a specific or relative date. You select the first date in your range in\u00a0Start Date.\u00a0\u00a0Select Specific Start DateSelect\u00a0the first date in your date range.\u00a0Select", "source": "../../raw_kb/article/pagerduty_v2_connector/index.html", "title": "PagerDuty V2 Connector"}, {"objectID": "ea23aa89bc64-5", "text": "DateSelect\u00a0the first date in your date range.\u00a0Select Specific End DateSelect the second date in your date range.\u00a0Days Back to Start FromEnter the number of the farthest day back that should be represented in the report. Combine with\u00a0Days Back to End At\u00a0to create a range of represented days.", "source": "../../raw_kb/article/pagerduty_v2_connector/index.html", "title": "PagerDuty V2 Connector"}, {"objectID": "ea23aa89bc64-6", "text": "For example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Days Back to End AtEnter the number of the most recent day back that should be represented in the report. Combine with\u00a0Days Back to Start From\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Incident IDSelect the ID of the incident you want to retrieve data for.\u00a0Schedule ID\u00a0Enter the ID of the schedule you want to retrieve information for.\u00a0Time ZoneSelect the time zone for the dates in your report.\u00a0\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nFAQs\nHow often can the data be updated?\nAs often as needed.\nAre there any API limits I should be aware of?\nNo.", "source": "../../raw_kb/article/pagerduty_v2_connector/index.html", "title": "PagerDuty V2 Connector"}, {"objectID": "e789f5f38b83-0", "text": "Title\n\nPage Filters in Dashboard Embed\n\nArticle Body\n\nIntro\nWith Page Filters in Dashboard Embed you are now able to add the same filters you use in your Domo instance inside of your embedded Dashboard. This will allow users to:\nFilter for any column with the same flow you know from the full instance.Choose from default date ranges to jump quickly to popular time frames.Change trend granularity with the \u201cgraph by\u201d option for hour, day, week, etc.\n\n\n\n\n\nNote: Unlike filtering on Dashboards in your full instance of Domo, you cannot save the filtered view in the embedded instance.", "source": "../../raw_kb/article/page_filters_in_dashboard_embed/index.html", "title": "Page Filters in Dashboard Embed"}, {"objectID": "e789f5f38b83-1", "text": "Enabling Page Filters in Dashboard Embed\nNavigate to the Dashboard you would like to embed.Click the  icon.Select Embed Dashboard from the dropdown menu.Enable the check the boxes for Allow interactions and filtering AND Show filter bar.\nUsing Page Filters in Dashboard Embed\nTo apply Page Filters,\nNavigate to the Dashboard you would like to filter.Click on the blue filter icon located at the top right-hand side of the Dashboard.Click the\u00a0+ button.A list of all column names used in DataSets in Cards in this Page appears. If a column name is used in more than one DataSet, an arrow appears to the right of the name so you can filter down to the desired DataSet if you want.Click the name of the column you want to filter.Alternatively, if the column name is used in more than one DataSet and you want to filter to show just the rows in a specific DataSet, you can click the arrow next to the column name to bring up a dialog with the names of all the applicable DataSets. Here you can check the boxes for all the DataSets you want to show rows for (or simply select all DataSets by checking the Select all box).If you select a column that appears in more than one DataSet without filtering down to a specific DataSet, the columns from the DataSet powering the most Cards in the Page will be used for the Filter.After you select a column or DataSets, a Filter button appears on the left side of the gray bar, and a dialog appears in which you can select your Filters. The interface components of the dialog differ depending on whether the column or row you selected contains series, amount, or date data.Do one of the following:", "source": "../../raw_kb/article/page_filters_in_dashboard_embed/index.html", "title": "Page Filters in Dashboard Embed"}, {"objectID": "e789f5f38b83-2", "text": "(Conditional) If the selected column contains string data,Select the checkboxes for each series you want to show in the Cards in this Page.You can select all of the checkboxes by clicking All or deselect all of the checkboxes by clicking None.You can filter the series that appear in the list by entering a keyword or a string of characters found in a keyword in the Filter by field.Note: Currently, only 500 unique values will show in the Filter menu.Finally, if you want to load values from a specific DataSet, you can click  then choose the desired DataSet. This will load the unique values on that DataSet but apply to all DataSets with that same column name.Specify whether the items you have checked appear or do not appear in your chart by selecting In or Not In from the menu in the top right.Click Apply.(Conditional) If the selected column contains amount data,Do one of the following:\nIf you want to filter amounts based on a range...\nLeave the dropdown menu in the upper right corner set to Range.Select a condition statement from the menu.One or more fields may appear, depending on the condition statement.(Conditional) If one or more fields appeared when you selected a condition statement, enter the desired amounts in the fields.For example, if you wanted your Cards to show information for amounts between 200,000 and 300,000, you would select is between from the menu, enter \"200,000\" in the first field, and enter \"300,000\" in the second field.If you want to filter amounts based on specific values from your DataSet...", "source": "../../raw_kb/article/page_filters_in_dashboard_embed/index.html", "title": "Page Filters in Dashboard Embed"}, {"objectID": "e789f5f38b83-3", "text": "Select Selection in the dropdown menu in the upper right corner.Check the boxes for all of the values you want to filter on.You can select all of the checkboxes by clicking All or deselect all of the checkboxes by clicking None. Or you can filter the values that appear in the list by entering a string of numbers in the Filter by field.If you want to load values from a specific DataSet, you can click\u00a0\u00a0then choose the desired DataSet. This will load the unique values on that DataSet but apply to all DataSets with that same column name.Finally, you can specify whether the items you have checked appear or do not appear in your chart by selecting In or Not In from the menu in the top right.Click Apply.(Conditional) If the selected column contains date data,Do one of the following:\nIf you want to filter dates based on a range...\nLeave the dropdown menu in the upper right corner set to Range.Select a condition statement from the menu.One or more fields may appear, depending on the condition statement.Enter the desired dates in the fields as necessary.For example, if you wanted your Cards to show information for dates between 1-31-2014 and 4-30-2015, you would select is between from the menu, select January 1, 2014 in the first field, and select April 30, 2015 in the second field.If you want to filter dates based on specific dates from your DataSet...", "source": "../../raw_kb/article/page_filters_in_dashboard_embed/index.html", "title": "Page Filters in Dashboard Embed"}, {"objectID": "e789f5f38b83-4", "text": "Select Selection in the dropdown menu in the upper right corner.Check the boxes for all of the dates you want to filter on.You can select all of the checkboxes by clicking All or deselect all of the checkboxes by clicking None. Or you can filter the dates that appear in the list by entering a filter string in the Filter by field. (For example, if you wanted to filter down to dates from 2010, you would enter \"2010\" into this field.)If you want to load values from a specific DataSet, you can click  then choose the desired DataSet. This will load the unique values on that DataSet but apply to all DataSets with that same column name.Finally, you can specify whether the dates you have checked appear or do not appear in your chart by selecting In or Not In from the menu in the top right.Click Apply.\nThe affected Cards in the Page update to reflect the Filters you have selected. In addition, a  icon appears on each affected Card.\nTo edit a Filter,\nClick the button for the Filter in the gray bar at the top of the Page.The dialog for the Filter appears.Edit the Filter settings as desired.Click Apply.\nYour changes are applied to the Filter.\nTo remove a Filter,\nClick the button for the Filter in the gray bar at the top of the Page.The dialog for the Filter appears.Click .Click Continue to confirm the removal.\nThis Filter is removed, and all of the Cards that used the Filter are updated accordingly.\nUsing Filter views\nYou can embed a Dashboard with Filter views that you have curated for your Subscribers. Filter views allow you to customize a Page to meet the needs of all audiences. Using Filter views, you can do all of the following:", "source": "../../raw_kb/article/page_filters_in_dashboard_embed/index.html", "title": "Page Filters in Dashboard Embed"}, {"objectID": "e789f5f38b83-5", "text": "Create and save your own Filters without affecting anyone else's view.Curate and share important views to create alignment on a specific perspective.Provide any number of personalized data stories for any person in any role.Designate which saved Filter view is the \"default\" for first-time visitors to a Page.\nAny Subscriber can add Filter views as well as rename, copy, and delete his/her own Filter views. For more information on Filter views, see Applying Page-Level Filters with Filter Views.\nApplying dynamic date range Filters\nYou can use dynamic date range Filters to adjust the date range window for all the Cards on a Page. These Filters can be saved and used as the default for all users in a Page. They can also be saved to different Filter Views (described in the previous section). Dynamic date range Filters can be a huge time-saver, since users do not need to manually apply filters to see data for a given date or time range. Also, with dynamic date range Filters, the date range data for your Cards automatically \"rolls over\" when the current period ends.", "source": "../../raw_kb/article/page_filters_in_dashboard_embed/index.html", "title": "Page Filters in Dashboard Embed"}, {"objectID": "e789f5f38b83-6", "text": "Note: Dynamic date range filters only apply to Visualization Cards and Sumo Cards. They do NOT work on Doc Cards, Poll Cards, Notebook Cards, and Custom Apps.", "source": "../../raw_kb/article/page_filters_in_dashboard_embed/index.html", "title": "Page Filters in Dashboard Embed"}, {"objectID": "e789f5f38b83-7", "text": "You choose dynamic date range Filters in the\u00a0Choose Date\u00a0menu in the gray filter bar at the top of a Page.The Filters you choose here are applied to all Cards in the Page that have had a date column applied in Analyzer. Filters are applied to each Card's unique date column and take into account date filters that have already been set on the Card. So for example, if a Page contained a Card that was powered by the \"Sales Dates\" column and the dates were filtered in Analyzer to show March through June, if dynamic date range Filters were set on the Page, the Filters would be applied to the \"Sales Dates\" column and would only work within the March-June time period. If the dynamic Filters were set outside that time period, the Card would display \"No data in filtered range.\"\nYou are able to choose Cards that will not be affected by the dynamic date, by deselecting the Allow global date feature. More information can be found in the Controlling how Page Filters affect your Page section above. If you have chosen the Hide Date on Card Details option for a Card, the dynamic date will also not be applied to the Card.\nMost of the options for dynamic date range Filters are the same as those for filtering dates in the Analyzer. In essence, these options are as follows:", "source": "../../raw_kb/article/page_filters_in_dashboard_embed/index.html", "title": "Page Filters in Dashboard Embed"}, {"objectID": "e789f5f38b83-8", "text": "Date Range. This lets you choose the range of data shown for all Cards in the Page being powered by date columns. By default\u00a0this is\u00a0set to\u00a0Default, meaning that all Cards use their own date ranges. A wide variety of other options is available, including the current date period, period-to-date options such as\u00a0Week to Date, and so on.\u00a0Graph By. This lets you choose the date grain for all Cards in the Page being powered by date columns.\u00a0The date grain determines\u00a0whether the data is shown by week, by month, etc. This menu is described in more detail in\u00a0Changing the unit of time used to represent data. By default no date grain is selected, meaning the Cards use\u00a0the same date grain used in their powering DataSets. (For example, if data for a Card was broken down by week in the DataSet, it would be automatically broken down by week in the Card).", "source": "../../raw_kb/article/page_filters_in_dashboard_embed/index.html", "title": "Page Filters in Dashboard Embed"}, {"objectID": "e789f5f38b83-9", "text": "Note: The Date Graph By does not impact Single Value charts. This is to ensure best data practices as Graph By will impact which row is returned in the chart query.", "source": "../../raw_kb/article/page_filters_in_dashboard_embed/index.html", "title": "Page Filters in Dashboard Embed"}, {"objectID": "19bf2db02257-0", "text": "Title\n\nPareto Chart\n\nArticle Body\n\nIntro\nPareto charts are single-series bar charts with categories ordered according to the size of their data items (largest to smallest). A line above the bars shows the cumulative value of all of the data items to that point. A Pareto chart has two scales\u2014one on the left that shows the actual data values, and one on the right that measures percentages of the total value of the data series.\nPowering Pareto charts\nPareto charts require only two columns or rows of data from your DataSet\u2014one for categories and one for values. The values in the values column are used to create both of the vertical scales in the chart. For information about value, category, and series data, see Understanding Chart Data.\nIn the Analyzer, you choose the columns containing the data for your Pareto chart. For more information about choosing data columns, see\u00a0Applying DataSet Columns to Your Chart.\nFor more information about formatting charts in the Analyzer, see\u00a0Visualization Card Building Part 2: The Card Builder.\nThe following graphic shows you how the data from a typical column-based spreadsheet is converted into a Pareto chart:\n\nCustomizing Pareto charts\nYou can customize the appearance of a Pareto chart by editing its Chart Properties. For information about all chart properties, see\u00a0 Chart Properties.", "source": "../../raw_kb/article/pareto_chart/index.html", "title": "Pareto Chart"}, {"objectID": "d933aecaeab2-0", "text": "TitleParticle ConnectorArticle BodyIntro\nParticle.io is a manufacturer of Internet-connected hardware and microcontrollers. Particle allows developers, hardware engineers, and DIY makers to build Internet-connected devices via WiFi, Cellular and Mesh connectivity. To learn more about the Particle API, visit their page (https://docs.particle.io/reference/device-cloud/api/).\nYou connect to your Particle account in the Data Center. This topic discusses the fields and menus that are specific to the Particle connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Particle account and create a DataSet, you must have a Particle access token. For help generating a token, please consult the Particle.io API documentation.\nConnecting to Your Particle Account\nThis section enumerates the options in the Credentials and Details panes in the Particle Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Particle account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAccess TokenEnter your Particle access token.\u00a0For help generating a token, please consult the Particle.io API documentation.\nOnce you have entered valid Particle credentials, you can use the same account any time you go to create a new Particle DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/particle_connector/index.html", "title": "Particle Connector"}, {"objectID": "d933aecaeab2-1", "text": "MenuDescriptionReportSelect the Particle report you want to run.\u00a0The following reports are available:Get All Historical Device VitalsReturns all available historical device vitals information.Get Cellular Network StatusReturns information about Particle IoT cellular network status.Get Data Usage for Product FleetReturns information about data usage costs for your Particle IoT products.Get Device  Returns detailed information about Particle IoT devices.Get Last Known Device VitalsReturns device vitals information from the last connection to the cloud for your Particle IoT devices.Get Sim  Returns detailed information about Particle IoT device SIM cards.Get Variable ValueReturns the value of a cloud variable you specify.List Customers for a ProductReturns information about your Particle IoT product customers.List Device GroupsReturns information about product device groups.List DevicesReturns information about Particle IoT devices.List Devices in a ProductReturns information about your Particle IoT devices you have assigned to a product.List Product FirmwaresReturns information about product firmware.List ProductsReturns information about your Particle IoT products.List Sim CardsReturns information about Particle IoT device SIM cards.DevicesSelect the devices you want to retrieve data for.Variable NameSelect the variable you want to retrieve data for. Variable names must correspond to the devices you select in the Devices\u00a0menu. If there are no variables listed, return to the\u00a0Devices\u00a0menu and choose devices with the same variable names.Data SelectionSelect the desired data type.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/particle_connector/index.html", "title": "Particle Connector"}, {"objectID": "501d15625ffb-0", "text": "TitlePatentsView ConnectorArticle BodyIntro\nPatentsView\u00a0 is a prototype patent data visualization and analysis platform intended to increase the value, utility, and transparency of US patent data. \u00a0To learn more about the PatentsView API, visit their page (http://www.patentsview.org/api/doc.html).\nYou connect to your PatentsView account in the Data Center. This topic discusses the fields and menus that are specific to the PatentsView connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nNone. This connector retrieves public data, so there is no need to enter account credentials.\u00a0\nConnecting to Your PatentsView Account\nThis section enumerates the options in the Details panes in the PatentsView Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/patentsview_connector/index.html", "title": "PatentsView Connector"}, {"objectID": "501d15625ffb-1", "text": "MenuDescriptionReportSelect the PatentsView report you want to run.\u00a0The following reports are available:AssigneesReturns a list of all assignees.CPCReturns a list of all CPC (Cooperative Patent Classification) subsections.LocationsReturns a list of all patent locations.NBERReturns a list of NBER\u00a0(National Bureau of Economic Research) categories.\u00a0PatentsReturns a list of patents.USPCReturns a list of USPC (United States Patent Classification) mainclasses.\u00a0Query TypeSelect your desired query type.\u00a0No Filter. Select this option if you do not want to filter data using a query.Query Builder. Select this option if you want help in building your query. A sample of template code will appear in the field below the options; all you need to do is fill in the gaps in the code with your desired filter criteria.Manual Query. Select this option if you want to build your entire filter query yourself.\u00a0QueryIf you selected Query Builder as your\u00a0Query Type, simply fill in the gaps in the code sample with your desired filter criteria.\nIf you selected\u00a0Manual Query\u00a0as your\u00a0Query Type, enter your query here.\u00a0\nAn example of a manual query would be as follows:\n('inventor_last_name' = 'Whitney' AND ('patent_title' TEXT_PHRASE 'cotton gin')) OR ('inventor_last_name' = 'Heath' AND 'patent_title' TEXT_ALL 'COBOL') AND ('patent_number' = '9616799').\u00a0\nIn other words, the report will pull data ONLY if the inventors's last name is \"Whitney\" and the patent name is \"cotton_gin\" OR the inventor's last name is \"Heath\" and the patent title is \"Cobol.\" In both cases,\u00a0the patent number must also be\u00a0\"9616799.\"", "source": "../../raw_kb/article/patentsview_connector/index.html", "title": "PatentsView Connector"}, {"objectID": "501d15625ffb-2", "text": "Refer to the following links for respective reports for filter selection:\"Patents\" -- Patents Report Filter List\u00a0\"Inventors\" -- Inventors Report Filter List\"Assignees\" -- Assignees Report Filter List\"Locations\" -- Locations Report Filter List\"CPC\" -- CPC Report Filter List\"USPC\" -- USPC\u00a0Report Filter List\"NBER\" -- NBER\u00a0Report Filter ListFieldsSelect the category of fields you want to pull data from.Date FilterSelect the date filter you want to apply to your report.Duration\u00a0Select whether you want to pull data for a specific date or a date range.\u00a0Report Date\u00a0Select whether the report data is for a specific date or for a relative number of days back from today.\u00a0Select Specific Date\u00a0Select the date for the report.\u00a0Days BackEnter the number of past days that should appear in the report.\u00a0\u00a0Start DateSpecify whether the\u00a0first date in your date range is a specific or relative date.\u00a0You select the last date in your range in\u00a0End Date.\u00a0End DateSpecify whether the second date in your date range is a specific or relative date. You select the first date in your range in\u00a0Start Date.\u00a0\u00a0Select Specific Start DateSelect\u00a0the first date in your date range.\u00a0Select Specific End DateSelect the second date in your date range.\u00a0Days Back to Start FromEnter the number of the farthest day back that should be represented in the report. Combine with\u00a0Days Back to End At\u00a0to create a range of represented days.\nFor example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.Days Back to End AtEnter the number of the most recent day back that should be represented in the report. Combine with\u00a0Days Back to Start From\u00a0to create a range of represented days.", "source": "../../raw_kb/article/patentsview_connector/index.html", "title": "PatentsView Connector"}, {"objectID": "501d15625ffb-3", "text": "For example, if you entered\u00a010\u00a0for\u00a0Days Back to Start From\u00a0and\u00a05\u00a0for\u00a0Days Back to End At, the report would contain data for\u00a010 days ago up until\u00a05 days ago.\nOther Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.\nFAQs\nHow often can the data be updated?\nAs often as needed.\nAre there any API limits I should be aware of?\nThe results from the API will only have one level of hierarchy of subentities under the primary entity.", "source": "../../raw_kb/article/patentsview_connector/index.html", "title": "PatentsView Connector"}, {"objectID": "86a8a35fa59c-0", "text": "Title\n\nPaydirt Connector\n\nArticle Body", "source": "../../raw_kb/article/paydirt_connector/index.html", "title": "Paydirt Connector"}, {"objectID": "86a8a35fa59c-1", "text": "Intro\nPaydirt\u00a0provides online invoicing and time tracking for freelancers and agencies.\u00a0 To learn more about the Paydirt API, visit their page (https://paydirtapp.com/documentation/api/introduction).  \nYou connect to your Paydirt account in the Data Center. This topic discusses the fields and menus that are specific to the Paydirt connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\u00a0Adding a DataSet Using a Data Connector.\nPrerequisites\nTo connect to your Paydirt account and create a DataSet, you must have a Paydirt API key.\u00a0You can find your Paydirt API key in your\u00a0Password Settings\u00a0page.\nConnecting to Your Paydirt Account\nThis section enumerates the options in the Credentials and Details panes in the Paydirt Connector page.\u00a0The components of the other panes in this page, Scheduling\u00a0and Name & Describe Your DataSet, are universal across most connector types and are discussed in greater length in\u00a0Adding a DataSet Using a Data Connector.\nCredentials Pane\nThis pane contains fields for entering credentials to connect to your Paydirt account. The following table describes what is needed for each field: \u00a0\nFieldDescriptionAPI KeyEnter your Paydirt API key.\u00a0You can find your API key in your\u00a0Password Settings\u00a0page.\nOnce you have entered valid Paydirt credentials, you can use the same account any time you go to create a new Paydirt DataSet. You can manage connector accounts in the Accounts tab in the Data Center. For more information about this tab, see Managing User Accounts for Connectors.\nDetails Pane\nThis pane contains a primary\u00a0Reports\u00a0menu, along with various other menus which may or may not appear depending on the report type you select.", "source": "../../raw_kb/article/paydirt_connector/index.html", "title": "Paydirt Connector"}, {"objectID": "86a8a35fa59c-2", "text": "MenuDescriptionReportSelect the Paydirt report you want to run.\u00a0The following reports are available:ClientsReturns a list of clients in your account.ProjectsReturns a list of projects in your account.JobsReturns a list of jobs in your account.TimeReturns a list of time logs in your account.UsersReturns a list of users in your account.Start DateSelect whether to pull data for a specific or relative start date. If you select Specific, you will be asked to choose a specific start date from a date picker. If you select Relative, you will be asked to enter an offset value (i.e. the number of days in the past you want to start pulling data for).\u00a0Select Specific Start DateSelect the date you want to start pulling data for. Combine with Select Specific End Date to create a range of dates.End DateSelect whether to pull data for a specific or relative end date. If you select Specific, you will be asked to choose a specific end date from a date picker. If you select Relative, you will be asked to enter an offset value (i.e. the number of days in the past you want to stop pulling data for).\u00a0Select Specific End DateSelect the date you want to stop pulling data for. Combine with Select Specific Start Date to create a range of dates.Start Date OffsetEnter the number of days back you want to start pulling data for. Combine with End Date Offset to create a relative date range. For example, if you entered 10 for Start Date Offset and 5 for End Date Offset, each time the report ran it would pull data from the last 10 days up until the last 5 days.User IDEnter the ID of the user you want to retrieve information for.Client IDEnter the ID of the client you want to retrieve information for.Project IDEnter the ID of the project you want to retrieve information for.Job IDEnter the ID of the job\u00a0you want to retrieve information for.\nOther Panes", "source": "../../raw_kb/article/paydirt_connector/index.html", "title": "Paydirt Connector"}, {"objectID": "86a8a35fa59c-3", "text": "Other Panes\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\u00a0Adding\u00a0a DataSet Using a Data Connector.", "source": "../../raw_kb/article/paydirt_connector/index.html", "title": "Paydirt Connector"}]
