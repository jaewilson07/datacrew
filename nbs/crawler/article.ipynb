{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Article\n",
    "description: class based approach to webcrawling\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp crawler.article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# use with local installs that don't have nbdev\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "import datetime as dt\n",
    "from dataclasses import dataclass, field\n",
    "import urllib.parse as url_parse\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import chardet\n",
    "\n",
    "import selenium.webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# from fastcore.basics import patch_to\n",
    "\n",
    "import markdownify as md\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "import datacrew.crawler.crawler as dcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "class CustomConverter(md.MarkdownConverter):\n",
    "    def convert_ul(self, el, text, convert_as_inline):\n",
    "        res = '\\n'\n",
    "        classList = el.get(\"class\")\n",
    "\n",
    "        if classList and (\"article-list\" in classList or \"section-list\" in classList):\n",
    "            res = '\\n***\\n'\n",
    "\n",
    "        res = res + super().convert_list(el, text, convert_as_inline)\n",
    "        return res\n",
    "\n",
    "    def convert_div(self, el, text, convert_as_inline):\n",
    "        classList = el.get(\"class\")\n",
    "        \n",
    "        if classList and \"mt-video-widget\" in classList:\n",
    "            # print(el)\n",
    "            # custom transformation\n",
    "            # unwrap child nodes of <a class=\"searched_found\">\n",
    "            text = \"\"\n",
    "            for child in el.children:\n",
    "                # print(child.get('src'))\n",
    "                text += child.get('src')\n",
    "            text = f'{\"{{< video\"} {text}{\" >}}\"}'\n",
    "            print(text)\n",
    "            return text\n",
    "\n",
    "        # default transformation\n",
    "        return super().convert_a(el, text, convert_as_inline)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@dataclass\n",
    "class Article:\n",
    "    url: str = None\n",
    "    base_url: str = None\n",
    "    entity_base_url: str = None\n",
    "\n",
    "    url_entity_prefix: str = None\n",
    "    url_id: str = None\n",
    "\n",
    "    driver: selenium.webdriver = field(repr=False, default=None)\n",
    "    soup: BeautifulSoup = field(repr=False, default=None)\n",
    "    article_soup: BeautifulSoup = field(repr=False, default=None)\n",
    "\n",
    "    is_success: bool = False\n",
    "\n",
    "    url_ls: list[str] = None\n",
    "    image_ls: list[str] = None\n",
    "\n",
    "    child_category_ls: list[dict] = None\n",
    "    child_article_ls: list[dict] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.child_category_ls = self.child_category_ls or []\n",
    "        self.child_article_ls = self.child_article_ls or []\n",
    "        self.url_ls = self.url_ls or []\n",
    "        self.image_ls = self.image_ls or []\n",
    "\n",
    "        if self.url_entity_prefix and self.url_entity_prefix[0] != \"/\":\n",
    "            self.url_entity_prefix = f\"/{self.url_entity_prefix}\"\n",
    "\n",
    "        if self.url_entity_prefix and self.url_entity_prefix in self.base_url:\n",
    "            self.base_url = self.base_url.replace(self.url_entity_prefix, \"\")\n",
    "\n",
    "        self.entity_base_url = url_parse.urljoin(\n",
    "            self.base_url, self.url_entity_prefix or '')\n",
    "\n",
    "        self.set_id()\n",
    "\n",
    "        self.get_urls()\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.url_id == other.url_id) or (self.url == other.url)\n",
    "\n",
    "    @staticmethod\n",
    "    def md_soup(soup, **options):\n",
    "        \"\"\"conerts soup to markdown text\"\"\"\n",
    "\n",
    "        return CustomConverter(**options).convert_soup(soup)\n",
    "\n",
    "    def add_child_category_to_ls(self, child):\n",
    "\n",
    "        if child not in self.child_category_ls:\n",
    "            self.child_category_ls.append(child)\n",
    "\n",
    "        return self.child_category_ls\n",
    "\n",
    "    def add_child_article_to_ls(self, url):\n",
    "        if url not in self.child_article_ls:\n",
    "            self.child_article_ls.append(url)\n",
    "\n",
    "        return self.child_article_ls\n",
    "\n",
    "    def add_url_to_ls(self, url, is_remove_query_string_parameters: bool = True, debug_prn: bool = False):\n",
    "\n",
    "        _old_url_ls = self.url_ls\n",
    "\n",
    "        if url.startswith(\"/\") and self.url_entity_prefix in url:\n",
    "            url = url_parse.urljoin(self.base_url, url)\n",
    "\n",
    "        if is_remove_query_string_parameters:\n",
    "            url = url_parse.urljoin(url, url_parse.urlparse(url).path)\n",
    "\n",
    "        if not url.startswith(self.base_url):\n",
    "            if debug_prn:\n",
    "                print(f\"not adding {url}\")\n",
    "            return self.url_ls\n",
    "\n",
    "        if url.endswith(\"/\"):\n",
    "            url = url[:-1]\n",
    "\n",
    "        if url.split(\"/\")[-4] == \"s\":\n",
    "            url = \"/\".join(url.split(\"/\")[:-1])\n",
    "\n",
    "        if url not in self.url_ls:\n",
    "            if debug_prn:\n",
    "                print(f\"{_old_url_ls} adding {url} to {self.url} list\")\n",
    "            self.url_ls.append(url)\n",
    "\n",
    "        return self.url_ls\n",
    "\n",
    "    def get_urls(self, soup=None):\n",
    "        soup = soup or self.soup\n",
    "        if not soup:\n",
    "            return\n",
    "\n",
    "        self.url_ls = []\n",
    "\n",
    "        for soup_link in soup.find_all(\"a\"):\n",
    "            url = soup_link.get(\"href\")\n",
    "\n",
    "            if not url:\n",
    "                continue\n",
    "\n",
    "            self.add_url_to_ls(url)\n",
    "        return self.url_ls\n",
    "\n",
    "    def set_id(self):\n",
    "        o = self.url.replace(self.entity_base_url, \"\")\n",
    "        self.url_id = o.split(\"/\")[0]\n",
    "        self.url = url_parse.urljoin(self.entity_base_url, self.url_id)\n",
    "        return self.url_id\n",
    "\n",
    "    def get_images(\n",
    "        self,\n",
    "        soup=None,  # pass a soup to just exctract images from the selected content.  Default will exctract all images on the page\n",
    "        test_base_url: str = None,  # pass to limit URLs to a specific base\n",
    "        debug_prn: bool = False,\n",
    "    ):\n",
    "        \"extract image urls from soup\"\n",
    "\n",
    "        soup = soup or self.soup\n",
    "\n",
    "        self.image_ls = [\n",
    "            {\n",
    "                \"url\": f\"{self.base_url if item.get('src').startswith('/') else ''}{item.get('src')}\",\n",
    "                \"relative_url\": item.get(\"src\"),\n",
    "                \"name\": item.get(\"alt\"),\n",
    "            }\n",
    "            for item in soup.find_all(\"img\")\n",
    "            if item.get(\"src\", False)\n",
    "        ]\n",
    "\n",
    "        if test_base_url:\n",
    "            self.image_ls = [\n",
    "                img for img in self.image_ls if img.get(\"url\").startswith(test_base_url)\n",
    "            ]\n",
    "\n",
    "        if debug_prn:\n",
    "            print(self.image_ls)\n",
    "        return self.image_ls\n",
    "\n",
    "@staticmethod\n",
    "def detect_encoding(file_path, debug_prn: bool = False):\n",
    "    detector = chardet.universaldetector.UniversalDetector()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for line in f:\n",
    "            detector.feed(line)\n",
    "            if detector.done:\n",
    "                break\n",
    "    detector.close()\n",
    "\n",
    "    encoding = detector.result\n",
    "\n",
    "    if debug_prn:\n",
    "        print(encoding)\n",
    "\n",
    "    with open(file_path, encoding=encoding['encoding']) as f:\n",
    "        try:\n",
    "            return f.read()\n",
    "        except Exception as e:\n",
    "            return e\n",
    "        finally:\n",
    "            f.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium.webdriver.common.by import By\n",
    "# import datacrew.crawler.crawler as dcc\n",
    "\n",
    "# TEST_URL = \"https://domo-support.domo.com/s/article/360043429913/\"\n",
    "\n",
    "# BASE_URL = \"https://domo-support.domo.com\"\n",
    "# IMG_BASE_URL = \"https://domo-support.domo.com/servlet/rtaImage\"\n",
    "\n",
    "# driver = dcc.driversetup(is_headless=False)\n",
    "\n",
    "# test_article = Article(url=TEST_URL, driver=driver, base_url=BASE_URL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article_KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class ArticleKB_GetSoupError(Exception):\n",
    "    def __init__(self, url):\n",
    "        super().__init__(f\"failed to retrieve soup for {url}\")\n",
    "\n",
    "\n",
    "class ArticleKB_ProcessSoupError(Exception):\n",
    "    def __init__(self, url, search_term):\n",
    "        super().__init__(f\"search term {search_term} does not exist in {url}\")\n",
    "\n",
    "\n",
    "@dataclass(init=False)\n",
    "class Article_KB(Article):\n",
    "    title: str = None\n",
    "    md_str: str = field(default=None, repr=False)\n",
    "    views: int = None\n",
    "    created: dt.date = None\n",
    "    last_updated: dt.date = None\n",
    "    article_id: str = None\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_url,\n",
    "        url = None,\n",
    "        path_html: str= None,\n",
    "        driver = None,\n",
    "        child_category_ls=None,\n",
    "        child_article_ls=None,\n",
    "        url_entity_prefix=\"/s/article/\",\n",
    "        debug_prn: bool = False,\n",
    "    ):\n",
    "        self.url = url\n",
    "        self.base_url = base_url\n",
    "        self.path_html = path_html\n",
    "\n",
    "        soup = None\n",
    "\n",
    "        if path_html:\n",
    "            page_decoded = self.detect_encoding(path_html, debug_prn = debug_prn)\n",
    "\n",
    "            soup = BeautifulSoup(page_decoded, features=\"lxml\")\n",
    "        else: \n",
    "            soup = dcc.pagesource(\n",
    "                driver=self.driver,\n",
    "                url=self.url,\n",
    "                element_type=By.CLASS_NAME,\n",
    "                element_id=\"slds-form-element\",\n",
    "                is_return_soup=True,\n",
    "            )\n",
    "\n",
    "        super().__init__(\n",
    "            url=url,\n",
    "            base_url=base_url,\n",
    "            soup=soup,\n",
    "            url_entity_prefix=url_entity_prefix,\n",
    "            driver=driver,\n",
    "            child_category_ls=child_category_ls,\n",
    "            child_article_ls=child_article_ls,\n",
    "\n",
    "        )\n",
    "\n",
    "        if not soup:\n",
    "            raise ArticleKB_GetSoupError(url=self.url)\n",
    "\n",
    "        self.article_soup = self.process_soup(soup, debug_prn=debug_prn)\n",
    "        self.is_success = True\n",
    "\n",
    "    def process_soup(self, soup: BeautifulSoup, debug_prn: bool = False):\n",
    "        search_term = \"slds-form-element\"\n",
    "\n",
    "        table = soup.find_all(class_=[search_term])\n",
    "\n",
    "        if not table or table == []:\n",
    "            raise ArticleKB_ProcessSoupError(\n",
    "                url=self.url, search_term=search_term)\n",
    "\n",
    "        tarticle = []\n",
    "        for row in table:\n",
    "            # print(\"❤️\")\n",
    "\n",
    "            cells = row.find(class_=\"slds-form-element__label\")\n",
    "\n",
    "            if list(cells.strings):\n",
    "                content = row.find(class_=\"slds-form-element__control\")\n",
    "                tarticle.append((list(cells.strings)[0], content))\n",
    "\n",
    "        kb_soup = dict(tarticle)\n",
    "\n",
    "        self.title = self.md_soup(kb_soup.get(\"Title\"))\n",
    "        self.md_str = self.md_soup(kb_soup.get(\"Article Body\"))\n",
    "        self.article_id = self.md_soup(kb_soup.get(\"Article Number\"))\n",
    "        self.views = self.md_soup(kb_soup.get(\"Article Total View Count\"))\n",
    "        self.created = parser.parse(self.md_soup(\n",
    "            kb_soup.get(\"Article Created Date\")))\n",
    "\n",
    "        self.last_updated = parser.parse(\n",
    "            self.md_soup(kb_soup.get(\"First Published Date\"))\n",
    "        )\n",
    "\n",
    "        self.get_images(\n",
    "            test_base_url=\"https://domo-support.domo.com/servlet/rtaImage\",\n",
    "            debug_prn=debug_prn,\n",
    "        )\n",
    "\n",
    "        return kb_soup\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of article_kb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium.webdriver.common.by import By\n",
    "# import datacrew.crawler.crawler as dcc\n",
    "\n",
    "\n",
    "# TEST_ARTICLE_URL = \"https://domo-support.domo.com/s/article/360043429913/\"\n",
    "\n",
    "# BASE_URL = \"https://domo-support.domo.com\"\n",
    "# IMG_BASE_URL = \"https://domo-support.domo.com/servlet/rtaImage\"\n",
    "\n",
    "# driver = dcc.driversetup(is_headless=False)\n",
    "\n",
    "# test_article = Article_KB(url=TEST_ARTICLE_URL, driver=driver, base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test implementation of Article KB by path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_ARTICLE_PATH = \"../../raw_kb/article/beast_mode_fixed_functions/index.html\"\n",
    "\n",
    "# BASE_URL = \"https://domo-support.domo.com\"\n",
    "# IMG_BASE_URL = \"https://domo-support.domo.com/servlet/rtaImage\"\n",
    "\n",
    "# driver = dcc.driversetup(is_headless=False)\n",
    "\n",
    "# test_article = Article_KB(\n",
    "#     # url=TEST_ARTICLE_URL, \n",
    "#     path_html=TEST_ARTICLE_PATH, base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in test_article.__dict__.keys():\n",
    "#     if key in [\n",
    "#         \"soup\",\"article_soup\", \"driver\", \n",
    "#             #    \"md_str\"\n",
    "#                ]:\n",
    "#         continue\n",
    "#     print({key: getattr(test_article, key)})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article_Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@dataclass(init=False)\n",
    "class Article_Category(Article):\n",
    "    top_parent = None\n",
    "    parent = None\n",
    "\n",
    "    path_html : str = None\n",
    "\n",
    "    category: str = None\n",
    "    category_description: str = None\n",
    "\n",
    "    is_child_recursive: bool = True\n",
    "\n",
    "    md_str: str = field(default=None, repr=False)\n",
    "\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        url,\n",
    "        base_url,\n",
    "        url_entity_prefix=\"s/topic/\",\n",
    "        path_html: str = None,\n",
    "        driver=None,\n",
    "        child_category_ls=None,\n",
    "        child_article_ls=None,\n",
    "        is_child_recursive: bool = False,\n",
    "        debug_prn: bool = False,\n",
    "        parent=None,\n",
    "        top_parent=None\n",
    "    ):\n",
    "        self.parent = parent\n",
    "        self.top_parent = top_parent\n",
    "        self.path_html = path_html\n",
    "\n",
    "        self.is_child_recursive = is_child_recursive\n",
    "\n",
    "        soup = None\n",
    "\n",
    "        if path_html:\n",
    "            self.is_child_recursive = False\n",
    "            page_decoded = self.detect_encoding(path_html, debug_prn = debug_prn)\n",
    "\n",
    "            soup = BeautifulSoup(page_decoded, features=\"lxml\")\n",
    "\n",
    "        else:\n",
    "            if not driver:\n",
    "                driver = dcc.driversetup(is_headless=False)\n",
    "\n",
    "            soup = dcc.pagesource(\n",
    "                driver=driver,\n",
    "                url=url,\n",
    "                element_type=By.CLASS_NAME,\n",
    "                element_ls=[\"section-list-item\", \"article-list-item\"],\n",
    "                is_return_soup=True,\n",
    "            )\n",
    "\n",
    "        if not soup:\n",
    "            raise ArticleKB_GetSoupError(url=url)\n",
    "\n",
    "        super().__init__(\n",
    "            url=url,\n",
    "            base_url=base_url,\n",
    "            soup=soup,\n",
    "            url_entity_prefix=url_entity_prefix,\n",
    "            driver=driver,\n",
    "            child_category_ls=child_category_ls,\n",
    "            child_article_ls=child_article_ls,\n",
    "        )\n",
    "\n",
    "        self.article_soup = self.process_soup(soup, debug_prn=debug_prn)\n",
    "        self.is_success = True\n",
    "\n",
    "    def process_soup(self, soup: BeautifulSoup, debug_prn: bool = False):\n",
    "        if self.is_child_recursive:\n",
    "            self.top_parent = self.top_parent or self.parent or self\n",
    "            self.parent = self.parent or self\n",
    "\n",
    "        # process parent attributes\n",
    "\n",
    "        article_soup = soup.find(class_=[\"cDomoKBCategoryNav\"])\n",
    "\n",
    "        category_soup = article_soup.find(\"h1\")\n",
    "        self.category = category_soup.get_text()\n",
    "\n",
    "        category_description_soup = article_soup.find(\"p\")\n",
    "        self.category_description = (\n",
    "            category_description_soup and category_description_soup.get_text()\n",
    "        )\n",
    "\n",
    "        table_item_term = [\"section-list-item\", \"article-list-item\"]\n",
    "        table_soup = article_soup.find_all(class_=[table_item_term])\n",
    "\n",
    "        if not table_soup or table_soup == []:\n",
    "            raise ArticleKB_ProcessSoupError(\n",
    "                url=self.url, search_term=table_item_term)\n",
    "\n",
    "        # process children\n",
    "        for row in table_soup:\n",
    "\n",
    "            url = row.find(\"a\").get(\"href\")\n",
    "            if url[0] == \"/\":\n",
    "                url = url_parse.urljoin(self.base_url, url)\n",
    "\n",
    "            child_id = url.split(\"/\")[-1]\n",
    "\n",
    "            print(f\"❤️ child url - {url}, {child_id}\")\n",
    "\n",
    "            # update url recursively\n",
    "            self.add_url_to_ls(url)\n",
    "            self.parent and self.parent.add_url_to_ls(url)\n",
    "            self.top_parent and self.top_parent.add_url_to_ls(url)\n",
    "\n",
    "            if \"/s/article/\" in url:\n",
    "                self.add_child_article_to_ls(url)\n",
    "                self.parent and self.parent.add_child_article_to_ls(url)\n",
    "                self.top_parent and self.top_parent.add_child_article_to_ls(\n",
    "                    url)\n",
    "                continue\n",
    "\n",
    "            # if anything else\n",
    "            if not self.url_entity_prefix in url:\n",
    "                print(f'skipping {url}')\n",
    "                continue\n",
    "\n",
    "            # if category\n",
    "            child_obj = None\n",
    "\n",
    "            if self.is_child_recursive:\n",
    "\n",
    "                child_obj = Article_Category(\n",
    "                    url=url,\n",
    "                    base_url=self.base_url,\n",
    "                    url_entity_prefix=self.url_entity_prefix,\n",
    "                    driver=self.driver,\n",
    "                    child_article_ls=self.child_article_ls,\n",
    "                    child_category_ls=self.child_category_ls,\n",
    "                    top_parent=self.top_parent or None,\n",
    "                    parent=self.parent or None,\n",
    "                    is_child_recursive = self.is_child_recursive\n",
    "                )\n",
    "            \n",
    "            elif not self.path_html:\n",
    "                child_obj = Article_Category(\n",
    "                url=url,\n",
    "                base_url=self.base_url,\n",
    "                url_entity_prefix=self.url_entity_prefix,\n",
    "                driver=self.driver)\n",
    "\n",
    "            if child_obj:\n",
    "                self.add_child_category_to_ls(child_obj)\n",
    "                self.parent and self.parent.add_child_category_to_ls(child_obj)\n",
    "                self.top_parent and self.top_parent.add_child_category_to_ls(child_obj)\n",
    "        \n",
    "        self.md_str = self.md_soup(article_soup)\n",
    "\n",
    "        return {\n",
    "            \"category\": category_soup,\n",
    "            \"description\": category_description_soup,\n",
    "            \"children\": table_soup,\n",
    "        }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of article_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_TOPIC_URL = 'https://domo-support.domo.com/s/topic/0TO5w000000ZamoGAC'\n",
    "# # TEST_TOPIC_URL = \"https://domo-support.domo.com/s/topic/0TO5w000000ZanAGAS/beast-mode\"\n",
    "\n",
    "# BASE_URL = \"https://domo-support.domo.com\"\n",
    "\n",
    "# driver = dcc.driversetup(is_headless=False)\n",
    "\n",
    "# test_category = Article_Category(url=TEST_TOPIC_URL, driver=driver, base_url=BASE_URL, is_child_recursive= False, debug_prn= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_TOPIC_PATH = '../../raw_kb/category/analyzer/index.html'\n",
    "\n",
    "# BASE_URL = \"https://domo-support.domo.com\"\n",
    "\n",
    "# test_category = Article_Category(url=TEST_TOPIC_URL,\n",
    "#                                  path_html=TEST_TOPIC_PATH,\n",
    "#                                  base_url=BASE_URL, \n",
    "#                                  is_child_recursive=True, debug_prn=True)\n",
    "\n",
    "# test_category.md_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in test_category.__dict__.keys():\n",
    "#     if key in [\"soup\", \"article_soup\", \"driver\", \"md_str\"]:\n",
    "#         continue\n",
    "#     print({key: getattr(test_category, key)})\n",
    "\n",
    "# test_category.url_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@dataclass(init=False)\n",
    "class Article_KB_Home(Article):\n",
    "    category: str = None\n",
    "    category_description: str = None\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        url,\n",
    "        base_url,\n",
    "        url_entity_prefix=\"s/knowledge-base\",\n",
    "        path_html=None,\n",
    "        debug_prn: bool = False,\n",
    "        driver=None,\n",
    "    ):\n",
    "        soup = None\n",
    "\n",
    "        if path_html:\n",
    "            self.path_html = path_html\n",
    "            self.is_child_recursive = False\n",
    "            page_decoded = self.detect_encoding(path_html, debug_prn=debug_prn)\n",
    "\n",
    "            soup = BeautifulSoup(page_decoded, features=\"lxml\")\n",
    "\n",
    "        else:\n",
    "            if not driver:\n",
    "                driver = dcc.driversetup(is_headless=False)\n",
    "\n",
    "            soup = dcc.pagesource(\n",
    "                driver=driver,\n",
    "                url=url,\n",
    "                element_type=By.CLASS_NAME,\n",
    "                element_ls=[\"blocks-list\"],\n",
    "                is_return_soup=True,\n",
    "            )\n",
    "\n",
    "        if not soup:\n",
    "            raise ArticleKB_GetSoupError(url=url)\n",
    "\n",
    "        super().__init__(\n",
    "            url=url,\n",
    "            base_url=base_url,\n",
    "            soup=soup,\n",
    "            url_entity_prefix=url_entity_prefix,\n",
    "            driver=driver,\n",
    "        )\n",
    "\n",
    "        self.article_soup = self.process_soup(soup, debug_prn=debug_prn)\n",
    "        self.is_success = True\n",
    "\n",
    "    def process_soup(self, soup: BeautifulSoup, debug_prn: bool = False):\n",
    "        # process parent attributes\n",
    "\n",
    "        article_soup = soup.find(class_=[\"cDomoKBCategoryNav\"])\n",
    "\n",
    "        category_soup = article_soup.find(\"h1\")\n",
    "        self.category = category_soup.get_text()\n",
    "\n",
    "        category_description_soup = article_soup.find(\"p\")\n",
    "        self.category_description = (\n",
    "            category_description_soup and category_description_soup.get_text()\n",
    "        )\n",
    "\n",
    "        table_item_term = [\"blocks-item\"]\n",
    "        table_soup = article_soup.find_all(class_=[table_item_term])\n",
    "\n",
    "        if not table_soup or table_soup == []:\n",
    "            raise ArticleKB_ProcessSoupError(\n",
    "                url=self.url, search_term=table_item_term)\n",
    "\n",
    "        # process children\n",
    "        for row in table_soup:\n",
    "            url = row.find(\"a\").get(\"href\")\n",
    "            if url[0] == \"/\":\n",
    "                url = url_parse.urljoin(self.base_url, url)\n",
    "\n",
    "            child_id = url.split(\"/\")[-1]\n",
    "\n",
    "            print(f\"❤️ child url - {url}, {child_id}\")\n",
    "\n",
    "            self.add_url_to_ls(url)\n",
    "\n",
    "        self.get_images(\n",
    "            test_base_url=\"https://domo-support.domo.com/servlet/rtaImage\",\n",
    "            debug_prn=debug_prn,\n",
    "        )\n",
    "\n",
    "        self.md_str = self.md_soup(article_soup)\n",
    "\n",
    "        return {\n",
    "            \"category\": category_soup,\n",
    "            \"description\": category_description_soup,\n",
    "            \"children\": table_soup,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_HOME_URL = \"https://domo-support.domo.com/s/knowledge-base\"\n",
    "\n",
    "# BASE_URL = \"https://domo-support.domo.com\"\n",
    "\n",
    "# driver = dcc.driversetup(is_headless=False)\n",
    "\n",
    "# test_home = Article_KB_Home(url=TEST_HOME_URL, driver=driver, base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_home.child_category_ls\n",
    "# test_home.url_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 9696: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# | hide\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnbdev\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m nbdev\u001b[39m.\u001b[39;49mnbdev_export()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\fastcore\\script.py:110\u001b[0m, in \u001b[0;36mcall_parse.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_f\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    109\u001b[0m     mod \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetmodule(inspect\u001b[39m.\u001b[39mcurrentframe()\u001b[39m.\u001b[39mf_back)\n\u001b[1;32m--> 110\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mod: \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m SCRIPT_INFO\u001b[39m.\u001b[39mfunc \u001b[39mand\u001b[39;00m mod\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m: SCRIPT_INFO\u001b[39m.\u001b[39mfunc \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sys\u001b[39m.\u001b[39margv)\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m sys\u001b[39m.\u001b[39margv[\u001b[39m1\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m: sys\u001b[39m.\u001b[39margv\u001b[39m.\u001b[39mpop(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nbdev\\doclinks.py:140\u001b[0m, in \u001b[0;36mnbdev_export\u001b[1;34m(path, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m files: nb_export(f)\n\u001b[0;32m    139\u001b[0m add_init(get_config()\u001b[39m.\u001b[39mlib_path)\n\u001b[1;32m--> 140\u001b[0m _build_modidx()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nbdev\\doclinks.py:102\u001b[0m, in \u001b[0;36m_build_modidx\u001b[1;34m(dest, nbs_path, skip_exists)\u001b[0m\n\u001b[0;32m    100\u001b[0m code_root \u001b[39m=\u001b[39m dest\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mresolve()\n\u001b[0;32m    101\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m globtastic(dest, file_glob\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*.py\u001b[39m\u001b[39m\"\u001b[39m, skip_file_re\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m^_\u001b[39m\u001b[39m'\u001b[39m, skip_folder_re\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.ipynb_checkpoints\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 102\u001b[0m     res[\u001b[39m'\u001b[39m\u001b[39msyms\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mupdate(_get_modidx((dest\u001b[39m.\u001b[39;49mparent\u001b[39m/\u001b[39;49mfile)\u001b[39m.\u001b[39;49mresolve(), code_root, nbs_path\u001b[39m=\u001b[39;49mnbs_path))\n\u001b[0;32m    103\u001b[0m idxfile\u001b[39m.\u001b[39mwrite_text(\u001b[39m\"\u001b[39m\u001b[39m# Autogenerated by nbdev\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39md = \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mpformat(res, width\u001b[39m=\u001b[39m\u001b[39m140\u001b[39m, indent\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, compact\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nbdev\\doclinks.py:73\u001b[0m, in \u001b[0;36m_get_modidx\u001b[1;34m(py_path, code_root, nbs_path)\u001b[0m\n\u001b[0;32m     71\u001b[0m _def_types \u001b[39m=\u001b[39m ast\u001b[39m.\u001b[39mFunctionDef,ast\u001b[39m.\u001b[39mAsyncFunctionDef,ast\u001b[39m.\u001b[39mClassDef\n\u001b[0;32m     72\u001b[0m d \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> 73\u001b[0m \u001b[39mfor\u001b[39;00m cell \u001b[39min\u001b[39;00m _iter_py_cells(py_path):\n\u001b[0;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m cell\u001b[39m.\u001b[39mnb \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     loc \u001b[39m=\u001b[39m _nbpath2html(cell\u001b[39m.\u001b[39mnb_path\u001b[39m.\u001b[39mrelative_to(nbs_path))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nbdev\\doclinks.py:49\u001b[0m, in \u001b[0;36m_iter_py_cells\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mYield cells from an exported Python file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m p \u001b[39m=\u001b[39m Path(p)\n\u001b[1;32m---> 49\u001b[0m cells \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mread_text()\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m# \u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[39mfor\u001b[39;00m cell \u001b[39min\u001b[39;00m cells[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m     51\u001b[0m     top,code \u001b[39m=\u001b[39m cell\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1008.0_x64__qbz5n2kfra8p0\\Lib\\pathlib.py:1059\u001b[0m, in \u001b[0;36mPath.read_text\u001b[1;34m(self, encoding, errors)\u001b[0m\n\u001b[0;32m   1057\u001b[0m encoding \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m   1058\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopen(mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m-> 1059\u001b[0m     \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1008.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39mcharmap_decode(\u001b[39minput\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors,decoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 9696: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b43e631a983881eee635638ba8d16a40e1a13e8bbb48ce0aff152a316858538a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
