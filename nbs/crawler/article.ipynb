{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Article\n",
    "description: class based approach to webcrawling\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp crawler.article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# use with local installs that don't have nbdev\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "import datetime as dt\n",
    "from dataclasses import dataclass, field\n",
    "import urllib.parse as url_parse\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium.webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# from fastcore.basics import patch_to\n",
    "\n",
    "import markdownify as md\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "import datacrew.crawler.crawler as dcc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@dataclass\n",
    "class Article:\n",
    "    url: str\n",
    "    base_url: str\n",
    "    entity_base_url: str = None\n",
    "\n",
    "    url_entity_prefix: str = None\n",
    "    url_id: str = None\n",
    "\n",
    "\n",
    "    driver: selenium.webdriver = field(repr=False, default=None)\n",
    "    soup: BeautifulSoup = field(repr=False, default=None)\n",
    "    article_soup: BeautifulSoup = field(repr=False, default=None)\n",
    "\n",
    "    is_success: bool = False\n",
    "\n",
    "    url_ls: list[str] = field(default_factory= lambda : [])\n",
    "    image_ls: list[str] = field(default_factory= lambda : [])\n",
    "\n",
    "    child_category_ls: list[dict] = field(default_factory=lambda : [])\n",
    "    child_article_ls: list[dict] = field(default_factory= lambda: [])\n",
    "\n",
    "    def __post_init__(self):    \n",
    "        if self.url_entity_prefix and self.url_entity_prefix[0] != \"/\":\n",
    "            self.url_entity_prefix = f\"/{self.url_entity_prefix}\"\n",
    "\n",
    "        if self.url_entity_prefix and self.url_entity_prefix in self.base_url:\n",
    "            self.base_url = self.base_url.replace(self.url_entity_prefix, \"\")\n",
    "\n",
    "        self.entity_base_url = url_parse.urljoin(self.base_url, self.url_entity_prefix or '')\n",
    "\n",
    "        self.set_id()\n",
    "\n",
    "        self.get_urls()\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return  (self.url_id == other.url_id) or (self.url ==other.url)\n",
    "\n",
    "    # @classmethod\n",
    "    # def get_from_url(\n",
    "    #     cls,\n",
    "    #     url: str,\n",
    "    #     driver: selenium.webdriver,\n",
    "    #     base_url: str,\n",
    "    #     url_entity_prefix: str = None,\n",
    "    #     element_type=By.CLASS_NAME,\n",
    "    #     element_id=\"slds-form-element\",\n",
    "    # ):\n",
    "\n",
    "    #     soup = dcc.pagesource(\n",
    "    #         driver=driver,\n",
    "    #         url=url,\n",
    "    #         element_type=element_type,\n",
    "    #         element_id=element_id,\n",
    "    #     )\n",
    "\n",
    "    #     return cls(\n",
    "    #         url=url,\n",
    "    #         url_entity_prefix=url_entity_prefix,\n",
    "    #         base_url=base_url,\n",
    "    #         soup=soup,\n",
    "    #         driver=driver,\n",
    "    #     )\n",
    "\n",
    "    @staticmethod\n",
    "    def md_soup(soup, **options):\n",
    "        return md.MarkdownConverter(**options).convert_soup(soup)\n",
    "\n",
    "    def add_url_to_ls(self, url, is_remove_query_string_parameters: bool = True, debug_prn: bool = False):\n",
    "\n",
    "        _old_url_ls = self.url_ls\n",
    "\n",
    "        if url.startswith(\"/\") and self.url_entity_prefix in url:\n",
    "            url = url_parse.urljoin(self.base_url, url)\n",
    "\n",
    "        if is_remove_query_string_parameters:\n",
    "            url = url_parse.urljoin(url, url_parse.urlparse(url).path)\n",
    "\n",
    "        if not url.startswith(self.base_url):\n",
    "            if debug_prn:\n",
    "                print(f\"not adding {url}\")\n",
    "            return self.url_ls\n",
    "\n",
    "        if url.endswith(\"/\"):\n",
    "            url = url[:-1]\n",
    "\n",
    "        if url.split(\"/\")[-4] == \"s\":\n",
    "            url = \"/\".join(url.split(\"/\")[:-1])\n",
    "\n",
    "        if url not in self.url_ls:\n",
    "            if debug_prn:\n",
    "                print(f\"{_old_url_ls} adding {url} to {self.url} list\")\n",
    "            self.url_ls.append(url)\n",
    "        \n",
    "        return self.url_ls\n",
    "\n",
    "    def get_urls(self, soup = None):\n",
    "        soup = soup or self.soup\n",
    "        if not soup:\n",
    "            return\n",
    "\n",
    "        for soup_link in soup.find_all(\"a\"):\n",
    "            url = soup_link.get(\"href\")\n",
    "\n",
    "            if not url:\n",
    "                continue\n",
    "\n",
    "            self.add_url_to_ls(url)\n",
    "        return self.url_ls\n",
    "\n",
    "    def set_id(self):\n",
    "        o = self.url.replace(self.entity_base_url, \"\")\n",
    "        self.url_id = o.split(\"/\")[0]\n",
    "        self.url = url_parse.urljoin(self.entity_base_url, self.url_id)\n",
    "        return self.url_id\n",
    "\n",
    "    def get_images(\n",
    "        self,\n",
    "        soup=None,  # pass a soup to just exctract images from the selected content.  Default will exctract all images on the page\n",
    "        test_base_url: str = None,  # pass to limit URLs to a specific base\n",
    "        debug_prn: bool = False,\n",
    "    ):\n",
    "        \"extract image urls from soup\"\n",
    "\n",
    "        soup = soup or self.soup\n",
    "\n",
    "        self.image_ls = [\n",
    "            {\n",
    "                \"url\": f\"{self.base_url if item.get('src').startswith('/') else ''}{item.get('src')}\",\n",
    "                \"relative_url\": item.get(\"src\"),\n",
    "                \"name\": item.get(\"alt\"),\n",
    "            }\n",
    "            for item in soup.find_all(\"img\")\n",
    "            if item.get(\"src\", False)\n",
    "        ]\n",
    "\n",
    "        if test_base_url:\n",
    "            self.image_ls = [\n",
    "                img for img in self.image_ls if img.get(\"url\").startswith(test_base_url)\n",
    "            ]\n",
    "\n",
    "        if debug_prn:\n",
    "            print(self.image_ls)\n",
    "        return self.image_ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'child_category_ls': []}\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import datacrew.crawler.crawler as dcc\n",
    "\n",
    "TEST_URL = \"https://domo-support.domo.com/s/article/360043429913/\"\n",
    "\n",
    "BASE_URL = \"https://domo-support.domo.com\"\n",
    "IMG_BASE_URL = \"https://domo-support.domo.com/servlet/rtaImage\"\n",
    "\n",
    "driver = dcc.driversetup(is_headless=False)\n",
    "\n",
    "test_article = Article(url=TEST_URL, driver=driver, base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class ArticleKB_GetSoupError(Exception):\n",
    "    def __init__(self, url):\n",
    "        super().__init__(f\"failed to retrieve soup for {url}\")\n",
    "\n",
    "\n",
    "class ArticleKB_ProcessSoupError(Exception):\n",
    "    def __init__(self, url, search_term):\n",
    "        super().__init__(f\"search term {search_term} does not exist in {url}\")\n",
    "\n",
    "\n",
    "@dataclass(init=False)\n",
    "class Article_KB(Article):\n",
    "    title: str = None\n",
    "    md_str: str = field(default=None, repr=False)\n",
    "    views: int = None\n",
    "    created: dt.date = None\n",
    "    last_updated: dt.date = None\n",
    "    article_id: str = None\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        url,\n",
    "        base_url,\n",
    "        driver,\n",
    "        child_category_ls=None,\n",
    "        child_article_ls=None,\n",
    "\n",
    "\n",
    "        url_entity_prefix=\"/s/article/\",\n",
    "        debug_prn: bool = False,\n",
    "    ):\n",
    "        self.url = url\n",
    "        self.base_url = base_url\n",
    "\n",
    "        soup = dcc.pagesource(\n",
    "            driver=self.driver,\n",
    "            url=self.url,\n",
    "            element_type=By.CLASS_NAME,\n",
    "            element_id=\"slds-form-element\",\n",
    "            is_return_soup=True,\n",
    "        )\n",
    "\n",
    "        super().__init__(\n",
    "            url=url,\n",
    "            base_url=base_url,\n",
    "            soup=soup,\n",
    "            url_entity_prefix=url_entity_prefix,\n",
    "            driver=driver,\n",
    "            child_category_ls=child_category_ls,\n",
    "            child_article_ls=child_article_ls,\n",
    "\n",
    "        )\n",
    "\n",
    "        if not soup:\n",
    "            raise ArticleKB_GetSoupError(url=self.url)\n",
    "\n",
    "        self.article_soup = self.process_soup(soup, debug_prn=debug_prn)\n",
    "        self.is_success = True\n",
    "\n",
    "    def process_soup(self, soup: BeautifulSoup, debug_prn: bool = False):\n",
    "        search_term = \"slds-form-element\"\n",
    "\n",
    "        table = soup.find_all(class_=[search_term])\n",
    "\n",
    "        if not table or table == []:\n",
    "            raise ArticleKB_ProcessSoupError(\n",
    "                url=self.url, search_term=search_term)\n",
    "\n",
    "        tarticle = []\n",
    "        for row in table:\n",
    "            # print(\"‚ù§Ô∏è\")\n",
    "\n",
    "            cells = row.find(class_=\"slds-form-element__label\")\n",
    "\n",
    "            if list(cells.strings):\n",
    "                content = row.find(class_=\"slds-form-element__control\")\n",
    "                tarticle.append((list(cells.strings)[0], content))\n",
    "\n",
    "        kb_soup = dict(tarticle)\n",
    "\n",
    "        self.title = self.md_soup(kb_soup.get(\"Title\"))\n",
    "        self.md_str = self.md_soup(kb_soup.get(\"Article Body\"))\n",
    "        self.article_id = self.md_soup(kb_soup.get(\"Article Number\"))\n",
    "        self.views = self.md_soup(kb_soup.get(\"Article Total View Count\"))\n",
    "        self.created = parser.parse(self.md_soup(\n",
    "            kb_soup.get(\"Article Created Date\")))\n",
    "\n",
    "        self.last_updated = parser.parse(\n",
    "            self.md_soup(kb_soup.get(\"First Published Date\"))\n",
    "        )\n",
    "\n",
    "        self.get_images(\n",
    "            test_base_url=\"https://domo-support.domo.com/servlet/rtaImage\",\n",
    "            debug_prn=debug_prn,\n",
    "        )\n",
    "\n",
    "        return kb_soup\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of article_kb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí§ retrieving https://domo-support.domo.com/s/article/360043429913/ üí§\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m IMG_BASE_URL \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://domo-support.domo.com/servlet/rtaImage\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m driver \u001b[39m=\u001b[39m dcc\u001b[39m.\u001b[39mdriversetup(is_headless\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 12\u001b[0m test_article \u001b[39m=\u001b[39m Article_KB(url\u001b[39m=\u001b[39;49mTEST_ARTICLE_URL, driver\u001b[39m=\u001b[39;49mdriver, base_url\u001b[39m=\u001b[39;49mBASE_URL)\n",
      "Cell \u001b[1;32mIn[8], line 44\u001b[0m, in \u001b[0;36mArticle_KB.__init__\u001b[1;34m(self, url, base_url, driver, child_category_ls, child_article_ls, url_entity_prefix, debug_prn)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_url \u001b[39m=\u001b[39m base_url\n\u001b[0;32m     36\u001b[0m soup \u001b[39m=\u001b[39m dcc\u001b[39m.\u001b[39mpagesource(\n\u001b[0;32m     37\u001b[0m     driver\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdriver,\n\u001b[0;32m     38\u001b[0m     url\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     is_return_soup\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     42\u001b[0m )\n\u001b[1;32m---> 44\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     45\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m     46\u001b[0m     base_url\u001b[39m=\u001b[39;49mbase_url,\n\u001b[0;32m     47\u001b[0m     soup\u001b[39m=\u001b[39;49msoup,\n\u001b[0;32m     48\u001b[0m     url_entity_prefix\u001b[39m=\u001b[39;49murl_entity_prefix,\n\u001b[0;32m     49\u001b[0m     driver\u001b[39m=\u001b[39;49mdriver,\n\u001b[0;32m     50\u001b[0m     child_category_ls\u001b[39m=\u001b[39;49mchild_category_ls,\n\u001b[0;32m     51\u001b[0m     child_article_ls\u001b[39m=\u001b[39;49mchild_article_ls,\n\u001b[0;32m     52\u001b[0m \n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m soup:\n\u001b[0;32m     56\u001b[0m     \u001b[39mraise\u001b[39;00m ArticleKB_GetSoupError(url\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl)\n",
      "File \u001b[1;32m<string>:12\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, url, base_url, entity_base_url, url_entity_prefix, url_id, driver, soup, article_soup, is_success, url_ls, image_ls, child_category_ls, child_article_ls)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import datacrew.crawler.crawler as dcc\n",
    "\n",
    "\n",
    "TEST_ARTICLE_URL = \"https://domo-support.domo.com/s/article/360043429913/\"\n",
    "\n",
    "BASE_URL = \"https://domo-support.domo.com\"\n",
    "IMG_BASE_URL = \"https://domo-support.domo.com/servlet/rtaImage\"\n",
    "\n",
    "driver = dcc.driversetup(is_headless=False)\n",
    "\n",
    "test_article = Article_KB(url=TEST_ARTICLE_URL, driver=driver, base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in test_article.__dict__.keys():\n",
    "    if key in [\"soup\", \"article_soup\", \"driver\", \"md_str\"]:\n",
    "        continue\n",
    "    print({key: getattr(test_article, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@dataclass(init=False)\n",
    "class Article_Category(Article):\n",
    "\n",
    "    category: str = None\n",
    "    category_description: str = None\n",
    "\n",
    "    is_child_recursive: bool = True\n",
    "\n",
    "    child_category_ls: list[dict] = field(default_factory=[])\n",
    "    child_article_ls: list[dict] = field(default_factory=[])\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        url,\n",
    "        base_url,\n",
    "        url_entity_prefix=\"s/topic/\",\n",
    "        driver=None,\n",
    "        child_category_ls=None,\n",
    "        child_article_ls=None,\n",
    "        is_child_recursive: bool = False,\n",
    "        debug_prn: bool = False,\n",
    "    ):\n",
    "\n",
    "        self.child_article_ls = child_article_ls or []\n",
    "        self.child_category_ls = child_category_ls or []\n",
    "        self.is_child_recursive = is_child_recursive\n",
    "\n",
    "        if not driver:\n",
    "            driver = dcc.driversetup(is_headless=False)\n",
    "\n",
    "        soup = dcc.pagesource(\n",
    "            driver=driver,\n",
    "            url=url,\n",
    "            element_type=By.CLASS_NAME,\n",
    "            element_ls=[\"section-list-item\", \"article-list-item\"],\n",
    "            is_return_soup=True,\n",
    "        )\n",
    "\n",
    "        if not soup:\n",
    "            raise ArticleKB_GetSoupError(url=url)\n",
    "\n",
    "        super().__init__(\n",
    "            url=url,\n",
    "            base_url=base_url,\n",
    "            soup=soup,\n",
    "            url_entity_prefix=url_entity_prefix,\n",
    "            driver=driver,\n",
    "            child_category_ls=child_category_ls,\n",
    "            child_article_ls=child_article_ls,\n",
    "\n",
    "        )\n",
    "\n",
    "        self.article_soup = self.process_soup(soup, debug_prn=debug_prn)\n",
    "        self.is_success = True\n",
    "\n",
    "        \n",
    "    def process_soup(self, soup: BeautifulSoup, debug_prn: bool = False):\n",
    "        # process parent attributes\n",
    "\n",
    "        article_soup = soup.find(class_=[\"cDomoKBCategoryNav\"])\n",
    "\n",
    "        category_soup = article_soup.find(\"h1\")\n",
    "        self.category = category_soup.get_text()\n",
    "\n",
    "        category_description_soup = article_soup.find(\"p\")\n",
    "        self.category_description = (\n",
    "            category_description_soup and category_description_soup.get_text()\n",
    "        )\n",
    "\n",
    "        table_item_term = [\"section-list-item\", \"article-list-item\"]\n",
    "        table_soup = article_soup.find_all(class_=[table_item_term])\n",
    "\n",
    "        if not table_soup or table_soup == []:\n",
    "            raise ArticleKB_ProcessSoupError(url=self.url, search_term=table_item_term)\n",
    "\n",
    "        # process children\n",
    "        for row in table_soup:\n",
    "            url = row.find(\"a\").get(\"href\")\n",
    "            if url[0] == \"/\":\n",
    "                url = url_parse.urljoin(self.base_url, url)\n",
    "            \n",
    "\n",
    "            child_id = url.split(\"/\")[-1]\n",
    "\n",
    "            print(f\"‚ù§Ô∏è child url - {url}, {child_id}\")\n",
    "            print(self.add_url_to_ls(url, debug_prn = True))\n",
    "\n",
    "            # if article\n",
    "            if \"/s/article/\" in url:\n",
    "                self.child_article_ls.append(url)\n",
    "                continue\n",
    "\n",
    "            # if anything else\n",
    "            if self.url_entity_prefix not in url:\n",
    "                continue\n",
    "\n",
    "            # if category\n",
    "            if (\n",
    "                self.url_entity_prefix in url\n",
    "                and child_id not in self.crawl_category_id_ls\n",
    "            ):\n",
    "                self.crawl_category_id_ls.append(child_id)\n",
    "\n",
    "                child_obj = {\"category\": row.get_text(), \"id\": child_id, \"url\": url}\n",
    "\n",
    "                if self.is_child_recursive and self.url_entity_prefix in url:\n",
    "\n",
    "                    child_obj.update(\n",
    "                        {\n",
    "                            \"child_article\": Article_Category(\n",
    "                                url=url,\n",
    "                                base_url=self.base_url,\n",
    "                                crawl_category_id_ls=self.crawl_category_id_ls,\n",
    "                                url_entity_prefix=self.url_entity_prefix,\n",
    "                                driver=self.driver,\n",
    "                            )\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                self.child_category_ls.append(child_obj)\n",
    "\n",
    "        return {\n",
    "            \"category\": category_soup,\n",
    "            \"description\": category_description_soup,\n",
    "            \"children\": table_soup,\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of article_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TOPIC_URL = 'https://domo-support.domo.com/s/topic/0TO5w000000ZamoGAC'\n",
    "# TEST_TOPIC_URL = \"https://domo-support.domo.com/s/topic/0TO5w000000ZanAGAS/beast-mode\"\n",
    "\n",
    "BASE_URL = \"https://domo-support.domo.com\"\n",
    "\n",
    "IMG_BASE_URL = \"https://domo-support.domo.com/servlet/rtaImage\"\n",
    "\n",
    "OUTPUT_FOLDER = \"../../raw_kb\"\n",
    "\n",
    "driver = dcc.driversetup(is_headless=False)\n",
    "\n",
    "test_category = Article_Category(url=TEST_TOPIC_URL, driver=driver, base_url=BASE_URL, is_child_recursive= True, debug_prn= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_category.url_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@dataclass(init=False)\n",
    "class Article_KB_Home(Article):\n",
    "\n",
    "    category: str = None\n",
    "    category_description: str = None\n",
    "\n",
    "    is_child_recursive: bool = True\n",
    "    crawl_category_id_ls: [str] = field(default=None)\n",
    "\n",
    "    child_category_ls: list[dict] = field(default_factory=[])\n",
    "    child_article_ls: list[dict] = field(default_factory=[])\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        url,\n",
    "        base_url,\n",
    "        url_entity_prefix=\"s/knowledge-base\",\n",
    "        crawl_category_id_ls=None,\n",
    "        debug_prn: bool = False,\n",
    "        driver=None,\n",
    "        is_child_recursive: bool = False,\n",
    "    ):\n",
    "\n",
    "        self.child_article_ls = []\n",
    "        self.child_category_ls = []\n",
    "        self.crawl_category_id_ls = crawl_category_id_ls or []\n",
    "        self.is_child_recursive = is_child_recursive\n",
    "\n",
    "        if not driver:\n",
    "            driver = dcc.driversetup(is_headless=False)\n",
    "\n",
    "        soup = dcc.pagesource(\n",
    "            driver=driver,\n",
    "            url=url,\n",
    "            element_type=By.CLASS_NAME,\n",
    "            element_ls=[\"blocks-list\"],\n",
    "            is_return_soup=True,\n",
    "        )\n",
    "\n",
    "        if not soup:\n",
    "            raise ArticleKB_GetSoupError(url=url)\n",
    "\n",
    "        super().__init__(\n",
    "            url=url,\n",
    "            base_url=base_url,\n",
    "            soup=soup,\n",
    "            url_entity_prefix=url_entity_prefix,\n",
    "            driver=driver,\n",
    "        )\n",
    "\n",
    "        self.article_soup = self.process_soup(soup, debug_prn=debug_prn)\n",
    "        self.is_success = True\n",
    "\n",
    "        \n",
    "    def process_soup(self, soup: BeautifulSoup, debug_prn: bool = False):\n",
    "        # process parent attributes\n",
    "\n",
    "        article_soup = soup.find(class_=[\"cDomoKBCategoryNav\"])\n",
    "\n",
    "        category_soup = article_soup.find(\"h1\")\n",
    "        self.category = category_soup.get_text()\n",
    "\n",
    "        category_description_soup = article_soup.find(\"p\")\n",
    "        self.category_description = (\n",
    "            category_description_soup and category_description_soup.get_text()\n",
    "        )\n",
    "\n",
    "        table_item_term = [\"blocks-item\"]\n",
    "        table_soup = article_soup.find_all(class_=[table_item_term])\n",
    "\n",
    "        if not table_soup or table_soup == []:\n",
    "            raise ArticleKB_ProcessSoupError(url=self.url, search_term=table_item_term)\n",
    "\n",
    "        # process children\n",
    "        for row in table_soup:\n",
    "            url = row.find(\"a\").get(\"href\")\n",
    "            if url[0] == \"/\":\n",
    "                url = url_parse.urljoin(self.base_url, url)\n",
    "\n",
    "            child_id = url.split(\"/\")[-1]\n",
    "\n",
    "            print(f\"‚ù§Ô∏è child url - {url}, {child_id}\")\n",
    "\n",
    "            self.add_url_to_ls(url)\n",
    "\n",
    "            # if article\n",
    "            if \"/s/article/\" in url:\n",
    "                self.child_article_ls.append(url)\n",
    "                continue\n",
    "\n",
    "            # if anything else\n",
    "            if '/s/topic/' in url and child_id not in self.crawl_category_id_ls : \n",
    "            \n",
    "                self.crawl_category_id_ls.append(child_id)\n",
    "\n",
    "                child_obj = {\"category\": row.get_text(), \"id\": child_id, \"url\": url}\n",
    "\n",
    "                if self.is_child_recursive and self.url_entity_prefix in url:\n",
    "\n",
    "                    child_obj.update(\n",
    "                        {\n",
    "                            \"child_article\": Article_Category(\n",
    "                                url=url,\n",
    "                                base_url=self.base_url,\n",
    "                                crawl_category_id_ls=self.crawl_category_id_ls,\n",
    "                                url_entity_prefix=self.url_entity_prefix,\n",
    "                                driver=self.driver,\n",
    "                            )\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                self.child_category_ls.append(child_obj)\n",
    "\n",
    "        return {\n",
    "            \"category\": category_soup,\n",
    "            \"description\": category_description_soup,\n",
    "            \"children\": table_soup,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_HOME_URL = \"https://domo-support.domo.com/s/knowledge-base\"\n",
    "\n",
    "BASE_URL = \"https://domo-support.domo.com\"\n",
    "\n",
    "IMG_BASE_URL = \"https://domo-support.domo.com/servlet/rtaImage\"\n",
    "\n",
    "OUTPUT_FOLDER = \"../../raw_kb\"\n",
    "\n",
    "driver = dcc.driversetup(is_headless=False)\n",
    "\n",
    "test_home = Article_KB_Home(url=TEST_HOME_URL, driver=driver, base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_home.child_category_ls\n",
    "test_home.url_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b43e631a983881eee635638ba8d16a40e1a13e8bbb48ce0aff152a316858538a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
