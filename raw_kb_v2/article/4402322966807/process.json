{"file_path": "../../raw_kb_v2\\article\\4402322966807\\index.html", "content": {"title": "\n\n\n Register Snowflake with Cloud Amplifier\n\n\n", "article_body": "\n\nIntro\n-------\n\nWith Cloud Amplifier, you can power your Domo instance using Snowflake.\n\n\n This article assumes you\n\n\n are familiar with Snowflake and provides information on how to register Snowflake with Cloud Amplifier in the following topics:\n\n Prerequisites\n* Read-only setup\n* Write setup\n* Use Snowflake-sourced DataSets\n* FAQ\n* Troubleshooting\n\nPrerequisites\n-----------------\n\nCloud Amplifier setup consists of two parts: Read-only or Read/Write.\n\n\n After the Read-only setup is complete, you may begin using virtual tables that read from Snowflake to create cards, set up Alerts, or serve as inputs in Magic ETL flows. You can set up Read only and return later to set up the Write portion.\n\n##\n Recommended Account Creation - All\n\nBefore setting up the Snowflake connection, we strongly recommend that you complete the following:\n\n **(Recommended) \u200bCreate a Snowflake service account \u2014**\n We recommend creating a new Snowflake account specifically for this integration. You can use any account with read access in Snowflake,\u00a0but a service account is best practice.\u00a0This account must have read\u00a0access to your default Snowflake environment in order to create virtual Snowflake tables in Domo.\n* **(Recommended) Create a Domo service account \u2014**\n We recommend creating a new Domo account specifically for this integration. The account role must have the Manage Cloud Accounts and Manage DataSet grants enabled.\n\nFor more information about roles and grants, see our article about\n\nManaging Custom Roles.\n\n\n###\n Account Creation - Write\n\nBefore registering with Cloud Amplifier for the Write portion of the setup, you must complete the following:\n\n **(Required) Create a default Snowflake database \u2014**\n You need a Snowflake database that is exclusively for Domo to write Domo-managed tables. During setup, this database is the default.\n\n*Note:**\n Any tables not managed by Domo in this database will not be seen by Cloud Amplifier.\n\n\n* **(Conditional) Place IP Addresses on an allowlist \u2014**\n If your Snowflake environment restricts access based on IP address, you may need to place Domo IPs on an allowlist.\n\nFor more information, see our article about\n\nAllowlisting IP Addresses for Connectors and Federated Adapters\n\n.\n\n*Important:**\n During the Write setup process, you are provided with SQL statements to create the integration. These statements must be executed against your Snowflake environment by a Snowflake administrator with the ACCOUNTADMIN role.\n\nThis is a Snowflake requirement and prevents the need to\u00a0manage your Snowflake administrator credentials within Domo, which is especially important in larger organizations where your Snowflake administrator may not have Domo access. After the integration is established, you no longer need a Snowflake administrator account.\n\nRead-only Setup\n-------------------\n\nTo set up Read-only access and\n\nto\n\nbegin referencing Snowflake tables from within Domo using Cloud Amplifier, follow these steps:\n\n. Log in to your Domo service account.\n2. In the navigation header, select\n **Data**\n .\n\n\n The Data Center displays.\n3. If you are not already there, go to the\n\n*Data Warehouse**\n in the side rail.\n4. In the warehouse area of the screen, select the molecule shown below.\n\n\n Selecting the molecule brings it\n\n\n into focus.\n5. Select\n **Add New Cloud**\n .\n\n\n The Amplify modal displays.\n6. In the modal under\n **Native integration**\n , select\n **Snowflake**\n .\n\n\n The\n **Cloud integrations**\n modal displays.\n7. Select\n **+ Add New Integration**\n .\n8. Enter the Snowflake setup information:\n\t* **Integration name**\n\t \u2014\u00a0A unique name to help you identify the integration in Domo.\n\t* (Optional)\n\t **Integration description**\n\t \u2014\u00a0A description of\u00a0the integration.\n\t* **Snowflake\u00a0connection URL**\n\t \u2014\u00a0This is your Snowflake URL,\n\n\n\t which you can find\n\n\n\t on the Snowflake login page. The URL is in this format:\n\t *instancename.region*\n\t .snowflakecomputing.com.\n\t* **Username/password**\n\t \u2014\u00a0The credentials for the Snowflake service account that you created.\n9. Select the Snowflake warehouse to use for loading and/or querying data.\n10. Read-only configuration is now complete. Continue to the next step to add Snowflake data to Domo.\n11. (Optional)\u00a0Select\n **Choose Data Tables**\n to create\u00a0DataSets in Domo.\n\n\n The modal displays navigation for databases, schemas, and tables\u00a0in Snowflake that you want to add to Domo. Locate and select the data you want to add and select\n **Create DataSets**\n .\n\nWrite Setup\n---------------\n\nRegistering with Cloud Amplifier for write capabilities is a multi-step process that requires a Snowflake administrator.\n\n\n The following graphic displays the process to register a Snowflake instance with Cloud Amplifier:\n\n\n Follow these steps to configure write capabilities:\n 1. Enter the name of the\n **Default Role**\n that you assigned to the Snowflake service account and the\n **Snowflake write database name**\n .\n\nThe\n **Snowflake write database name**\n is the default Snowflake database to which all new data coming from Domo\u00a0is added. The name is\u00a0case\n\n\n sensitive,\n\n\n and each letter should be capitalized.\n2. Select\n **Generate SQL**\n to generate SQL unique to this integration.\n\n*Important:**\n You cannot use this SQL\u00a0for other integrations or accounts and you must regenerate it\u00a0if the credentials are changed.\n3. Copy the SQL from the dialog and execute the SQL against your Snowflake warehouse. This SQL can only be executed by a Snowflake account administrator with the ACCOUNTADMIN role.\n\n\n The output of that SQL is a CSV file description of the integration that includes IDs required by Domo to continue setup.\n4. Copy the following values from the SQL output:\n\t* **User ARN**\n\t :\n\n STORAGE\\_AWS\\_IAM\\_USER\\_ARN\n\t* **External ID**\n\t : STORAGE\\_AWS\\_EXTERNAL\\_ID\n\n\n\t Additional SQL is generated to register the ARN and External ID with Domo. A Snowflake administrator with the ACCOUNTADMIN role must execute this SQL against the warehouse you selected for storing data earlier in this process.\n5. In Domo, confirm that the script successfully executed.\n\n\n Domo then initializes\u00a0the Snowflake integration, creates required assets in Snowflake, such as tables and schemas, and enables Cloud Amplifier for this account.\n6. Finalize the write integration by checking the box to acknowledge that you understand that\u00a0Domo can make changes to your Snowflake environment.\n7. Select\n **Apply**\n .\n\n\n When you see the\n **Select Snowflake tables**\n screen, your connection is working.\n8. (Optional) The modal displays navigation for databases, schemas, and tables\u00a0in Snowflake that you want to add to Domo. Locate and select the data you want to add and select\n **Create DataSets**\n .\n\n\n Write setup for Snowflake is now complete.\n\nUse Snowflake-sourced DataSets\n----------------------------------\n\nWhen you use Snowflake-sourced DataSets in a DataFlow, the data is queried live from Snowflake at the time the flow is executed. In addition, Snowflake-sourced DataSets are checked for updates every 15 minutes based on the table's\n\nLAST\\_ALTERED\n\nDateTime. If a table has been updated since it was last checked, DataFlows that use that table as a trigger will execute.\n\n\n FAQ\n-------\n\n*Are there requirements for database configuration (outside of Domo) or best practices?**\n\n\n Make sure to create a dedicated database inside Snowflake for your Domo integration. If you connect to an existing Snowflake database, then Domo does not see the tables that are in that database.\n\n\n**What is the guidance around warehouse configuration in Snowflake for Cloud Amplifier?**\n\n\n Domo performs different activities within the CDW account, such as data loading and\u00a0querying. For proof of concepts\u00a0and initial testing, we recommend a small-sized multi-cluster warehouse (multi-purpose for load\u00a0and query) set to scale up automatically. You can set a limit on the\n\n\n max cluster size to put an upper bound on scaling and\u00a0limit the cost envelope.\n\n\n When you are ready for production data, we recommend setting up warehouses depending on the purpose. Using separate warehouses for querying and loading allows you to optimize performance as needed.\n\n\n**How do I use data transformation on my Snowflake data?**\n\n\n With your data in Snowflake, Domo supports two different mechanisms for transforming data:\n\n. **DataSet Views**\n \u2014\u00a0DataSet Views provide\n\n\n the Views Explorer tool to create data transformations on your Snowflake DataSets. You can perform operations such as filtering, grouping/aggregation,\u00a0JOINs, UNIONs, and creating calculated columns from a graphic user interface. DataSet Views are created as virtual DataSets, with\u00a0queries sent back to the parent DataSets.\n\n*Note:**\n Creating a DataSet View in Domo does not create a View (normal or materialized) in Snowflake. The View definition is stored in Domo, and the resulting query is sent to Snowflake table(s) when needed.\n2. **Magic ETL DataFlows**\n \u2014\u00a0Magic ETL is\u00a0supported with Domo running on the customer's CDW. Using Magic ETL with Snowflake data results in data being exported from\u00a0Snowflake to\u00a0Magic ETL\u00a0in a transient state, processed, and written back to Snowflake.\u00a0Note that Domo only operates on this data in a transient fashion and does not store DataFlow outputs in Domo. (They are sent to the Snowflake warehouse.)\n\n*Note:**\n Data is cached in the Magic ETL execution environment for seven days, or the two most recent data versions from that Magic ETL execution.\n\n*What is the difference between Domo-managed and customer-managed Snowflake DataSets?**\n\n\n When you connect Domo to your Snowflake account, Domo operates over two classes of databases and underlying tables. Tables you create and update directly through independent pipelines or ingestion mechanisms can be explored and registered in Domo, accessible in a read-only fashion. Domo can read and directly query these customer-managed databases.\n\n\n Additionally, we recommend creating a new database in Domo for Read/Write access. Domo uses this Domo-managed database to write data that comes\n\n\n in through the Domo ingestion pipeline,\u00a0such as with the thousands of connectors available to bring data into Snowflake. Domo also uses this Domo-managed database to create outputs of data transformations (DataFlow outputs).\n\n\n**How are permission configured between Domo and Snowflake?**\n\n\n Permissions originating in Snowflake are not programmatically passed into Domo. However, you can use Domo's native permission model, as well as personalized data permisssons (PDP) for data security to manage data access to underlying assets in Snowflake.\n\n\n**What are the differences between using connectors to create DataSets from Snowflake and using Cloud Amplifier to create DataSets?**\n\n **Leaving data in Snowflake**\n \u2014\u00a0Perhaps the biggest difference is that all Snowflake connectors import/duplicate data from Snowflake to Domo, while Cloud Amplifier leaves the data in Snowflake.\n* **Bulk create**\n \u2014\u00a0Cloud Amplifier allows you to look up and bulk select up to 50 Snowflake tables to immediately create 50 unique DataSets.\u00a0To do this with connectors, you would have to configure each DataSet individually with a connector.\n\nTroubleshooting\n-------------------\n\nIf you get stuck, one of the following\u00a0troubleshooting steps may help:\n\n\n**Check Snowflake Service Account**\n\n. Log into Snowflake with the service account credentials.\n2. Make sure you can view the default Snowflake Database and can query tables that you expect to import.\n\n*Assign Correct Role**\n\n\n Make sure that a Snowflake administrator with the ACCOUNTADMIN role is executing the SQL that Domo provided in Snowflake.\n\n\n**Use Correct URL**\n\n\n Make sure that the Snowflake connection URL in Domo matches the Snowflake login URL.\n\n\n You can find the URL on the Snowflake login page. The URL will be in this format:\n *instancename.region.*\n snowflakecomputing.com.\n\n\n If you are still experiencing issues, please submit a request to the\n\nDomo Support\n\nteam.\n\n", "preview_article": "\n\nClick here to preview\n\n", "url_name": "\n\n\n 4402322966807\n\n\n", "summary____________________________________________briefly_describe_the_article_the_summary_is_used_in_search_results_to_help_users_find_relevant_articles_you_can_improve_the_accuracy_of_search_results_by_including_phrases_that_your_customers_use_to_describe_this_issue_or_topic": "\n\n", "article_number": "\n\n\n 000003148\n\n\n", "archived_date": "\n\n\n", "language": "\n\n\n English\n\n\n", "primary_version": "\n\nRegister Snowflake with Cloud Amplifier\n\n", "article_total_view_count": "\n\n\n 5,346\n\n\n", "": "\n\n", "article_created_date": "\n\n\n 10/24/2022, 9:09 PM\n\n\n", "first_published_date": "\n\n\n 10/24/2022, 10:42 PM\n\n\n"}, "title": "register_snowflake_with_cloud_amplifier", "breadcrumbs": [{"text": "domo", "url": "/s/knowledge-base/"}, {"text": "connecting_data_to_domo", "url": "/s/topic/0TO5w000000ZammGAC"}, {"text": "cloud_amplifier", "url": "/s/topic/0TO5w000000Zjd3GAC"}]}