{"file_path": "../../raw_kb_v2\\article\\360042923034\\index.html", "content": {"title": "\n\n\n Running a DataFlow\n\n\n", "article_body": "\n\nIntro\n-------\n\nWhen you run a DataFlow, you are executing the script for that DataFlow. The first time you run a DataFlow, it generates one or more new DataSets based on the data in your input DataSets, any SQL transforms you have applied, and how you have indicated that you want them to be combined, also using SQL. On subsequent runs, the DataSets are updated to accommodate new changes to the input DataSets themselves as well as any changes you have made to the SQL for the DataFlow.\n\n\n**Notes:**\n\n You cannot run a\n\n\n DataFlow\n\n\n if you do not have access to any of its component\n\n\n DataSets\n\n\n .\n* If a DataSet fails to execute, it will retry once automatically with no notifications being sent. If the DataFlow continues to fail after the first attempt, notifications will be sent.\n* In previous versions of DataFlows, you could not execute a DataFlow while a previously executed DataFlow was in the indexing state. This is no longer the case. You can now execute multiple DataFlows at once.\n\n\n---\n\n*Important:**\n Input DataSets\u00a0in a DataFlow\u00a0cannot be restricted by PDP policies\u2014all available rows\n *must*\n pass through the DataFlow. Because of this you must apply PDP policies to the output DataSets generated by a DataFlow.\n\n\n When you build a DataFlow using an input DataSet\u00a0with PDP\u00a0policies in place,\u00a0the DataFlow breaks unless\u00a0at least one of the following criteria\u00a0applies:\n\n You have an \"Admin\" security profile.\n* You are\u00a0the DataSet owner.\n* You are\u00a0part of the \"All Rows\" policy. This gives you access to all of the rows in the DataSet.\n\nFor more information about using PDP with DataFlows, see\n\nPDP and DataFlows/DataFusions\n\n.\n\n\n You can run DataFlows one at a time or in bulk.\n\n\n Running a Single DataFlow\n---------------------------\n\nYou can run a single DataFlow in any\u00a0of the following locations:\n\n From the\n **DataFlows**\n tab in the Data Center. This is the fastest way to run a DataFlow; however, the DataFlow must have already been created in the\n **Create DataFlow**\n view.\n* From the Details view for the DataFlow. As with the previously mentioned option, the DataFlow must already be created to do this.\n* From the\n **Create/Edit DataFlow**\n view. In this view, you can choose between\n **Save**\n and\n **Save and Run**\n . The\n **Save**\n option only saves changes you have made to the DataFlow and, if you have just created the DataFlow, adds a card to the\n **DataFlows**\n listing in the\n **Data Center**\n page. The\n **Save and Run**\n option performs the same function as\n **Save**\n and also runs the script for the DataFlow.\n\n*To run a DataFlow from the Data Center page,**\n\n. In Domo,\u00a0click\n ****Data****\n in the toolbar at the top of the screen.\n2. Click\n\nin the left-hand navigation pane.\n\n\n The\n **DataFlows**\n tab opens.\n3. Locate the DataFlow you want to run.\n\n\n You can use the filter options to narrow down the DataFlows that appear in the list.\n4. Mouse over the desired DataFlow, click\n\n, then select\n **Run**\n .\n\nThis runs the script for the DataFlow. If this is the first time you have run this DataFlow, DataSets based on the DataFlow are generated and added to the\n **DataSets**\n tab. If the DataSets have already been generated, they are updated according to changes made to the input DataSets and DataFlow SQL.\n\n\n**To run a**\n**DataFlow from the Details view,**\n\n. In Domo,\u00a0click\n ****Data****\n in the toolbar at the top of the screen.\n2. Click\n\nin the left-hand navigation pane.\n\n\n The\n **DataFlows**\n tab opens.\n3. Locate the DataFlow you want to run.\n\n\n You can use the filter options to narrow down the DataFlows that appear in the list.\n4. Mouse over the desired DataFlow, click\n\n, then select\n **Details**\n .\n5. Click\n\nthen select\n **Run**\n .\n\n*To run a DataFlow from the Create/Edit DataFlow view,**\n\n. In Domo,\u00a0click\n ****Data****\n in the toolbar at the top of the screen.\n2. (Conditional) Do one of the following:\n\n* If you have not yet created the DataFlow...\n\n\t1. Click\n\t\t **ETL**\n\t\t or\n\t\t **SQL**\n\t\t in the\n\t\t **Magic Transform**\n\t\t toolbar.\n\t\t2. Follow the steps provided in\n\n\t Creating an SQL DataFlow\n\n\t .\n\t\t3. Once you have created the DataFlow, click\n\t\t **Save and Run**\n\t\t .\n\n\n\t\t This runs the script for the DataFlow. DataSets based on the DataFlow are generated and added to the\n\t\t **DataSets**\n\t\t tab, and an entry for the DataFlow appears in the\n\t\t **DataFlow**\n\t\t tab.\n\t* If the DataFlow already exists...\n\n\t1. Click\n\n\t in the left-hand navigation pane to open the\n\t\t **DataFlows**\n\t\t tab.\n\t\t2. Locate the DataFlow\u00a0you want to run.\n\n\n\t\t For more information about searching and filtering DataFlow in the Data Center, see\n\n\t Data Center Layout\n\n\t .\n\t\t3. Mouse over the DataFlow row and click the\n\n\t icon.\n\t\t4. Select\n\t\t **Edit**\n\t\t .\n\t\t5. Make any changes you want (for more specific information, see\n\n\t Creating an SQL DataFlow\n\n\t ) then click\n\t\t **Save and Run**\n\t\t .\n\n\n\t\t This runs the script for the DataFlow. All DataSets based on the DataFlow are updated according to changes made to the input DataSets and the DataFlow SQL.\n\nFor more information about components of the Data Center and the\n **DataFlows**\n tab, see\n\nData Center Layout\n\n.\n\n\n**Note:**\n Many users ask why output DataSets for a DataFlow are not marked as \"Updated\" when the DataFlow runs successfully. This is usually because the data has not actually changed\u2014no update has occurred. Therefore, the DataSets do not show as updated.\n\n\n Running Multiple DataFlows\n----------------------------\n\nYou can run multiple DataFlows at once by selecting them in the Data Center then choosing the\n **Run Now**\n option.\n\n\n**To run multiple DataSets at once,**\n\n. In Domo,\u00a0click\n ****Data****\n in the toolbar at the top of the screen.\n2. Click\n\nin the left-hand navigation pane.\n\n\n The\n **DataFlows**\n tab opens.\n3. Locate one of the DataFlows you want to run.\n\n\n For more information about searching and filtering DataFlow in the Data Center, see\n\nData Center Layout\n\n.\n4. Mouse over the row for the DataFlow and click the circled checkmark that pops up over the connector icon.\n5. In the blue bar that appears at the top of the screen, click the\n\nicon.\n6. Select\n **Run Now**\n .\n\n\n All of the DataFlows you have selected should now run.\n\nCancelling a DataFlow\n-----------------------\n\nIf you wish to cancel an executed DataFlow mid-run, you may do so by selecting the\n **Cancel**\n option from the\n\nmenu. To protect data integrity, DataFlows cannot be cancelled once they reach\u00a0the \"Indexing\" stage; they must continue running until completion.\n\n*Video - Cancel a DataFlow**\n\nTroubleshooting\n-----------------\n\nFor troubleshooting information, see\n\nDataFlow and DataFusion Troubleshooting and FAQ\n\n.\n\n", "preview_article": "\n\nClick here to preview\n\n", "url_name": "\n\n\n 360042923034\n\n\n", "summary____________________________________________briefly_describe_the_article_the_summary_is_used_in_search_results_to_help_users_find_relevant_articles_you_can_improve_the_accuracy_of_search_results_by_including_phrases_that_your_customers_use_to_describe_this_issue_or_topic": "\n\n", "article_number": "\n\n\n 000004559\n\n\n", "archived_date": "\n\n\n", "language": "\n\n\n English\n\n\n", "primary_version": "\n\nRunning a DataFlow\n\n", "article_total_view_count": "\n\n\n 5,451\n\n\n", "": "\n\n", "article_created_date": "\n\n\n 10/24/2022, 10:14 PM\n\n\n", "first_published_date": "\n\n\n 10/24/2022, 10:41 PM\n\n\n"}, "title": "running_a_dataflow", "breadcrumbs": [{"text": "domo", "url": "/s/knowledge-base/"}, {"text": "transforming_data_in_domo", "url": "/s/topic/0TO5w000000ZamzGAC"}, {"text": "dataflow_management", "url": "/s/topic/0TO5w000000ZanUGAS"}]}