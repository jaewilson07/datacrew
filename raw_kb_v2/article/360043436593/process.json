{"file_path": "../../raw_kb_v2\\article\\360043436593\\index.html", "content": {"title": "\n\n\n Google BigQuery Service Connector\n\n\n", "article_body": "\n\nIntro\n---------\n\nGoogle BigQuery is a cloud-based big data analytics web service for processing very large read-only data sets. You can use Domo's Google BigQuery Service connector to pull data from a specified project. Google BigQuery queries are written using a variation of the standard\n\nSQL SELECT\n\nstatement. To learn more about the\u00a0BigQuery\u00a0API, go to\n\nhttps://cloud.google.com/bigquery/docs/reference/v2/\n\n.\n\n\n The Google BigQuery\u00a0Service connector is a \"Cloud App\" connector, meaning it retrieves data stored in the cloud. In the Data Center, you can access the connector page for this and other Cloud App connectors by clicking\n **Cloud App**\n in the toolbar at the top of the window.\n\n\n This topic discusses the fields and menus that are specific to the\u00a0Google BigQuery\u00a0Service connector user interface.\u00a0For general information about adding DataSets, setting update schedules, and editing DataSet information, see\n\nAdding a DataSet Using a Data Connector\n\n.\n\n  |  |\n| --- | --- |\n|\n**Primary Use Cases**\n |\n Any situations in which you need to extract data from Google BigQuery.\n  |\n|\n**Primary Metrics**\n |\n DFP data\n  |\n|\n**Primary Company Roles**\n | * Marketing roles\n* Finance roles\n |\n|\n**Average Implementation Time**\n |\n This depends on how many queries need to be written. Having someone who understands the BigQuery database structure and knows how to build the queries will greatly cut down on deployment time.\n  |\n|\n**Ease of Use (on a 1-to-10 scale with 1 being easiest)**\n |\n 5\n  |\n\nBest Practices\n----------------\n\n\n* Structuring your queries to be optimized so you are pre-aggregating data\n *before*\n pulling it into Domo will significantly improve performance.\n* Getting your data closely structured to support the visualizations prior to ingestion will save time by potentially eliminating the ETL process in Domo.\n\nPrerequisites\n---------------\n\nTo connect to a BigQuery service account,\n\nyou must have a Google BigQuery\u00a0service account JSON key. To generate a key, do the following:\n\n\n1. In the Google Cloud Platform Console, open the IAM & Admin page.\n2. Click\n **Service accounts**\n in the left-hand navigation pane.\n3. Select your project and click\n **Open**\n .\n4. Click\n **Create Service Account**\n .\n5. Enter a name and description for the service account.\n6. Click\n **Create**\n .\n\n*Note:**\n You may need the \u201cBigQuery Admin\u201d role in the service account permissions dialog. Please consult with your Google administrator for additional guidance.\n7. Select\n **Project > Owner**\n .\n8. Click\n **Continue**\n .\n9. Click\n **Create key**\n .\n10. Select\n **JSON**\n as the key type.\n11. Click\n **Create**\n .\n\nA private key will be saved to your computer.\n\n\n Connecting to Your\u00a0BigQuery\u00a0Service Account\n---------------------------------------------\n\nThis section enumerates the options in the\n\nCredentials\n\nand\n\nDetails\n\npanes in the\u00a0Google BigQuery\u00a0Service Connector page.\u00a0The components of the other panes in this page,\n **Scheduling**\n and\n **Name & Describe Your DataSet**\n , are universal across most connector types and are discussed in greater length in\n\nAdding a DataSet Using a Data Connector\n\n.\n\n##\n Credentials Pane\n\nThis pane contains fields for entering credentials to connect to your BigQuery\u00a0service\u00a0account. The following table describes what is needed for each field:\n\n\n Field\n  |\n Description\n  |\n| --- | --- |\n|\n Service Account Key JSON\n  |\n Copy and paste the JSON for your BigQuery\u00a0service account key. For information about creating a key, see \"Prerequisites,\" above.\n  |\n\nOnce you have entered a valid key,\u00a0you can use the same account any time you go to create a new Google BigQuery\u00a0Service DataSet. You can manage connector accounts in the\n **Accounts**\n tab in the\n\nData Center\n\n. For more information about this tab, see\n\nManaging User Accounts for Connectors\n\n.\n\n##\n Details Pane\n\nThis pane contains a number of fields and menus you can use to configure your report.\n\n\n**Tip:**\n Use the \"Table Information\" report to get the DataSet ID,\u00a0Project ID, table name,\u00a0etc. This can help you create and form your queries.\n\n\n Menu\n  |\n Description\n  |\n| --- | --- |\n|\n Report\n  |\n Select the BigQuery report type to run. The following reports are available:\n\n\n|  |  |\n| --- | --- |\n|\n Query\n  |\n Lets you enter a query and configure the parameters.\n  |\n|\n Table Data\n  |\n Lets you pull data for a selected BigQuery project, dataset, and table.\n  |\n|\n Table Information\n  |\n Returns the table resource that describes the structure of this table. This report does\n *not*\n return the data in the table. To do this, run the \"Table Data\" report.\n  |\n\n|\n|\n SQL Dialect\n  |\n Select whether your query is to be written using LegacySQL or StandardSQL. By default,\n\nStandard SQL is used.\n\n|\n|\n Query\n  |\n Enter a fully qualified BigQuery query. The query language you use must match what you have selected in the\n **SQL Dialect**\n\nmenu.\n\n\n For full documentation about writing BigQuery queries, see\n\nhttps://cloud.google.com/bigquery/query-reference\n\n. For more information about setting a query prefix, see\n\nhttps://cloud.google.com/bigquery/docs/reference/standard-sql/enabling-standard-sql\n\n.\n  |\n|\n Query Parameter\n  |\n\nEnter the query parameter value. This is the initial value for query parameter. You can provide multiple comma separated query parameters. The query in the above \"Query\" field will fetch the data according to the parameter values provided here. For more information, see \"Using the Query Parameter\" section below.\n\n\n Example:\n\n!{lastvalue:\\_id}!=1,!{lastrundate:start\\_date}!=02/01/1944\n\n\n |\n|\n Allow Large Results\n  |\n Select whether you expect a large resulting DataSet from this query. If you select\n **Yes**\n , a temporary table will be created and then deleted when the job is finished. You will need to enter a DataSet\u00a0ID in the\n **DataSet ID**\n field for the table to be created.\n  |\n|\n DataSet\u00a0Name\n  |\n Select the name of the dataset you want to pull\u00a0into Domo.\n  |\n|\n Table Name\n  |\n Select the table you want to pull data from.\n  |\n|\n Processing Location\n  |\n Enter the location where your query will run. Queries running in a specific location may only reference data in that location.\n  |\n|\n Max Results\n  |\n Enter the maximum number of results you want to return in your report. The default is 10,000 results per page. If your DataSet\u00a0throws an \"Out of Memory\" error, decrease this number.\n  |\n|\n Use Google BigQuery Schema\n  |\n\nSelect this checkbox to use the schema received from Google BigQuery.\n\nThis is useful when a column's datatype may be perceived incorrectly to Domo.\n\n\n Example: Your table may contain '123' in a String column.\n\n|\n\n\n###\n Using the Query Parameter\n\n\n Query parameter indicates the initial values for the query parameters. After the initial run, the query will only request the updated data from the provider on subsequent runs. You can provide multiple query parameters separated by comma.\n\n\n**Note:**\n You must use the query parameters provided here in the Query field above. The query will fetch the data according to the parameter values provided here.\n\n\n Example:\n\nIn this example, the values \"id=1\" and \"start date=02/01/1944\" will be used in the first run of the above query.\n\n\n The value for the query parameter 'last run date' is optional. By default, the last run date is '02/01/1700' if is not provided.\n\n\n###\n Other Panes\n\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\n\nAdding\u00a0a DataSet Using a Data Connector\n\n.\n\n\n Troubleshooting\n-----------------\n\n\n* Ensure that the credentials have the proper access to the query the tables needed.\n* Make sure the queries are correct and calling the correctly named data sources.\n\nFAQs\n------\n\n\n####\n When should I use this connector?\n\nUse this connector to import small to large datasets from Google BigQuery. This connector uses a Service Account key in JSON format to connect, and only connects to the project specified in the key. Once connected, you can replace the dataset on every run, append data to the existing dataset on every run, or merge (upsert) new or updated data on every run. For very large datasets, it is recommended you use one of Domo's Google High Bandwidth or Unload connectors.\n\n###\n How is the page size determined?\n\nThe\n **Max Results**\n parameter, set in the\n **Details**\n section of the connector, is the maximum number of rows of data to return per page of results. Setting\n **Max Results**\n to a smaller value, such as 1000, then paging through results, may improve reliability when the query result set is large.\n\n\n In addition to Domo's\n **Max Results**\n row limit, Google imposes a byte limit of 10 MB per page of results. If your row values contain a lot of data, you may have fewer rows per page returned in order to come under the byte limit.\n\n###\n How do I process data in specific locations?\n\nYou can specify the processing location in your Query report for storing your BigQuery data when you create a DataSet. After you create the DataSet, the location cannot be changed. Queries that run in a specific location may only reference data in that location. There are two types of locations: a regional location and a multi-regional location. For more information, visit\n\nDataset locations\n\n.\n\n###\n My DataSet returns the error \"Too large to run.\" How can I retrieve large results for my query?\n\nIf you are expecting large results for your query, go to the\n **Details**\n section of the connector interface. Select\n **Yes**\n for\n **Allow large results?**\n , and select the DataSet\u00a0in the\n **DataSet Name**\n menu.\u00a0Your Google account must have Table creation permissions enabled in order to set\n **Allow large results**\n to\n **Yes**\n .\n\n###\n How frequently will my data update?\n\nAs often as needed.\n\n###\n Are there any API limits that I need to be aware of?\n\nNo\n\n###\n Can I use the same Google BigQuery account for multiple DataSets?\n\nYes\n\n###\n What kind of credentials do I need to power up this connector?\n\nYou need the service account key JSON of your Google BigQuery Service Account.\n\n###\n Where can I find my service account key JSON?\n\nTo find your service account key JSON:\n\n. Open the IAM & Admin page in the GCP Console.\n2. In the left navigation, click\n **Service accounts**\n .\n3. Select your project and click\n **Open**\n .\n4. Click\n **Create Service Account**\n .\n5. Enter a service account name and service account description. Click\n **Create**\n .\n6. Select a role you wish to grant to the service account (Project Owner). Click\n **Continue**\n .\n7. Click\n **Create key**\n . Select JSON key type. Click\n **Create**\n . Private key will be saved to your computer.\n8. Close the pop up. Click\n **Done**\n .\n\n\n", "preview_article": "\n\nClick here to preview\n\n", "url_name": "\n\n\n 360043436593\n\n\n", "summary____________________________________________briefly_describe_the_article_the_summary_is_used_in_search_results_to_help_users_find_relevant_articles_you_can_improve_the_accuracy_of_search_results_by_including_phrases_that_your_customers_use_to_describe_this_issue_or_topic": "\n\n", "article_number": "\n\n\n 000003935\n\n\n", "archived_date": "\n\n\n", "language": "\n\n\n English\n\n\n", "primary_version": "\n\nGoogle BigQuery Service Connector\n\n", "article_total_view_count": "\n\n\n 5,244\n\n\n", "": "\n\n", "article_created_date": "\n\n\n 10/24/2022, 9:16 PM\n\n\n", "first_published_date": "\n\n\n 10/24/2022, 10:40 PM\n\n\n"}, "title": "google_bigquery_service_connector", "breadcrumbs": [{"text": "domo", "url": "/s/knowledge-base/"}, {"text": "connecting_data_to_domo", "url": "/s/topic/0TO5w000000ZammGAC"}, {"text": "connectors", "url": "/s/topic/0TO5w000000ZanLGAS"}, {"text": "file_connectors", "url": "/s/topic/0TO5w000000ZaowGAC"}]}