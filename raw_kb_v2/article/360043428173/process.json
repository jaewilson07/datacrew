{"file_path": "../../raw_kb_v2\\article\\360043428173\\index.html", "content": {"title": "\n\n\n Dealing with Attribution Windows\n\n\n", "article_body": "\n\n\"Attribution windows\" are essentially periods in which some companies (such as Facebook and YouTube) reserve the right to restate their metrics over a period of days. For example, Youtube has a 35-day attribution window,\u00a0meaning\u00a0they can restate their numbers anytime within this window. Likewise, Facebook has a 28-day window.\n\n\n You can deal with such attribution windows by setting up a rolling file and a historical file. The rolling file should be set to replace and should cover the attribution window. The historical file should be set to contain the growing history and should execute once a day to capture just a single day\u2019s data in an append.\n\n\n There are multiple ways to combine these files and some of it depends on API timing. If both of these calls (the rolling and append daily) happen quickly and early, the fastest and simplest approach is to use DataFusion. The files\u00a0will contain the same schema because they are the\u00a0same call, covering different date ranges. If both calls are made early and run quickly, you will only have minimal minutes each day where the calls are executing, and you could possibly have a gap between the rolling\u00a0file and the historical file completing with a single day missing.\n\n\n If the DataSets\u00a0are small and you need to account for the slight chance of a missing day during the run, you\u2019ll want to set up an\u00a0ETL like the following:\n\nIn the above screenshot you have a top branch (historical) that contains the history including day 35 as an append each day. In the bottom branch you have a daily replace file of the last 35 days. So there is overlap of day 35 in both files. Because of this, you need to do a filter on one of the branches removing the 35\n th\n day so it is not counted twice. As long as one of these DataSets is running quickly and reliably, you will have this data overlapped then filtered to ensure reliable, contiguous reporting.\n\n\n Here are the parameters for each transform:\n\n", "preview_article": "\n\nClick here to preview\n\n", "url_name": "\n\n\n 360043428173\n\n\n", "summary____________________________________________briefly_describe_the_article_the_summary_is_used_in_search_results_to_help_users_find_relevant_articles_you_can_improve_the_accuracy_of_search_results_by_including_phrases_that_your_customers_use_to_describe_this_issue_or_topic": "\n\n", "article_number": "\n\n\n 000004600\n\n\n", "archived_date": "\n\n\n", "language": "\n\n\n English\n\n\n", "primary_version": "\n\nDealing with Attribution Windows\n\n", "article_total_view_count": "\n\n\n 4,694\n\n\n", "": "\n\n", "article_created_date": "\n\n\n 10/24/2022, 10:15 PM\n\n\n", "first_published_date": "\n\n\n 10/24/2022, 10:41 PM\n\n\n"}, "title": "dealing_with_attribution_windows", "breadcrumbs": [{"text": "domo", "url": "/s/knowledge-base/"}, {"text": "transforming_data_in_domo", "url": "/s/topic/0TO5w000000ZamzGAC"}, {"text": "transformation_tips_and_tricks", "url": "/s/topic/0TO5w000000ZaoJGAS"}]}