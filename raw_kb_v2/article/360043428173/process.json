{"file_path": "../../raw_kb_v2\\article\\360043428173\\index.html", "content": {"Title": "Dealing with Attribution Windows", "Article Body": "\"Attribution windows\" are essentially periods in which some companies (such as Facebook and YouTube) reserve the right to restate their metrics over a period of days. For example, Youtube has a 35-day attribution window,\u00a0meaning\u00a0they can restate their numbers anytime within this window. Likewise, Facebook has a 28-day window.\n                       \n\n                        You can deal with such attribution windows by setting up a rolling file and a historical file. The rolling file should be set to replace and should cover the attribution window. The historical file should be set to contain the growing history and should execute once a day to capture just a single day\u2019s data in an append.\n                       \n\n                        There are multiple ways to combine these files and some of it depends on API timing. If both of these calls (the rolling and append daily) happen quickly and early, the fastest and simplest approach is to use DataFusion. The files\u00a0will contain the same schema because they are the\u00a0same call, covering different date ranges. If both calls are made early and run quickly, you will only have minimal minutes each day where the calls are executing, and you could possibly have a gap between the rolling\u00a0file and the historical file completing with a single day missing.\n                       \n\n                        If the DataSets\u00a0are small and you need to account for the slight chance of a missing day during the run, you\u2019ll want to set up an\u00a0ETL like the following:\n                       \n\n\n\n\n                        In the above screenshot you have a top branch (historical) that contains the history including day 35 as an append each day. In the bottom branch you have a daily replace file of the last 35 days. So there is overlap of day 35 in both files. Because of this, you need to do a filter on one of the branches removing the 35\n                        \n                         th\n                        \n                        day so it is not counted twice. As long as one of these DataSets is running quickly and reliably, you will have this data overlapped then filtered to ensure reliable, contiguous reporting.\n                       \n\n                        Here are the parameters for each transform:", "Preview Article": "Click here to preview", "URL Name": "360043428173", "Summary\n                     \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                       Briefly describe the article. The summary is used in search results to help users find relevant articles. You can improve the accuracy of search results by including phrases that your customers use to describe this issue or topic.": "", "Article Number": "000004600", "Archived Date": "", "Language": "English", "Primary Version": "Dealing with Attribution Windows", "Article Total View Count": "4,694", "": "", "Article Created Date": "10/24/2022, 10:15 PM", "First Published Date": "10/24/2022, 10:41 PM"}, "title": "\n              Dealing with Attribution Windows\n             ", "breadcrumbs": [{"text": "\n\n               Domo\n              \n", "url": "/s/knowledge-base/"}, {"text": "\n\n               Transforming Data In Domo\n              \n", "url": "/s/topic/0TO5w000000ZamzGAC"}, {"text": "\n\n               Transformation Tips And Tricks\n              \n", "url": "/s/topic/0TO5w000000ZaoJGAS"}]}