{"file_path": "../../raw_kb_v2\\article\\360043436073\\index.html", "content": {"title": "\n\n\n Amazon Redshift Unload Connector\n\n\n", "article_body": "\n\nIntro\n-------\n\nAmazon Redshift is a fast and powerful, fully managed, petabyte-scale data warehouse service in the cloud.\n\n\n You connect to your Amazon Redshift Unload account in the Data Center. This topic discusses the fields and menus that are specific to the Amazon Redshift Unload connector user interface. General information for adding DataSets, setting update schedules, and editing DataSet information is discussed in\n\nAdding a DataSet Using a Data Connector\n\n.\n\n\n Prerequisites\n---------------\n\nTo connect to Amazon Redshift\u00a0so you can begin creating Amazon Redshift Unload\u00a0DataSets, you must have the following:\n\n The host name for the Redshift database\n* The database name for the Redshift database\n* Your Redshift username and password\n* The port number of your Redshift database\n* Your AWS access key\n* Your AWS secret access key\n* The name of the S3 bucket data will be unloaded into\n* The name of the S3 bucket region\n\nCA certificate text or URL path is required\n **only**\n if you select\n ****Certificate string****\n or\n ****URL path****\n ,\u00a0respectively, in the\n ****Certificate type****\n menu.\n\n\n If you do not know any of the information for Redshift, contact your Amazon Redshift Database Administrator.\n\n\n To find your AWS Access Key and Secret Access Key:\n\n. Log in to your AWS Management Console.\n2. Click on your username at the top right of the page.\n3. Select\n ****Security Credentials****\n in the dropdown menu.\n4. In the\n ****Access Credentials****\n section, copy the latest Access Key ID.\n5. Click on the\n ****Show link****\n in the same row, and copy the Secret Access Key.\n\n\n###\n Whitelisting\n\nBefore you can connect to Redshift, you must also whitelist a number of IP addresses on your database server on the\u00a0port\u00a0you want to connect to. For the full list of IP addresses, see\n\nWhitelisting IP Addresses for Connectors\n\n.\n\n\n Connecting to Your Amazon Redshift Unload Account\n---------------------------------------------------\n\n\n This section enumerates the options in the\n **Credentials**\n and\n **Details**\n panes in the Amazon Redshift Unload Connector page.\u00a0The components of the other panes in this page,\n **Scheduling**\n and\n **Name & Describe Your DataSet**\n , are universal across most connector types and are discussed in greater length in\n\nAdding a DataSet Using a Data Connector\n\n.\n\n\n###\n\nCredentials Pane\n\n\n This pane contains fields for entering credentials to connect to your Amazon Redshift Unload account. The following table describes what is needed for each field:\n\n\n|\n\nField\n\n|\n\nDescription\n\n|\n| --- | --- |\n|\n Host\n  |\n Enter the host name for the Redshift\u00a0database you want to pull data from.\n  |\n|\n Database\n  |\n Enter the database name for the Redshift database you want to pull data from.\n  |\n|\n Username\n  |\n Enter the username for your Redshift account,\n  |\n|\n Password\n  |\n Enter the password for your Redshift account.\n  |\n|\n Database Port\n  |\n Enter the port number for the Redshift database you want to pull data from.\n  |\n|\n Certificate Format\n  |\n Select a certificate format. If you do not want to include a certificate, leave the default\n ****No certificate****\n option selected. If you select\n **Certificate string**\n , you must paste the text for your certificate in the\n ****Certificate****\n field. If you select\n ****URL path****\n , you must enter the URL where your certificate is located in the\n ****Certificate****\n field.\n  |\n|\n Certificate\n  |\n Paste the text for your CA certificate or enter the URL where your certificate is located.\u00a0This is optional. If you do not want to include a certificate, select\n ****No certificate****\n in the\n ****Certificate Format****\n menu.\n  |\n|\n Access Key\n  |\n Enter your AWS\u00a0access key. For information about obtaining an access key, see \"Prerequisites,\" above.\n  |\n|\n Secret Access Key\n  |\n Enter your AWS\u00a0secret key. For information about obtaining an access key, see \"Prerequisites,\" above.\n  |\n|\n S3 Bucket\n  |\n Enter the name of the S3 bucket to use in pulling in data.\n  |\n|\n S3 Bucket Region\n  |\n Select the region containing the desired S3 bucket.\n  |\n\n\n Once you have entered valid credentials, you can use the same account any time you go to create a new Amazon Redshift Unload DataSet. You can manage connector accounts in the\n **Accounts**\n tab in the Data Center. For more information about this tab, see\n\nManaging User Accounts for Connectors\n\n.\n\n\n###\n Details Pane\n\nThis pane contains various options for specifying the data you want to pull into Domo.\n\n\n Menu\n  |\n Description\n  |\n| --- | --- |\n|\n Header Query (Optional)\n  |\n Enter the SQL query to use in obtaining the correct header metadata for the query specified below (in the\n **Query**\n field). This is necessary because Redshift does not dump header data using UNLOAD. If you leave this blank, header data will be retrieved using the query you enter in the\n **Query**\n field.\n  |\n|\n Cache Last Good Header?\n  |\n If you select\n **Yes**\n for this option, the connector caches the header so it does not create an additional query.\n  |\n|\n Query Type\n  |\n Select the desired query type. If you select\n **Query**\n , you will be prompted to enter a regular SQL query without a parameter. If you select\n **Query Parameter**\n , you will be prompted to enter a SQL query with a parameter.\n  |\n|\n Query\n  |\n Enter the SQL query you want to use to pull in data.\n\n\n For example:\n\nselect \\* from Employee\n\nYou can use the\n ****Generated Query****\n parameter to help you write a usable SQL query. To use the\n **Generated Query**\n , do the following:\n 1. Select your database table\u00a0and table columns in the appropriate menus.\n2. Copy the SQL statement that appears in the\n ****Generated Query****\n field.\n3. Paste the copied SQL statement into the\n ****Query****\n field.\n\n\n |\n|\n Fetch Size (Optional)\n  |\n Enter the fetch size for memory performance. If you leave this blank, a default value of 1000 will be used. If an \"Out of Memory\" error is generated, try decreasing the fetch size.\n  |\n|\n Query Parameter\n  |\n Enter the query parameter value. This is the initial value for the query parameter. The \"Last Run\" date is optional. If you do not enter this date, a default date of \"02/01/1700\" is used.\n\n\n For example:\n\n!{lastvalue:\\_id}!=1,!{lastrundate:start\\_date}!=02/01/1944,!{lastmaxvalue:size}!=0\n\n|\n|\n Validation Type\n  |\n Select the desired validation type. If you select\n **Validate schema**\n , the previous schema is validated against the current schema. If these are not the same, the validation fails. If you select this option, you are asked to select a validation case in the\n **Validate By**\n menu.\n  |\n|\n Validate By\n  |\n Select the desired validation case option.\n\n\n If you select\n **Column case sensitive**\n , if the previous schema and current schema are the same except for differences in letter case, the schemas are not considered the same and the validation fails.\n\n\n If you select\n **Column by order**\n , if the previous schema and current schema are the same except for column order differences, the schemas are not considered the same and the validation fails.\n  |\n|\n Boolean Format\n  |\n Select the desired Boolean format for returned data.\n  |\n|\n Database Tables (Optional)\n  |\n Select the database tables you want to pull into Domo, if desired.\n  |\n|\n Table Columns (Optional)\n  |\n Select the table columns you want to pull into Domo.\n  |\n|\n Generated Query (Optional)\n  |\n Copy and paste the SQL statement in this field into the\n ****Query****\n field. For more information, see\n ****Query****\n , above.\n  |\n|\n Query Timeout (Optional)\n  |\n Enter the desired query timeout value.\n  |\n|\n Use High Bandwidth Upload\n  |\n Select this checkbox to use high bandwidth upload transfer.\n  |\n|\n Keep Files in S3?\n  |\n Select whether or not you want to keep your files in S3.\n  |\n\n\n###\n Other Panes\n\nFor information about the remaining sections of the connector interface, including how to configure scheduling, retry, and update options, see\n\nAdding\u00a0a DataSet Using a Data Connector\n\n.\n\n\n FAQs\n------\n\n\n#####\n How often can the data be updated?\n\nAs often as needed.\n\n####\n Are there any API limits I should be aware of?\n\nThis depends on your server configuration.\n\n####\n Why can't I connect to my Redshift\u00a0database? Do I need to whitelist any IP addresses?\n\nBefore you can connect to a Redshift database, you must also whitelist a number of IP addresses on your database server on the port you want to connect to. For the full list of IP addresses, see\n\nWhitelisting IP Addresses\n\n.\n\n", "preview_article": "\n\nClick here to preview\n\n", "url_name": "\n\n\n 360043436073\n\n\n", "summary____________________________________________briefly_describe_the_article_the_summary_is_used_in_search_results_to_help_users_find_relevant_articles_you_can_improve_the_accuracy_of_search_results_by_including_phrases_that_your_customers_use_to_describe_this_issue_or_topic": "\n\n", "article_number": "\n\n\n 000003905\n\n\n", "archived_date": "\n\n\n", "language": "\n\n\n English\n\n\n", "primary_version": "\n\nAmazon Redshift Unload Connector\n\n", "article_total_view_count": "\n\n\n 4,735\n\n\n", "": "\n\n", "article_created_date": "\n\n\n 10/24/2022, 9:16 PM\n\n\n", "first_published_date": "\n\n\n 10/24/2022, 10:39 PM\n\n\n"}, "title": "amazon_redshift_unload_connector", "breadcrumbs": [{"text": "domo", "url": "/s/knowledge-base/"}, {"text": "connecting_data_to_domo", "url": "/s/topic/0TO5w000000ZammGAC"}, {"text": "connectors", "url": "/s/topic/0TO5w000000ZanLGAS"}, {"text": "database_connectors", "url": "/s/topic/0TO5w000000ZaojGAC"}]}