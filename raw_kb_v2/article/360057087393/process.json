{"file_path": "../../raw_kb_v2\\article\\360057087393\\index.html", "content": {"title": "\n\n\n Creating a Recursive/Snapshot DataFlow in Magic ETL\n\n\n", "article_body": "\n\nIntro\n-------\n\nA \"recursive\" or \"snapshot\" DataFlow is a DataFlow that uses itself as an input.\n\n\n DataFlows (both SQL and Magic ETL) cannot append data natively like Connectors. However, if you need to create a DataFlow that appends data, you can do so by running it once and then using the output as part of the input for the next run. By doing this, every time the DataFlow runs, it includes the data from before and also appends the new data onto itself.\n\n*Important:**\n There are significant behavioral differences in Magic ETL. Read the\n\n\n Behavior Changes and Feature Updates in Magic ETL\n\n\n article before converting mission-critical Magic ETL DataFlows.\n **Failure to do so may cause an unintended change to your DataFlow\u2019s behavior.**\n\n*Video\u00a0- What is a Recursive DataFlow?**\n\n*Important:**\n If a recursive DataFlow is edited incorrectly, you could lose ALL historical data. To avoid this any time you are editing, create an additional DataSet that is a copy of your historical DataSet. This DataSet will remain static. If anything happens to your historical DataSet, you will have a backup from before you began editing.\n\n##\n To create a recursive DataFlow in Magic ETL:\n\n\n1. Create and run a Magic\u00a0ETL DataFlow.\n2. Once the DataFlow has finished running, load the output DataSet as an input DataSet.\n\n\n The Output tile\u00a0will show the output DataSet name followed by \"1.\"\n\nYou should now have two DataSets in the DataFlow\u2014the updating original DataSet and the historical DataSet.\n\n\n You now need to find a column to use as a constraint. This helps determine when to replace data in your historical DataSet with new data. Constraint columns are normally ID columns or date columns or have other unique identifiers. In this example, we use the `Date` column as a constraint.\n3. Use\n **Select Columns**\n to select only the constraint column.\n4. Use\n **Remove Duplicates**\n to return a unique list of constraints.\n5. Use an Outer Join to combine your new data to the historical DataSet. If you selected the historical DataSet on the left side of the join, as shown below, use a\n **Left Outer**\n Join. If you select the historical DataSet on the right side of the join, use a\n **Right Outer**\n Join. (Do not select\n **Inner Join**\n , as this could result in a loss of data.) If the date columns are named the same you will notice a warning in Step 3. If you are doing a Left Outer Join then you can auto-fix the right table, and if you are doing a Right Outer Join you can auto-fix the left table. This will add the conflicting column to the Alterations section and will allow you to rename the column if you would like to keep it or drop it altogether. In this situation, we will rename it to \u201cDelete if not null\u201d for our next step.\n6. Filter any rows from your DataSet\u00a0where the new date column is not null.\n\n\n This returns only rows from the historical DataSet that do not exist in the new updating DataSet. You can do this by adding a Filter Rule or by adding a Formula Rule as shown in the examples below.\n\n*Add Filter Rule:**\n\n*Add Formula Rule:**\n7. Use\n **Select Columns**\n to remove the extra date column.\n8. Use\n **Append**\n to join the historical DataSet and new updating DataSet. If all steps have been done correctly, both DataSets will show \"No changes.\"\n\n\n Make sure not to forget to choose how you would like the data to be handled if the data types don't match between columns that should be combined. For more information about this option you can find it here under the \"Append Rows (Union)\" section:\n\nBehavior Changes and Feature Updates in Magic ETL\n\n.\n9. Connect the\n **Append**\n tile to your output. Once complete, your ETL should look like the following:\n\n\n###\n Troubleshooting/FAQ\n\nSee\n\nTop 5 issues Users Experience with DataFlows\n\nto see common issues and errors seen when building DataFlows.\n\n", "preview_article": "\n\nClick here to preview\n\n", "url_name": "\n\n\n 360057087393\n\n\n", "summary____________________________________________briefly_describe_the_article_the_summary_is_used_in_search_results_to_help_users_find_relevant_articles_you_can_improve_the_accuracy_of_search_results_by_including_phrases_that_your_customers_use_to_describe_this_issue_or_topic": "\n\n", "article_number": "\n\n\n 000004573\n\n\n", "archived_date": "\n\n\n", "language": "\n\n\n English\n\n\n", "primary_version": "\n\nCreating a Recursive/Snapshot DataFlow in Magic ETL\n\n", "article_total_view_count": "\n\n\n 7,288\n\n\n", "": "\n\n", "article_created_date": "\n\n\n 10/24/2022, 10:15 PM\n\n\n", "first_published_date": "\n\n\n 10/24/2022, 10:41 PM\n\n\n"}, "title": "creating_a_recursivesnapshot_dataflow_in_magic_etl", "breadcrumbs": [{"text": "domo", "url": "/s/knowledge-base/"}, {"text": "transforming_data_in_domo", "url": "/s/topic/0TO5w000000ZamzGAC"}, {"text": "magic_etl", "url": "/s/topic/0TO5w000000ZanvGAC"}]}